!!! abstract "Informa√ß√µes da entrega"
    üìÜ 05/10/2025

    üìñ O enunciado da atividade est√° dispon√≠vel neste [link](https://insper.github.io/ann-dl/versions/2025.2/projects/classification).

## Integrantes do Grupo
- Carlos Eduardo P. Yamada

- Pedro De Lucca S. C. Ferro

## C√≥digo-fonte
- Notebook de explora√ß√£o e modelagem: `src/projs/proj1_classification/main.ipynb`

## Resumo

Este projeto implementa uma rede neural Multi-Layer Perceptron (MLP) para classifica√ß√£o de alertas de terremotos em quatro categorias: **green**, **yellow**, **orange** e **red**. O modelo foi treinado utilizando dados s√≠smicos que incluem caracter√≠sticas como magnitude, profundidade, intensidade sentida pela comunidade (CDI), intensidade de danos (MMI) e signific√¢ncia do evento.

## Fontes de Dados

Os datasets utilizados neste projeto est√£o dispon√≠veis no Kaggle:

- **Earthquake Dataset**: [https://www.kaggle.com/datasets/warcoder/earthquake-dataset](https://www.kaggle.com/datasets/warcoder/earthquake-dataset)
- **Earthquake Alert Prediction Dataset**: [https://www.kaggle.com/datasets/ahmeduzaki/earthquake-alert-prediction-dataset](https://www.kaggle.com/datasets/ahmeduzaki/earthquake-alert-prediction-dataset)

## Objetivos

- Desenvolver um **modelo de classifica√ß√£o multiclasse** para prever o n√≠vel de alerta de terremotos;
- **Avaliar** o desempenho do modelo utilizando m√∫ltiplas m√©tricas (acur√°cia, precis√£o, *recall*, *F1-score*);
- Analisar os **padr√µes de erro** e limita√ß√µes do modelo.

## Dataset

### Descri√ß√£o dos Dados

O dataset utilizado √© uma vers√£o pr√©-processada e otimizada especificamente para aplica√ß√µes de machine learning em avalia√ß√£o de riscos s√≠smicos e sistemas de predi√ß√£o de alertas de terremotos. Cont√©m **1300 amostras** e **6 colunas**, representando registros de eventos s√≠smicos com diferentes intensidades e alertas associados.

| Coluna      | Tipo                  | Descri√ß√£o                                                                               |
|-------------|-----------------------|-----------------------------------------------------------------------------------------|
| `magnitude` | Num√©rico (`float`)    | Medida da energia liberada pelo terremoto na escala Richter.                            |
| `depth`     | Num√©rico (`float`)    | Profundidade do epicentro em quil√¥metros.                                               |
| `cdi`       | Num√©rico (`float`)    | *Community Decimal Intensity* ‚Äì intensidade sentida pela popula√ß√£o (escala de 1 a 10).  |
| `mmi`       | Num√©rico (`float`)    | *Modified Mercalli Intensity* ‚Äì intensidade dos danos observados (escala de 1 a 10).    |
| `sig`       | Num√©rico (`float`)    | Signific√¢ncia do evento (pontua√ß√£o calculada pelo USGS).                                |
| `alert`     | Categ√≥rica (`string`) | *Target*: n√≠vel de alerta ‚Äî `green`, `yellow`, `orange`, ou `red`.                      |
 
### Balanceamento dos Dados via SMOTE

O dataset utilizado foi balanceado utilizando **SMOTE** (*Synthetic Minority Over-sampling Technique*), uma t√©cnica avan√ßada de oversampling que gera amostras sint√©ticas para as classes minorit√°rias. Diferente da simples duplica√ß√£o de amostras, o SMOTE cria novos exemplos interpolando entre inst√¢ncias existentes da classe minorit√°ria, resultando em:

- **Melhor generaliza√ß√£o**: O modelo aprende padr√µes mais diversos em vez de memorizar amostras duplicadas;
- **Redu√ß√£o de overfitting**: Amostras sint√©ticas adicionam variabilidade controlada ao dataset;
- **Distribui√ß√£o equilibrada**: Todas as classes de alerta possuem aproximadamente o mesmo n√∫mero de amostras.

|      ![label-dist-unbalanced](./img/image_01.png)      |
| :--------------------------------------: |
| Figura 1: Distribui√ß√£o das classes no conjunto de dados desbalanceado |

|      ![label-dist-balanced](./img/image_02.png)      |
| :--------------------------------------: |
| Figura 2: Distribui√ß√£o das classes no conjunto de dados balanceado (utilizado no treinamento) |

### An√°lise Explorat√≥ria

|      ![num-features-histogram](./img/image_03.png)      |
| :--------------------------------------: |
| Figura 3: Distribui√ß√£o dos atributos num√©ricos do dataset |

|      ![corr-matrix](./img/image_04.png)      |
| :--------------------------------------: |
| Figura 4: Matriz de correla√ß√£o entre as vari√°veis num√©ricas |

As principais observa√ß√µes da an√°lise explorat√≥ria incluem:
- Forte correla√ß√£o entre `magnitude` e `sig` (signific√¢ncia);
- Correla√ß√£o moderada entre `cdi` e `mmi`;
- `depth` apresenta menor correla√ß√£o com outras vari√°veis.

## Metodologia

### Pr√©-processamento

1. **One-hot Encoding**: Convers√£o da vari√°vel categ√≥rica `alert` em 4 colunas bin√°rias;
2. **Normaliza√ß√£o Z-Score**: Padroniza√ß√£o de todas as features num√©ricas usando m√©dia e desvio padr√£o;
3. **Embaralhamento**: Randomiza√ß√£o das amostras para evitar overfitting por enviesamento;
4. **Divis√£o dos dados**: $70\%$ treino, $30\%$ teste (com `random_state=42`).

### Arquitetura do Modelo

**Multi-Layer Perceptron (MLP) - Scikit-learn**

- **Camada de entrada**: 5 neur√¥nios (features normalizadas);
- **Camada oculta**: 16 neur√¥nios;
- **Camada de sa√≠da**: 4 neur√¥nios (classes de alerta);
- **Fun√ß√£o de ativa√ß√£o**: ReLU (camadas ocultas), sigmoide (sa√≠da);
- **Otimizador**: Adam;
- **Learning rate**: 0.01;
- **Batch size**: 100;
- **√âpocas**: 1000.

## Resultados

### Evolu√ß√£o do Treinamento

| ![accuracy-evolution](./img/image_05.png) |
| :--------------------------------------: |
| Figura 5: Evolu√ß√£o da acur√°cia ao longo das 1000 √©pocas de treinamento |

| ![conf-matrix-test](./img/image_06.png) |
| :--------------------------------------: |
| Figura 6: Matriz de confus√£o dos resultados de teste |

| ![score-comparison](./img/image_07.png) |
| :--------------------------------------: |
| Figura 7: Compara√ß√£o de Precis√£o, Recall e F1-Score por classe de alerta |

### M√©tricas de Performance

| M√©trica | Conjunto de Treino | Conjunto de Teste |
|---------|-------------------|-------------------|
| **Acur√°cia** | $~80\%$ | $~78\%$ |
| **Diferen√ßa (Overfitting)** | - | $~2\%$ |

O modelo apresentou boa generaliza√ß√£o, com diferen√ßa m√≠nima entre treino e teste, indicando aus√™ncia de overfitting significativo.

### Erros mais significativos

| ![main-errors](./img/image_08.png) |
| :--------------------------------------: |
| Figura 8: Visualiza√ß√£o dos principais erros |

### Curva de perda durante o treinamento

| ![loss-curve](./img/image_09.png) |
| :--------------------------------------: |
| Figura 9: Curva de perda durante o treinamento |

### Compara√ß√£o entre as distribui√ß√µes de reais e preditas

| ![prediction-comparison](./img/image_10.png) |
| :--------------------------------------: |
| Figura 10: Compara√ß√£o entre as distribui√ß√µes de reais e preditas |

### An√°lise de Erros

Os principais tipos de erro do modelo incluem:
- Confus√£o entre classes adjacentes (`orange` ‚Üî `green`, `green` ‚Üî `yellow`);
- Melhor desempenho nas classes extremas (`yellow` e `red`);
- Maior dificuldade nas classes intermedi√°rias devido √† sobreposi√ß√£o de caracter√≠sticas.

### Distribui√ß√£o das Predi√ß√µes

A distribui√ß√£o das predi√ß√µes do modelo manteve-se consistente com a distribui√ß√£o real das classes no conjunto de teste, indicando que o modelo n√£o apresenta vi√©s significativo em dire√ß√£o a nenhuma classe espec√≠fica.

## Discuss√£o

### Pontos Fortes

1. **Boa generaliza√ß√£o**: Diferen√ßa m√≠nima entre acur√°cia de treino e teste ($~2\%$);
2. **Modelo balanceado**: N√£o apresenta vi√©s excessivo para nenhuma classe;
3. **Converg√™ncia est√°vel**: Curva de perda monotonicamente decrescente;
4. **Performance consistente**: M√©tricas equilibradas entre precis√£o e recall.

### Limita√ß√µes

1. **Confus√£o entre classes adjacentes**: O modelo tem dificuldade em distinguir alertas de n√≠veis pr√≥ximos;
2. **Acur√°cia moderada**: $~78\%$ pode n√£o ser suficiente para aplica√ß√µes cr√≠ticas de seguran√ßa;
3. **Arquitetura simples**: Uma √∫nica camada oculta pode limitar a capacidade de aprender padr√µes complexos.

### Melhorias Poss√≠veis

- Adicionar mais camadas ocultas para aumentar a capacidade representacional;
- Implementar t√©cnicas de regulariza√ß√£o (Dropout, L2);
- Explorar outras arquiteturas (CNN, LSTM) se houver dados temporais;
- Aumentar o dataset para melhorar a generaliza√ß√£o;
- Feature engineering: criar vari√°veis derivadas das existentes;
- Ajuste fino de hiperpar√¢metros via Grid Search ou Random Search.

## Conclus√£o

O modelo MLP desenvolvido demonstrou capacidade satisfat√≥ria para classifica√ß√£o de alertas de terremotos, atingindo $~78\%$ de acur√°cia no conjunto de teste. A an√°lise detalhada revelou que o modelo funciona melhor para classes extremas (green e red) e apresenta maior confus√£o entre classes adjacentes. 

Para aplica√ß√µes em sistemas de alerta real, recomenda-se:
- Priorizar recall para classes cr√≠ticas (red e orange) para minimizar falsos negativos;
- Investigar t√©cnicas de ensemble para melhorar a robustez;
- Coletar mais dados para as transi√ß√µes entre classes.