!!! abstract "Informa√ß√µes da entrega"
    üìÜ Deadline: 05/09/2025

    üìñ O enunciado da atividade est√° dispon√≠vel neste [link](https://insper.github.io/ann-dl/versions/2025.2/exercises/data).

## Exerc√≠cio 1

Os dados foram gerados por um script em Python, apresentado a seguir:

=== "main.py"

    ``` py
    import matplotlib.pyplot as plt

    N = 400

    def main():
        class_0 = Data(mu=(2,  3), std=(.8,  2.5), n=N)
        class_1 = Data(mu=(5,  6), std=(1.2, 1.9), n=N)
        class_2 = Data(mu=(8,  1), std=(.9,   .9), n=N)
        class_3 = Data(mu=(15, 4), std=(.5,  2.0), n=N)

    x0, y0 = class_0.sample_initialize()
        x1, y1 = class_1.sample_initialize()
        x2, y2 = class_2.sample_initialize()
        x3, y3 = class_3.sample_initialize()

    plt.plot(x0, y0, "o", label="Classe 0")
        plt.plot(x1, y1, "o", label="Classe 1")
        plt.plot(x2, y2, "o", label="Classe 2")
        plt.plot(x3, y3, "o", label="Classe 3")

    plt.legend()

    plt.title("Plot das classes")

    plt.show()

    return 0

    if__name__ == "__main__":
        main()

    ```

=== "utils.py"

    ``` py
    import numpy as np

    class Data:
        def__init__(self, mu, std, n):
            self.mu_x, self.mu_y = mu
            self.std_x, self.std_y = std
            self.n = n

    def sample_initialize(self) -> tuple[np.ndarray, np.ndarray]:
            return np.random.normal(self.mu_x, self.std_x, self.n), np.random.normal(self.mu_y, self.std_y, self.n)

    class MultiDimensionData:
        def__init__(self, mu, cov, n):
            self.mu = mu
            self.cov = cov
            self.n = n

    def sample_initialize(self):
            return np.random.multivariate_normal(self.mu, self.cov, self.n)
    ```

A imagem a seguir mostra o *plot* dos pontos gerados em para cada uma das classes, diferenciadas pela cor.

![Classes por cor](./img/plot_classes_ex1.png)

Podemos observar que, principalmente as classes 0 e 1 possuem um grande *overlap*, que tamb√©m √© presente entre as classes 1 e 2, de maneira menos gritante. A classe 3 est√° completamente separada das outras tr√™s, quando observada visualmente.

Dessa forma, podemos concluir que as classes poderiam ser separadas com linhas, mas que provavelmente existiriam alguns conflitos quanto √† classifica√ß√£o das classes 0 e 1 e das classes 1 e 2.

Abaixo segue uma representa√ß√£o visual de como as linhas poderiam separar as classes.

![Classes por cor - separa√ß√£o manual](./img/plot_classes_ex1_sketch.png)

## Exerc√≠cio 2

As amostras foram geradas pelo c√≥digo apresentado abaixo:

=== "main.py"

    ``` py
    import matplotlib.pyplot as plt
    import numpy as np

    def main():
        mu_A = np.array([0, 0, 0, 0, 0])
        cov_A = np.array([[1.0, 0.8, 0.1, 0.0, 0.0],
                        [0.8, 1.0, 0.3, 0.0, 0.0],
                        [0.1, 0.3, 1.0, 0.5, 0.0],
                        [0.0, 0.0, 0.5, 1.0, 0.2],
                        [0.0, 0.0, 0.0, 0.2, 1.0]])

    mu_B = np.array([1.5, 1.5, 1.5, 1.5, 1.5])
        cov_B = np.array([[ 1.5, -0.7, 0.2, 0.0, 0.0],
                        [-0.7,  1.5, 0.4, 0.0, 0.0],
                        [ 0.2,  0.4, 1.5, 0.6, 0.0],
                        [ 0.0,  0.0, 0.6, 1.5, 0.3],
                        [ 0.0,  0.0, 0.0, 0.3, 1.5]])

    class_A = MultiDimensionData(mu=mu_A, cov=cov_A, n=500)
        class_B = MultiDimensionData(mu=mu_B, cov=cov_B, n=500)

    sample_A = class_A.sample_initialize()
        sample_B = class_B.sample_initialize()

    dataset = np.concatenate((sample_A, sample_B))

    return 0

    if__name__ == "__main__":
        main()
    ```

=== "utils.py"

    ``` py
    import numpy as np

    class Data:
        def__init__(self, mu, std, n):
            self.mu_x, self.mu_y = mu
            self.std_x, self.std_y = std
            self.n = n

    def sample_initialize(self) -> tuple[np.ndarray, np.ndarray]:
            return np.random.normal(self.mu_x, self.std_x, self.n), np.random.normal(self.mu_y, self.std_y, self.n)

    class MultiDimensionData:
        def__init__(self, mu, cov, n):
            self.mu = mu
            self.cov = cov
            self.n = n

    def sample_initialize(self):
            return np.random.multivariate_normal(self.mu, self.cov, self.n)
    ```

Em seguida, aplicou-se o conceito de **PCA** (**Principal Component Analysis**) para reduzir a dimensionalidade dos dados para **duas** dimens√µes (2D).

### **Passo-a-passo**

Ap√≥s gerar as amostras (classes A e B), √© necess√°rio obter a matriz de covari√¢ncia dos dados como um todo.

```py
mat = np.cov(dataset, rowvar=False)
```

Depois disso, precisamos obter os autovalores e os autovetores dessa matriz, sendo que os autovalores servir√£o para auxiliar na defini√ß√£o da import√¢ncia das *features* e os autovetores s√£o essenciais para que possamos obter um novo conjunto de amostras, agora apenas com as *features* selecionadas.

```py
# Obten√ß√£o dos autovalores e autovetores
eigenvalues, eigenvectors = np.linalg.eig(mat)

# Processo feito para ordenar a lista de autovetores e autovalores
## Obt√©m os √≠ndices que ordenariam o vetor e inverte a lista
idx = np.argsort(eigenvalues)[::-1]

## Ordena a lista de autovalores
eigenvalues = eigenvalues[idx]

## Ordena a lista de autovetores (colunas)
eigenvectors = eigenvectors[:, idx]

# Obt√©m os dois principais autovetores (para PC1 e PC2)
pcs = eigenvectors[:, :2] # matrix 5x2

# Centralizar o dataset original 
dataset_mu = dataset.mean(axis=0) # matriz 1000x5
dataset_cent = dataset - dataset_mu

# Obten√ß√£o do novo conjunto de dados
Z = dataset_cent @ pcs # (1000,5) x (5, 2)
```

Nota-se que foram realizadas algumas outras etapas antes de obtermos o novo conjunto de amostras, que foram realizadas para que esse conjunto estivesse centralizado.

Por fim, podemos *plotar* o gr√°fico com as duas *features* selecionadas e separ√°-las de acordo com as respectivas classes.

![Plot 2D - ex. 2](./img/plot_ex2.png)

De acordo com a imagem, observa-se que os dados da classe B tendem mais a valores negativos, enquanto os da classes A tendem mais a valores positivos.

O problema surge pois existe uma grande quantidade de dados que s√£o semelhantes, tornando o uso de modelos simples para classifica√ß√£o linear inadequados para classificar as classes. Seria necess√°rio o uso de ferramentas mais robustas como um MLP, que possibilitam uma propaga√ß√£o de erro em camadas para que o modelo seja treinado de forma mais eficiente (*backpropagation*).

## Exerc√≠cio 3

### **Objetivo do dataset**

O dataset apresenta como objetivo prever se um passageiro foi transportado para uma outra dimens√£o durante uma colis√£o da nave espacial Titanic com uma anomalia espa√ßo-temporal. Para isso, s√£o disponibilizados dados que foram recuperados dos registros pessoais dos passageiros do sistema da nave.

### **Descri√ß√£o das *features***

Existem 14 features diferentes do dataset a ser analisado. Podemos separ√°-las em num√©ricas e em categ√≥ricas, como mostrado a seguir:

- **Num√©ricas**: `Age`, `RoomService`, `FoodCourt`, `ShoppingMall`, `Spa`, `VRDeck`;
- **Categ√≥ricas**: `HomePlanet`, `CryoSleep`, `Cabin`, `Destination`, `VIP`, `Name`, `Transported`.

### **Valores ausentes**

Podemos observar na imagem abaixo a quantidade de valores nulos por *feature*.

![Histograma dos valores nulos por coluna (feature)](./img/null_histpng.png)

### **Pr√©-processamento dos dados**

Para cada tipo de feature, os dados faltantes foram tratados de maneiras diferentes:

- **categ√≥ricas (bin√°rias e nominais)**: foi extra√≠da a **moda** da coluna e os valores ausentes foram preenchidos por ela, visto que √© uma estrat√©gia simples, mas que contorna o problema de impossibilitar o *one-hot encoding*, por exemplo.
- **num√©ricas**: foi extra√≠da a **mediana** e os valores ausentes preenchidos por ela, da mesma forma, √© uma t√©cnica simples que n√£o exige muito tratamento, al√©m de garantir roubstez a outliers, algo que o uso da m√©dia n√£o possibilitaria.

Dessa forma, apesar de o dataset sofrer um leve desbalanceamento, os dados puderam ser mantidos em vez de remover linhas inteiras que contivessem valores nulos, mantendo a integridade da base de dados.

Al√©m disso, a *feature* `Cabin` foi subdividida em 3 categorias menores: `CabinDeck`, `CabinNum` e `CabinSide`, como √© descrito no site do [Kaggle](https://www.kaggle.com/competitions/spaceship-titanic/data?select=sample_submission.csv).

### **Fazendo *one-hot encoding* de *features* categ√≥ricas**

Para *features* como `HomePlanet`, `Destination`, `CabinDeck` e `CabinSide` (derivadas da *feature* `Cabin`), foi feito one-hot encoding para transform√°-las em vari√°veis categ√≥ricas de ordem bin√°ria, sendo uma das etapas para possibilitar a implementa√ß√£o de uma rede neural cuja fun√ß√£o de ativa√ß√£o √© a tangente hiperb√≥lica ($tanh(x)$).

### **Padroniza√ß√£o dos dados (z-score)**

Em seguida, os dados foram tratados de forma que as features num√©ricas possu√≠ssem m√©dia $0$ ($\mu = 0$) e desvio padr√£o $1$ ($\sigma = 0$). Essa √© outra etapa para que seja poss√≠vel realizar o treinamento da rede neural utilizando a fun√ß√£o tanh(x) como fun√ß√£o de ativa√ß√£o, visto que o dom√≠nio da fun√ß√£o est√° definido no intervalo $[-1, 1]$.

### **Visualiza√ß√£o dos resultados**

O primeiro histograma mostra a compara√ß√£o de como era a distribui√ß√£o das idades ANTES do tratamento dos dados e como ficou AP√ìS o tratamento.

![Histograma de distribui√ß√£o de idades](./img/age_comparison.png)

Podemos observar que a quantidade de pessoas √† bordo na faixa de 20 anos se mostra maior quando os dados n√£o foram tratados. Ap√≥s o tratamento, a faixa muda para 25 anos.

Em seguida, temos a compara√ß√£o para duas vari√°veis semelhantes, que abordam os gastos na pra√ßa de alimenta√ß√£o da nave e com servi√ßos de quarto, respectivamente.

![Histograma de distribui√ß√£o de gastos com pra√ßa de alimenta√ß√£o](./img/food_court_comparison.png)

![Histograma de distribui√ß√£o de gastos com servi√ßos de quarto](./img/room_service_comparison.png)

Conseguimos, a partir dos gr√°ficos, concluir que no caso dessas duas vari√°veis, n√£o houverem mudan√ßas significativas, uma vez que boa parte dos passageiros n√£o gastou com esses dois servi√ßos.
