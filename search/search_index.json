{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#ann-e-deep-learning","title":"ANN e Deep Learning","text":"<p>Turma</p> <p> 2025.2</p>"},{"location":"#entregas","title":"Entregas","text":"Exerc\u00edcios <ul> <li> Data - Prazo 05/09/2025</li> <li> Perceptron - Prazo 14/09/2025</li> <li> MLP - Prazo 21/09/2025</li> <li> VAE - Prazo 26/10/2025</li> </ul> Projetos <ul> <li> Classifica\u00e7\u00e3o - Prazo 05/10/2025</li> <li> Regress\u00e3o - Prazo 26/10/2025</li> <li> Generative Models - Prazo --/--/2025</li> </ul>"},{"location":"exs/ex1_data/main/","title":"Data","text":"<p>Informa\u00e7\u00f5es da entrega</p> <p> 05/09/2025</p> <p> O enunciado da atividade est\u00e1 dispon\u00edvel neste link.</p>"},{"location":"exs/ex1_data/main/#exercicio-1","title":"Exerc\u00edcio 1","text":"<p>Os dados foram gerados por um script em Python, apresentado a seguir:</p> main.pyutils.py <pre><code>import matplotlib.pyplot as plt\n\nN = 400\n\ndef main():\n    class_0 = Data(mu=(2,  3), std=(.8,  2.5), n=N)\n    class_1 = Data(mu=(5,  6), std=(1.2, 1.9), n=N)\n    class_2 = Data(mu=(8,  1), std=(.9,   .9), n=N)\n    class_3 = Data(mu=(15, 4), std=(.5,  2.0), n=N)\n\nx0, y0 = class_0.sample_initialize()\n    x1, y1 = class_1.sample_initialize()\n    x2, y2 = class_2.sample_initialize()\n    x3, y3 = class_3.sample_initialize()\n\nplt.plot(x0, y0, \"o\", label=\"Classe 0\")\n    plt.plot(x1, y1, \"o\", label=\"Classe 1\")\n    plt.plot(x2, y2, \"o\", label=\"Classe 2\")\n    plt.plot(x3, y3, \"o\", label=\"Classe 3\")\n\nplt.legend()\n\nplt.title(\"Plot das classes\")\n\nplt.show()\n\nreturn 0\n\nif__name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>import numpy as np\n\nclass Data:\n    def__init__(self, mu, std, n):\n        self.mu_x, self.mu_y = mu\n        self.std_x, self.std_y = std\n        self.n = n\n\ndef sample_initialize(self) -&gt; tuple[np.ndarray, np.ndarray]:\n        return np.random.normal(self.mu_x, self.std_x, self.n), np.random.normal(self.mu_y, self.std_y, self.n)\n\nclass MultiDimensionData:\n    def__init__(self, mu, cov, n):\n        self.mu = mu\n        self.cov = cov\n        self.n = n\n\ndef sample_initialize(self):\n        return np.random.multivariate_normal(self.mu, self.cov, self.n)\n</code></pre> <p>A imagem a seguir mostra o plot dos pontos gerados em para cada uma das classes, diferenciadas pela cor.</p> <p></p> <p>Podemos observar que, principalmente as classes 0 e 1 possuem um grande overlap, que tamb\u00e9m \u00e9 presente entre as classes 1 e 2, de maneira menos gritante. A classe 3 est\u00e1 completamente separada das outras tr\u00eas, quando observada visualmente.</p> <p>Dessa forma, podemos concluir que as classes poderiam ser separadas com linhas, mas que provavelmente existiriam alguns conflitos quanto \u00e0 classifica\u00e7\u00e3o das classes 0 e 1 e das classes 1 e 2.</p> <p>Abaixo segue uma representa\u00e7\u00e3o visual de como as linhas poderiam separar as classes.</p> <p></p>"},{"location":"exs/ex1_data/main/#exercicio-2","title":"Exerc\u00edcio 2","text":"<p>As amostras foram geradas pelo c\u00f3digo apresentado abaixo:</p> main.pyutils.py <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\ndef main():\n    mu_A = np.array([0, 0, 0, 0, 0])\n    cov_A = np.array([[1.0, 0.8, 0.1, 0.0, 0.0],\n                    [0.8, 1.0, 0.3, 0.0, 0.0],\n                    [0.1, 0.3, 1.0, 0.5, 0.0],\n                    [0.0, 0.0, 0.5, 1.0, 0.2],\n                    [0.0, 0.0, 0.0, 0.2, 1.0]])\n\nmu_B = np.array([1.5, 1.5, 1.5, 1.5, 1.5])\n    cov_B = np.array([[ 1.5, -0.7, 0.2, 0.0, 0.0],\n                    [-0.7,  1.5, 0.4, 0.0, 0.0],\n                    [ 0.2,  0.4, 1.5, 0.6, 0.0],\n                    [ 0.0,  0.0, 0.6, 1.5, 0.3],\n                    [ 0.0,  0.0, 0.0, 0.3, 1.5]])\n\nclass_A = MultiDimensionData(mu=mu_A, cov=cov_A, n=500)\n    class_B = MultiDimensionData(mu=mu_B, cov=cov_B, n=500)\n\nsample_A = class_A.sample_initialize()\n    sample_B = class_B.sample_initialize()\n\ndataset = np.concatenate((sample_A, sample_B))\n\nreturn 0\n\nif__name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>import numpy as np\n\nclass Data:\n    def__init__(self, mu, std, n):\n        self.mu_x, self.mu_y = mu\n        self.std_x, self.std_y = std\n        self.n = n\n\ndef sample_initialize(self) -&gt; tuple[np.ndarray, np.ndarray]:\n        return np.random.normal(self.mu_x, self.std_x, self.n), np.random.normal(self.mu_y, self.std_y, self.n)\n\nclass MultiDimensionData:\n    def__init__(self, mu, cov, n):\n        self.mu = mu\n        self.cov = cov\n        self.n = n\n\ndef sample_initialize(self):\n        return np.random.multivariate_normal(self.mu, self.cov, self.n)\n</code></pre> <p>Em seguida, aplicou-se o conceito de PCA (Principal Component Analysis) para reduzir a dimensionalidade dos dados para duas dimens\u00f5es (2D).</p>"},{"location":"exs/ex1_data/main/#passo-a-passo","title":"Passo-a-passo","text":"<p>Ap\u00f3s gerar as amostras (classes A e B), \u00e9 necess\u00e1rio obter a matriz de covari\u00e2ncia dos dados como um todo.</p> <pre><code>mat = np.cov(dataset, rowvar=False)\n</code></pre> <p>Depois disso, precisamos obter os autovalores e os autovetores dessa matriz, sendo que os autovalores servir\u00e3o para auxiliar na defini\u00e7\u00e3o da import\u00e2ncia das features e os autovetores s\u00e3o essenciais para que possamos obter um novo conjunto de amostras, agora apenas com as features selecionadas.</p> <pre><code># Obten\u00e7\u00e3o dos autovalores e autovetores\neigenvalues, eigenvectors = np.linalg.eig(mat)\n\n# Processo feito para ordenar a lista de autovetores e autovalores\n## Obt\u00e9m os \u00edndices que ordenariam o vetor e inverte a lista\nidx = np.argsort(eigenvalues)[::-1]\n\n## Ordena a lista de autovalores\neigenvalues = eigenvalues[idx]\n\n## Ordena a lista de autovetores (colunas)\neigenvectors = eigenvectors[:, idx]\n\n# Obt\u00e9m os dois principais autovetores (para PC1 e PC2)\npcs = eigenvectors[:, :2] # matrix 5x2\n\n# Centralizar o dataset original \ndataset_mu = dataset.mean(axis=0) # matriz 1000x5\ndataset_cent = dataset - dataset_mu\n\n# Obten\u00e7\u00e3o do novo conjunto de dados\nZ = dataset_cent @ pcs # (1000,5) x (5, 2)\n</code></pre> <p>Nota-se que foram realizadas algumas outras etapas antes de obtermos o novo conjunto de amostras, que foram realizadas para que esse conjunto estivesse centralizado.</p> <p>Por fim, podemos plotar o gr\u00e1fico com as duas features selecionadas e separ\u00e1-las de acordo com as respectivas classes.</p> <p></p> <p>De acordo com a imagem, observa-se que os dados da classe B tendem mais a valores negativos, enquanto os da classes A tendem mais a valores positivos.</p> <p>O problema surge pois existe uma grande quantidade de dados que s\u00e3o semelhantes, tornando o uso de modelos simples para classifica\u00e7\u00e3o linear inadequados para classificar as classes. Seria necess\u00e1rio o uso de ferramentas mais robustas como um MLP, que possibilitam uma propaga\u00e7\u00e3o de erro em camadas para que o modelo seja treinado de forma mais eficiente (backpropagation).</p>"},{"location":"exs/ex1_data/main/#exercicio-3","title":"Exerc\u00edcio 3","text":""},{"location":"exs/ex1_data/main/#objetivo-do-dataset","title":"Objetivo do dataset","text":"<p>O dataset apresenta como objetivo prever se um passageiro foi transportado para uma outra dimens\u00e3o durante uma colis\u00e3o da nave espacial Titanic com uma anomalia espa\u00e7o-temporal. Para isso, s\u00e3o disponibilizados dados que foram recuperados dos registros pessoais dos passageiros do sistema da nave.</p>"},{"location":"exs/ex1_data/main/#descricao-das-features","title":"Descri\u00e7\u00e3o das features","text":"<p>Existem 14 features diferentes do dataset a ser analisado. Podemos separ\u00e1-las em num\u00e9ricas e em categ\u00f3ricas, como mostrado a seguir:</p> <ul> <li>Num\u00e9ricas: <code>Age</code>, <code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>;</li> <li>Categ\u00f3ricas: <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Cabin</code>, <code>Destination</code>, <code>VIP</code>, <code>Name</code>, <code>Transported</code>.</li> </ul>"},{"location":"exs/ex1_data/main/#valores-ausentes","title":"Valores ausentes","text":"<p>Podemos observar na imagem abaixo a quantidade de valores nulos por feature.</p> <p></p>"},{"location":"exs/ex1_data/main/#pre-processamento-dos-dados","title":"Pr\u00e9-processamento dos dados","text":"<p>Para cada tipo de feature, os dados faltantes foram tratados de maneiras diferentes:</p> <ul> <li>categ\u00f3ricas (bin\u00e1rias e nominais): foi extra\u00edda a moda da coluna e os valores ausentes foram preenchidos por ela, visto que \u00e9 uma estrat\u00e9gia simples, mas que contorna o problema de impossibilitar o one-hot encoding, por exemplo.</li> <li>num\u00e9ricas: foi extra\u00edda a mediana e os valores ausentes preenchidos por ela, da mesma forma, \u00e9 uma t\u00e9cnica simples que n\u00e3o exige muito tratamento, al\u00e9m de garantir roubstez a outliers, algo que o uso da m\u00e9dia n\u00e3o possibilitaria.</li> </ul> <p>Dessa forma, apesar de o dataset sofrer um leve desbalanceamento, os dados puderam ser mantidos em vez de remover linhas inteiras que contivessem valores nulos, mantendo a integridade da base de dados.</p> <p>Al\u00e9m disso, a feature <code>Cabin</code> foi subdividida em 3 categorias menores: <code>CabinDeck</code>, <code>CabinNum</code> e <code>CabinSide</code>, como \u00e9 descrito no site do Kaggle.</p>"},{"location":"exs/ex1_data/main/#fazendo-one-hot-encoding-de-features-categoricas","title":"Fazendo one-hot encoding de features categ\u00f3ricas","text":"<p>Para features como <code>HomePlanet</code>, <code>Destination</code>, <code>CabinDeck</code> e <code>CabinSide</code> (derivadas da feature <code>Cabin</code>), foi feito one-hot encoding para transform\u00e1-las em vari\u00e1veis categ\u00f3ricas de ordem bin\u00e1ria, sendo uma das etapas para possibilitar a implementa\u00e7\u00e3o de uma rede neural cuja fun\u00e7\u00e3o de ativa\u00e7\u00e3o \u00e9 a tangente hiperb\u00f3lica (\\(tanh(x)\\)).</p>"},{"location":"exs/ex1_data/main/#padronizacao-dos-dados-z-score","title":"Padroniza\u00e7\u00e3o dos dados (z-score)","text":"<p>Em seguida, os dados foram tratados de forma que as features num\u00e9ricas possu\u00edssem m\u00e9dia \\(0\\) (\\(\\mu = 0\\)) e desvio padr\u00e3o \\(1\\) (\\(\\sigma = 0\\)). Essa \u00e9 outra etapa para que seja poss\u00edvel realizar o treinamento da rede neural utilizando a fun\u00e7\u00e3o tanh(x) como fun\u00e7\u00e3o de ativa\u00e7\u00e3o, visto que o dom\u00ednio da fun\u00e7\u00e3o est\u00e1 definido no intervalo \\([-1, 1]\\).</p>"},{"location":"exs/ex1_data/main/#visualizacao-dos-resultados","title":"Visualiza\u00e7\u00e3o dos resultados","text":"<p>O primeiro histograma mostra a compara\u00e7\u00e3o de como era a distribui\u00e7\u00e3o das idades ANTES do tratamento dos dados e como ficou AP\u00d3S o tratamento.</p> <p></p> <p>Podemos observar que a quantidade de pessoas \u00e0 bordo na faixa de 20 anos se mostra maior quando os dados n\u00e3o foram tratados. Ap\u00f3s o tratamento, a faixa muda para 25 anos.</p> <p>Em seguida, temos a compara\u00e7\u00e3o para duas vari\u00e1veis semelhantes, que abordam os gastos na pra\u00e7a de alimenta\u00e7\u00e3o da nave e com servi\u00e7os de quarto, respectivamente.</p> <p></p> <p></p> <p>Conseguimos, a partir dos gr\u00e1ficos, concluir que no caso dessas duas vari\u00e1veis, n\u00e3o houverem mudan\u00e7as significativas, uma vez que boa parte dos passageiros n\u00e3o gastou com esses dois servi\u00e7os.</p>"},{"location":"exs/ex2_perceptron/main/","title":"Perceptron","text":"<p>Informa\u00e7\u00f5es da entrega</p> <p> 14/09/2025</p> <p> O enunciado da atividade est\u00e1 dispon\u00edvel neste link.</p> <p>Para trabalhar nos exerc\u00edcios, foi feita um arquivo de utilidades (<code>./utils/data.py</code>) com algumas fun\u00e7\u00f5es comuns que foram utilizadas em outras situa\u00e7\u00f5es tamb\u00e9m.</p> data.py<pre><code>import numpy as np\n\nclass Data:\n    def __init__(self, mu, std, n):\n        self.mu_x, self.mu_y = mu\n        self.std_x, self.std_y = std\n        self.n = n\n\n    def sample_initialize(self) -&gt; tuple[np.ndarray, np.ndarray]:\n        return np.random.normal(self.mu_x, self.std_x, self.n), np.random.normal(self.mu_y, self.std_y, self.n)\n\nclass MultiDimensionData:\n    def __init__(self, mu: list, cov: list, n: int):\n        self.mu = np.array(mu)\n        self.cov = np.array(cov)\n        self.n = n\n\n    def sample_initialize(self):\n        return np.random.multivariate_normal(self.mu, self.cov, self.n)\n</code></pre> <p>E importamos isso no arquivo de execu\u00e7\u00e3o do c\u00f3digo.</p> <pre><code>from utils import data\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\n</code></pre>"},{"location":"exs/ex2_perceptron/main/#geracao-de-dados","title":"Gera\u00e7\u00e3o de dados","text":"<p>Foram geradas 2000 amostras de dados, utilizando uma distribui\u00e7\u00e3o normal (Gaussiana) multivariada, sendo que metade dos dados fazem parte de uma classe e a outra metade de outra (denominadas classes 0 e 1)</p> <pre><code>class_0 = data.MultiDimensionData(mu=[mu1, mu2],\n                                  cov=[[cov11, cov12], [cov21, cov22]],\n                                  n=N)\n\nclass_1 = data.MultiDimensionData(mu=[mu1, mu2],\n                                  cov=[[cov11, cov12], [cov21, cov22]],\n                                  n=N)\n\nfeatures = np.concatenate((class_0.sample_initialize(), class_1.sample_initialize()))\n\nlabels = np.concatenate((np.zeros(N, dtype=int), np.ones(N, dtype=int)))\n\nshuffled_features, shuffled_labels = shuffle_sample(sample_array=features, labels_array=labels)\n</code></pre> <p>sendo <code>N = 1000</code>.</p> <p>Foram utilizados diferentes valores para m\u00e9dia e covari\u00e2ncia para cada um dos exerc\u00edcios, disponibilizados no link com o enunciado do exerc\u00edcio.</p> <p>Tamb\u00e9m precisamos levar em conta que os dados foram embaralhados para evitar enviesamento durante o treinamento do modelo.</p> <p>Para fins pr\u00e1ticos, iremos referenci\u00e1-los aqui como linearmente separ\u00e1veis (i - exerc\u00edcio 1) e sobrepostos (ii - exerc\u00edcio 2).</p> <p>O plot dos gr\u00e1ficos para (i) e (ii) se encontra abaixo, respectivamente.</p> Figura 1 - Amostragem com dados linearmente separados Figura 2 - Amostragem com dados sobrepostos"},{"location":"exs/ex2_perceptron/main/#implementacao-do-perceptron","title":"Implementa\u00e7\u00e3o do perceptron","text":"<p>Foram definidas algumas fun\u00e7\u00f5es que foram utilizadas para o perceptron.</p> Shuffle <pre><code>def shuffle_sample(sample_array, labels_array):\n    lista = list(zip(sample_array, labels_array))\n    random.shuffle(lista)\n\n    features, labels = zip(*lista)\n    return np.array(features), np.array(labels)\n</code></pre> M\u00e9tricas <pre><code>def confusion_matrix(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    VP = np.sum((y_true == 1) &amp; (y_pred == 1))  # verdadeiros positivos\n    VN = np.sum((y_true == 0) &amp; (y_pred == 0))  # verdadeiros negativos\n    FP = np.sum((y_true == 0) &amp; (y_pred == 1))  # falsos positivos\n    FN = np.sum((y_true == 1) &amp; (y_pred == 0))  # falsos negativos\n\n    return np.array([[VN, FP],\n                     [FN, VP]])\n\ndef accuracy(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    return np.mean(y_true == y_pred)\n</code></pre> Processamento <pre><code>def forward(x, y, activation, n_epochs, eta=.01):\n    W = np.array([[0, 0]])\n    b = 0\n\n    acc_array = []\n    total_epochs = 0\n\n    for i in range(n_epochs):\n        print(f\"[epoch {i+1}] Starting...\")\n\n        total_epochs = i+1\n        y_pred_vec = []\n        updated = 0\n\n        for j in range(x.shape[0]):\n            z = np.dot(W, x[j].T) + b\n\n            y_pred = activation(z)\n\n            y_pred_vec.append(y_pred)\n\n            error = y[j] - y_pred\n\n            if error != 0:\n                updated += 1\n                W = W + eta * error * x[j]\n                b = b + eta * error\n\n        acc = accuracy(y, y_pred_vec)\n        acc_array.append(acc)\n\n        print(f\"- Accuracy: {acc}\")\n\n        if not updated:\n            print(f\"- No updates detected...\")\n\n            break\n\n    print(f\"Training finished after {total_epochs} epochs.\")\n    return W, b, y_pred_vec\n</code></pre> <p>No exerc\u00edcio 1, como esperado, o modelo converge ap\u00f3s algumas \u00e9pocas (menos que 100), visto que os dados s\u00e3o linearmente separ\u00e1veis.</p> <p>O gr\u00e1fico abaixo mostra a linha de separa\u00e7\u00e3o entre as classes, calculada com base nos pesos e no bias obtidos pelo forward pass ap\u00f3s o treinamento.</p> Figura 3 - Linha de separa\u00e7\u00e3o para a amostra (i) <p>Em seguida, calculamos para os dados sobrepostos, em que o esperado era que o modelo n\u00e3o fosse capaz de convergir, visto que precisamos de um modelo mais complexo (por exemplo, MLP ou SVM) para separar os dados de forma mais correta. Ao rodar o c\u00f3digo, foi obtida uma acur\u00e1cia de aproximadamente \\(60\\%\\), e a linha de decis\u00e3o pode ser vista na imagem abaixo.</p> Figura 4 - Linha de separa\u00e7\u00e3o para a amostra (ii)"},{"location":"exs/ex3_mlp/main/","title":"MLP","text":"<p>Informa\u00e7\u00f5es da entrega</p> <p>\ud83d\udcc6 Data 21/09/2025</p> <p>\ud83d\udcd6 O enunciado da atividade est\u00e1 dispon\u00edvel neste link.</p> <p>Para essa atividade, uma sequ\u00eancia de passos foi seguida a fim de garantir a execu\u00e7\u00e3o correta do MLP:</p> <ol> <li> <p>Inicializa\u00e7\u00e3o da amostra;</p> </li> <li> <p>Amostragem (\\(x\\)): \\(n_{features} \\times n_{amostras}\\)</p> </li> <li>R\u00f3tulos (\\(y\\)): \\(n_{outputs} \\times n_{amostras}\\)</li> <li> <p>Defini\u00e7\u00e3o de hiperpar\u00e2metros para o treinamento do modelo;</p> </li> <li> <p>Pesos da camada oculta: (\\(W^{(1)}\\)) \\(n_{features} \\times n_{neur\u00f4nios}\\)</p> </li> <li>Bias da camada oculta(\\(b^{(1)}\\)): \\(n_{neur\u00f4nios} \\times n_{amostras}\\)</li> <li>Pesos da camada de sa\u00edda (\\(W^{(2)}\\)): \\(n_{neur\u00f4nios} \\times n_{sa\u00eddas}\\)</li> <li>Bias da camada de sa\u00edda (\\(b^{(2)}\\)): \\(n_{sa\u00eddas} \\times n_{amostras}\\)</li> <li>Fun\u00e7\u00e3o de ativa\u00e7\u00e3o: \\(f(x)\\)</li> </ol> <ul> <li>Derivada da fun\u00e7\u00e3o de ativa\u00e7\u00e3o: \\(f'(x)\\)</li> <li>Fun\u00e7\u00e3o de perda: \\(\\mathcal{L}\\)</li> <li>Treino;</li> <li>Teste.</li> </ul>"},{"location":"exs/ex3_mlp/main/#exercicio-1-calculo-manual-das-etapas-para-um-multi-layer-perceptron-mlp","title":"Exerc\u00edcio 1: C\u00e1lculo manual das etapas para um Multi-Layer Perceptron (MLP)","text":"<ul> <li>Passo 1</li> </ul> Inicializa\u00e7\u00e3o da amostra <p><code>{ .py title=main.py }     samples_1 = np.array([[0.5, -0.2]]).T   # n_features X n_samples      labels_1 = np.array([[1]])              # n_outputs X n_samples</code></p> <ul> <li>Passo 2</li> </ul> Defini\u00e7\u00e3o de hiperpar\u00e2metros main.py<pre><code>W1_1 = np.array([[0.3, 0.2], [-0.1, 0.4]])  # n_features X n_neurons\nb1_1 = np.array([[0.1], [-0.2]])            # n_neurons X n_samples\n\nW2_1 = np.array([[0.5], [-0.3]])            # n_neurons X n_outputs\nb2_1 = np.array([[0.2]])                    # n_outputs X n_samples\n\nactivation_function_1 = lambda x: (np.exp(2 * x) - 1) / (np.exp(2 * x) + 1)\nactivation_function_1_derivative = lambda x: 1 - (activation_function_1(x)**2)\n\nloss_function_1 = lambda y, y_pred: 0.5 * (y - y_pred)**2\nloss_function_1_derivative = lambda y, y_pred: y - y_pred\n</code></pre> <p>Foi utilizada, conforme o enunciado do exerc\u00edcio, a fun\u00e7\u00e3o de perda Mean Squared Error (MSE) e a fun\u00e7\u00e3o de ativa\u00e7\u00e3o \\(tanh(x)\\).</p> <ul> <li>Passo 3</li> </ul> TreinamentoClasse main.py<pre><code>kwargs_1 = {\n            \"input\": samples_1,\n            \"output\": labels_1,\n            \"W_hidden\": W1_1,\n            \"b_hidden\": b1_1,\n            \"W_output\": W2_1,\n            \"b_output\": b2_1,\n            \"eta\": eta_1,\n            \"hidden_activation\": activation_function_1,\n            \"hidden_activation_d\": activation_function_1_derivative,\n            \"output_activation\": activation_function_1,\n            \"output_activation_d\": activation_function_1_derivative,\n            \"loss_function\": loss_function_1,\n            \"loss_function_d\": loss_function_1_derivative\n        }\n\nmlp_data_train_1 = data.MLP(**kwargs_1)\n\nz1, h1, z2, y_pred = mlp_data_train_1.forward()\n\nloss = mlp_data_train_1.loss_calculation(labels_1, y_pred)\n\ndW1_1, db1_1, dW2_1, db2_1 = mlp_data_train_1.backpropagation(z1, h1, z2, y_pred)\n\nW_hidden, b_hidden, W_output, b_output = mlp_data_train_1.update_weights(dW1_1, db1_1, dW2_1, db2_1)\n</code></pre> models.py<pre><code>class MLP:\n\n    def__init__(self, **kwargs):\n        self.input  = kwargs.get(\"input\")\n        self.output = kwargs.get(\"output\")\n        self.W_hidden = kwargs.get(\"W_hidden\")\n        self.b_hidden = kwargs.get(\"b_hidden\")\n        self.W_output = kwargs.get(\"W_output\")\n        self.b_output = kwargs.get(\"b_output\")\n        self.eta = kwargs.get(\"eta\", 0.001)\n\n        # Hidden layer\n        self.hidden_activation   = kwargs.get(\"hidden_activation\")\n        self.hidden_activation_d = kwargs.get(\"hidden_activation_d\")\n\n        # Output layer (opcional)\n        self.output_activation   = kwargs.get(\"output_activation\", None)\n        self.output_activation_d = kwargs.get(\"output_activation_d\", None)\n\n        # Loss\n        self.loss_function   = kwargs.get(\"loss_function\")\n        self.loss_function_d = kwargs.get(\"loss_function_d\")\n\n    def forward(self):\n        # Hidden layer\n        # z1_pre: (n_neurons X n_samples);\n        # W1: (n_neurons X n_feat); input: (n_feat X n_samples); b1: (n_neurons X n_samples)\n        z1_pre = self.W_hidden.T @ self.input + self.b_hidden\n        z1_act = self.hidden_activation(z1_pre)\n\n        # Output layer\n        # z2_pre: (n_outputs X n_samples);\n        # W2: (n_outputs X n_neurons); z1_act: (n_neurons X n_samples); b2: (n_outputs X n_samples)\n        z2_pre = self.W_output.T @ z1_act + self.b_output\n\n        if self.output_activation:\n            z2_act = self.output_activation(z2_pre)\n        else:\n            z2_act = z2_pre\n\n        return z1_pre, z1_act, z2_pre, z2_act\n\n    def loss_calculation(self, true_label, predicted_label):\n        return self.loss_function(true_label, predicted_label)\n\n    def backpropagation(self, z1_pre, z1_act, z2_pre, z2_act):\n        # formato n_output X n_samples\n        output_error = self.loss_function_d(self.output, z2_act)\n\n        if self.output_activation_d:\n            output_error *= self.output_activation_d(z2_pre)\n\n        # formato n_neurons X n_samples\n        hidden_error = (self.W_output @ output_error) * self.hidden_activation_d(z1_pre)\n\n        # Gradientes\n        W_output_gradient = z1_act @ output_error.T\n        b_output_gradient = np.sum(output_error, axis=1, keepdims=True)\n        W_hidden_gradient = self.input @ hidden_error.T\n        b_hidden_gradient = np.sum(hidden_error, axis=1, keepdims=True)\n\n        return W_hidden_gradient, b_hidden_gradient, W_output_gradient, b_output_gradient\n\n    def update_weights(self, W_hidden_gradient, b_hidden_gradient,\n                    W_output_gradient, b_output_gradient):\n        self.W_hidden -= self.eta * W_hidden_gradient\n        self.b_hidden -= self.eta * b_hidden_gradient\n        self.W_output -= self.eta * W_output_gradient\n        self.b_output -= self.eta * b_output_gradient\n        return self.W_hidden, self.b_hidden, self.W_output, self.b_output\n</code></pre> <p>Os resultados do backward pass para as camadas oculta (1) e de sa\u00edda (2) foram:</p> <p>\\(\\frac{\\partial \\mathcal{L}}{\\partial W^{(1)}} \\approx \\begin{bmatrix} 0.26179727 &amp; 0.22385243 \\cr -0.08471891 &amp; 0.39045903 \\end{bmatrix}\\)</p> <p>\\(\\frac{\\partial \\mathcal{L}}{\\partial b^{(1)}} \\approx \\begin{bmatrix} 0.02359454  \\cr -0.15229515 \\end{bmatrix}\\)</p> <p>\\(\\frac{\\partial \\mathcal{L}}{\\partial W^{(2)}} \\approx \\begin{bmatrix} 0.45670643 \\cr -0.27075481 \\end{bmatrix}\\)</p> <p>\\(\\frac{\\partial \\mathcal{L}}{\\partial b^{(2)}} \\approx 0.03577581\\)</p>"},{"location":"exs/ex3_mlp/main/#exercicio-2-classificacao-binaria-com-dados-sinteticos","title":"Exerc\u00edcio 2: Classifica\u00e7\u00e3o bin\u00e1ria com dados sint\u00e9ticos","text":"<ul> <li>Passo 1</li> </ul> Inicializa\u00e7\u00e3o da amostra main.py<pre><code>N_FEATURES_2 = 2\nN_OUTPUT_2 = 1\nN_NEURONS_2 = 10\nSAMPLE_SIZE_2 = 1000\nTRAIN_SIZE = .8\n\nsamples_1_2, samples_labels_1_2 = make_classification(n_samples=SAMPLE_SIZE_2 // 2,\n                                                n_classes=1,\n                                                n_clusters_per_class=1,\n                                                n_features=N_FEATURES_2,\n                                                n_informative=2,\n                                                n_redundant=0,\n                                                random_state=21,\n                                                class_sep=2.0)\n\nsamples_2_2, samples_labels_2_2 = make_classification(n_samples=SAMPLE_SIZE_2 // 2,\n                                                n_classes=1,\n                                                n_clusters_per_class=2,\n                                                n_features=N_FEATURES_2,\n                                                n_informative=2,\n                                                n_redundant=0,\n                                                random_state=42,\n                                                class_sep=2.0)\n\nsamples_labels_1_2[:] = 0\nsamples_labels_2_2[:] = 1\n\nsamples_total_2 = np.concatenate((samples_1_2, samples_2_2))\nsamples_total_labels_2 = np.concatenate((samples_labels_1_2, samples_labels_2_2))\n\nshuffled_samples_total_2, shuffled_samples_total_labels_2 = data.shuffle_sample(sample_array=samples_total_2, labels_array=samples_total_labels_2)\n</code></pre> <p>O tamanho da amostragem \u00e9 de 1000, com 2 classes, 2 features e 16 neur\u00f4nios para a camada oculta. Como \u00e9 um problema de classifica\u00e7\u00e3o bin\u00e1ria, o n\u00famero de outputs \u00e9 de 1 (0 ou 1).</p> <p>A imagem (ref) ilustra graficamente a rela\u00e7\u00e3o entre as features.</p> Figura 1: Amostragem para o exerc\u00edcio 2 <ul> <li>Passo 2</li> </ul> Defini\u00e7\u00e3o de hiperpar\u00e2metros main.py<pre><code>val = (6 / (N_FEATURES_2 + N_OUTPUT_2))**.5\n\nW1_2 = np.random.uniform(-val, val, size=(N_FEATURES_2, N_NEURONS_2))\nW2_2 = np.random.uniform(-val, val,  size=(N_NEURONS_2, N_OUTPUT_2))\n\nb1_2 = np.zeros((N_NEURONS_2, 1)) # n_neurons X n_sample (train)\nb2_2 = np.zeros((N_OUTPUT_2, 1))\n\ntrain_sample_2, test_sample_2, train_sample_labels_2, test_sample_labels_2 = data.train_test_split(shuffled_samples_total_2, shuffled_samples_total_labels_2, TRAIN_SIZE)\n\ntrain_sample_2 = train_sample_2.T\ntest_sample_2 = test_sample_2.T\n\nmu  = np.mean(train_sample_2, axis=1, keepdims=True)\nstd = np.std(train_sample_2, axis=1, keepdims=True) + 1e-8\n\ntrain_sample_norm_2 = (train_sample_2 - mu) / std\ntest_sample_norm_2  = (test_sample_2  - mu) / std\n\nsigmoid = lambda x: 1 / (1 + np.exp(-x))\nsigmoid_d = lambda x: sigmoid(x) * (1 - sigmoid(x))\n\neps = 1e-8\nbce = lambda y, y_pred: -(y * np.log(y_pred + eps) + (1 - y) * np.log(1 - y_pred + eps))\nbce_d = lambda y, y_pred: (y_pred - y) / ((y_pred + eps) * (1 - y_pred + eps))\n</code></pre> <p>Aqui, inicializamos os pesos com o m\u00e9todo de Xavier/Glorot. No exerc\u00edcio, \u00e9 utilizada a inicializa\u00e7\u00e3o uniforme de Xavier, definida pela equa\u00e7\u00e3o \\(2.1\\).</p> \\[ x = \\sqrt{\\frac{6}{n_{inputs} + n_{outputs}}} \\quad \\text{(2.1)} \\] <p>Foi utilizada a fun\u00e7\u00e3o de ativa\u00e7\u00e3o sigmoide, pois os valores est\u00e3o normalizados, juntamente \u00e0 fun\u00e7\u00e3o de perda Binary Cross-Entropy (BCE), por se tratar de uma classifica\u00e7\u00e3o bin\u00e1ria.</p> <ul> <li>Passo 3</li> </ul> Treinamento train.py<pre><code>kwargs_2 = {\"input\": train_sample_norm_2,\n        \"output\": train_sample_labels_2,\n        \"W_hidden\": W1_2,\n        \"b_hidden\": b1_2,\n        \"W_output\": W2_2,\n        \"b_output\": b2_2,\n        \"eta\": .001,\n        \"hidden_activation\": sigmoid,\n        \"hidden_activation_d\": sigmoid_d,\n        \"output_activation\": sigmoid,\n        \"output_activation_d\": sigmoid_d,\n        \"loss_function\": bce,\n        \"loss_function_d\": bce_d}\n\nmlp_object_train_2 = data.MLP(**kwargs_2)\n\nepoch_losses = {100: [], 300: [], 500: []}\nepoch_accuracy = {}\n\nfor n_epochs, losses in epoch_losses.items():\n    epoch_accuracy[n_epochs] = []\n\nfor epoch in range(n_epochs):\n        z1_pre, z1_activation, z2_pre, z2_activation = mlp_object_train_2.forward()\n\nloss = mlp_object_train_2.loss_calculation(train_sample_labels_2, z2_activation)\n        losses.append(np.mean(loss))\n\ny_pred = (z2_activation &gt; 0.5).astype(int)\n        acc = np.mean(y_pred == train_sample_labels_2)\n        epoch_accuracy[n_epochs].append(acc)\n\nW_hidden_gradient, b_hidden_gradient, W_output_gradient, b_output_gradient = mlp_object_train_2.backpropagation(z1_pre, z1_activation, z2_pre, z2_activation)\n\nW_hidden, b_hidden, W_output, b_output = mlp_object_train_2.update_weights(W_hidden_gradient, b_hidden_gradient, W_output_gradient, b_output_gradient)\n</code></pre> <p>O treinamento foi realizado utilizando 100, 300 e 500 \u00e9pocas, e foi avaliada de acordo com as perdas ao longo do treinamento, assim como a acur\u00e1cia obtida.</p> Figura 2: Perda ao longo do treinamento Figura 3: Acur\u00e1cia ao longo do treinamento <ul> <li>Passo 4</li> </ul> Teste main.py<pre><code>kwargs_test_2 = {\n                \"input\": test_sample_norm_2,\n                \"output\": test_sample_labels_2,\n                \"W_hidden\": W_hidden,\n                \"b_hidden\": b_hidden,\n                \"W_output\": W_output,\n                \"b_output\": b_output,\n                \"eta\": .001,\n                \"hidden_activation\": sigmoid,\n                \"hidden_activation_d\": sigmoid_d,\n                \"output_activation\": sigmoid,\n                \"output_activation_d\": sigmoid_d,\n                \"loss_function\": bce,\n                \"loss_function_d\": bce_d\n            }\n\nmlp_object_test_2 = data.MLP(**kwargs_test_2)\n\nz1_test_2, h1_test_2, z2_test_2, y_pred_test_2 = mlp_object_test_2.forward()\n\nloss_test_2 = mlp_object_test_2 = data.MLP(**kwargs_test_2).loss_calculation(test_sample_labels_2, y_pred_test_2)\n\nTHRESHOLD = .5\n\ny_pred = (y_pred_test_2 &gt; THRESHOLD).astype(int)\nacc_test = np.mean(y_pred == test_sample_labels_2)\n</code></pre> <p>Ap\u00f3s o treinamento, foi obtida uma acur\u00e1cia de \\(90.50\\%\\), como esperado de acordo com o gr\u00e1fico ilustrado na figura 3.</p>"},{"location":"exs/ex3_mlp/main/#exercicio-3-classificacao-multi-classe-com-dados-sinteticos","title":"Exerc\u00edcio 3: Classifica\u00e7\u00e3o multi-classe com dados sint\u00e9ticos","text":"<ul> <li>Passo 1</li> </ul> Inicializa\u00e7\u00e3o da amostra main.py<pre><code>SAMPLE_SIZE_3           = 1500\nN_FEATURES_3            = 4\nN_INFORMATIVE_3         = 4\nN_REDUNDANT_3           = 0\nrandom_state            = {\"classe 0\": 21,\n                    \"classe 1\": 42,\n                    \"classe 2\": 84}\nn_cluters_per_class     = {\"classe 0\": 2,\n                    \"classe 1\": 3,\n                    \"classe 2\": 4}\nCLASS_SEP_3             = 2.0\nN_CLASSES_3             = 3\nN_NEURONS_3             = 128\n\nsamples_0_3, samples_labels_0_3 = make_classification(n_samples=SAMPLE_SIZE_3 // 3,\n                                                n_classes=1,\n                                                n_clusters_per_class=n_cluters_per_class[\"classe 0\"],\n                                                n_features=N_FEATURES_3,\n                                                n_informative=N_INFORMATIVE_3,\n                                                n_redundant=N_REDUNDANT_3,\n                                                random_state=random_state[\"classe 0\"],\n                                                class_sep=CLASS_SEP_3)\n\nsamples_1_3, samples_labels_1_3 = make_classification(n_samples=SAMPLE_SIZE_3 // 3,\n                                                n_classes=1,\n                                                n_clusters_per_class=n_cluters_per_class[\"classe 1\"],\n                                                n_features=N_FEATURES_3,\n                                                n_informative=N_INFORMATIVE_3,\n                                                n_redundant=N_REDUNDANT_3,\n                                                random_state=random_state[\"classe 1\"],\n                                                class_sep=CLASS_SEP_3)\n\nsamples_2_3, samples_labels_2_3 = make_classification(n_samples=SAMPLE_SIZE_3 // 3,\n                                                n_classes=1,\n                                                n_clusters_per_class=n_cluters_per_class[\"classe 2\"],\n                                                n_features=N_FEATURES_3,\n                                                n_informative=N_INFORMATIVE_3,\n                                                n_redundant=N_REDUNDANT_3,\n                                                random_state=random_state[\"classe 2\"],\n                                                class_sep=CLASS_SEP_3)\n\nsamples_labels_0_3[:] = 0\nsamples_labels_1_3[:] = 1\nsamples_labels_2_3[:] = 2\n\nsamples_total_3 = np.concatenate((samples_0_3, samples_1_3, samples_2_3))\nsamples_total_labels_3 = np.concatenate((samples_labels_0_3, samples_labels_1_3, samples_labels_2_3))\n\nshuffled_samples_total_3, shuffled_samples_total_labels_3 = data.shuffle_sample(sample_array=samples_total_3, labels_array=samples_total_labels_3)\n</code></pre> <p>A figura 4 mostra um gr\u00e1fico da distribui\u00e7\u00e3o das amostras em rela\u00e7\u00e3o \u00e0 2 features.</p> Figura 4: Amostragem para o exerc\u00edcio 3 <ul> <li>Passo 2</li> </ul> Defini\u00e7\u00e3o dos hiperpar\u00e2metros main.py<pre><code>val = (6 / (N_FEATURES_3 + N_CLASSES_3))**.5\n\nW1_3 = np.random.uniform(-val, val, size=(N_FEATURES_3, N_NEURONS_3))\nW2_3 = np.random.uniform(-val, val, size=(N_NEURONS_3, N_CLASSES_3))\n\nb1_3 = np.zeros((N_NEURONS_3, 1))\nb2_3 = np.zeros((N_CLASSES_3, 1))\n\ntrain_sample_3, test_sample_3, train_sample_labels_3, test_sample_labels_3 = data.train_test_split(shuffled_samples_total_3, shuffled_samples_total_labels_3)\n\ntrain_sample_3 = train_sample_3.T\ntest_sample_3 = test_sample_3.T\n\nmu  = np.mean(train_sample_3, axis=1, keepdims=True)\nstd = np.std(train_sample_3, axis=1, keepdims=True) + 1e-8\n\ntrain_sample_norm_3 = (train_sample_3 - mu) / std\ntest_sample_norm_3  = (test_sample_3  - mu) / std\n\ntanh = lambda x: (np.exp(2*x) - 1) / (np.exp(2*x) + 1)\ntanh_d = lambda x: 1 - tanh(x)**2\n\ndef softmax(z):\n    exp_z = np.exp(z - np.max(z, axis=0, keepdims=True))\n    return exp_z / np.sum(exp_z, axis=0, keepdims=True)\n\ndef cce(y, y_pred, eps=1e-8):\n    N = y.shape[1]\n    return -np.sum(y * np.log(y_pred + eps)) / N\n\ndef cce_d(y, y_pred):\n    N = y.shape[1]\n    return (y_pred - y) / N\n</code></pre> <p>Nesse exerc\u00edcio, utilizamos a fun\u00e7\u00e3o de ativa\u00e7\u00e3o \\(tanh(x)\\), visto que a amostra foi normalizada, e \\(softmax(x)\\), que \u00e9 adequada para problemas de classifica\u00e7\u00e3o multi-classe. Para avalia\u00e7\u00e3o, foi utilizada a fun\u00e7\u00e3o de perda Categorical Cross-Entropy.</p> <ul> <li>Passo 3</li> </ul> Treinamento main.py<pre><code>THRESHOLD_3 = .5\nactivation_array = [tanh, softmax]\nactivation_d_array = [tanh_d, None]\n\nkwargs_train_3 = {\n                \"input\": train_sample_norm_3,\n                \"output\": train_labels_onehot_3,\n                \"W_hidden\": W1_3,\n                \"b_hidden\": b1_3,\n                \"W_output\": W2_3,\n                \"b_output\": b2_3,\n                \"eta\": .001,\n                \"hidden_activation\": activation_array[0],\n                \"hidden_activation_d\": activation_d_array[0],\n                \"output_activation\": activation_array[1],\n                \"output_activation_d\": activation_d_array[1],\n                \"loss_function\": cce,\n                \"loss_function_d\": cce_d\n                }\n\nmlp_object_train_3 = data.MLP(**kwargs_train_3)\n\nepoch_losses_3 = {100: [], 300: [], 500: []}\nepoch_accuracy_3 = {}\n\nbatch_size = 32\nN = train_sample_norm_3.shape[1]\n\nfor n_epochs, losses in epoch_losses_3.items():\n    epoch_accuracy_3[n_epochs] = []\n\nfor epoch in range(n_epochs):\n        epoch_correct = 0\n        epoch_count = 0\n        epoch_loss_accum = 0.0\n\nfor start in range(0, N, batch_size):\n            end = min(start + batch_size, N)\n\nsample_batch = train_sample_norm_3[:, start:end]\n            labels_batch = train_labels_onehot_3[:, start:end]\n\nmlp_object_train_3.input = sample_batch\n            mlp_object_train_3.output = labels_batch\n\nz1_pre_train_3, z1_activation_train_3, z2_pre_train_3, z2_activation_train_3 = mlp_object_train_3.forward(\n            )\n\n# ==============================================================\n            # Armazenando a loss para plotar no gr\u00e1fico depois\n            loss = mlp_object_train_3.loss_calculation(labels_batch,\n                                                    z2_activation_train_3)\n            if np.ndim(loss) &gt; 0:\n                loss = np.mean(loss)\n\nB = end - start\n            epoch_loss_accum += loss * B\n            # ==============================================================\n\n# ==============================================================\n            # Armazenando a acur\u00e1cia do modelo para plotar no gr\u00e1fico depois\n            preds_idx = np.argmax(z2_activation_train_3, axis=0)\n            true_idx = np.argmax(labels_batch, axis=0)\n            epoch_correct += np.sum(preds_idx == true_idx)\n            epoch_count += B\n            # ==============================================================\n\n# ==============================================================\n            # Backpropagation\n            dW1_train_3, db1_train_3, dW2_train_3, db2_train_3 = mlp_object_train_3.backpropagation(\n                z1_pre_train_3, z1_activation_train_3, z2_pre_train_3,\n                z2_activation_train_3)\n            # ==============================================================\n\n# ==============================================================\n            # Ajustando os par\u00e2metros para o pr\u00f3ximo batch\n            W_hidden_train_3, b_hidden_train_3, W_output_train_3, b_output_train_3 = mlp_object_train_3.update_weights(\n                dW1_train_3, db1_train_3, dW2_train_3, db2_train_3)\n            # ==============================================================\n\nepoch_loss = epoch_loss_accum / epoch_count\n        epoch_acc = epoch_correct / epoch_count\n\nlosses.append(epoch_loss)\n        epoch_accuracy_3[n_epochs].append(epoch_acc)\n</code></pre> <p>Dessa vez, fazemos o treinamento em batches como tentativa de aumentar a qualidade do modelo.</p> <ul> <li>Passo 4</li> </ul> Teste <pre><code>kwargs_test_3 = {\n                \"input\": test_sample_norm_3, \n                \"output\": test_sample_labels_3, \n                \"W_hidden\": W_hidden_train_3, \n                \"b_hidden\": b_hidden_train_3, \n                \"W_output\": W_output_train_3, \n                \"b_output\": b_output_train_3, \n                \"eta\": .001, \n                \"hidden_activation\": activation_array[0], \n                \"hidden_activation_d\": activation_d_array[0], \n                \"output_activation\": activation_array[1],\n                \"output_activation_d\": activation_d_array[1], \n                \"loss_function\": cce,\n                \"loss_function_d\": cce_d\n            }\n\nmlp_object_test_3 = data.MLP(**kwargs_test_3)\n\ndef accuracy_from_preds(z2_act, y_true):\n    # z2_act: (M, N), y_true: one-hot (M, N) ou indices (N,)\n    y_pred_idx = np.argmax(z2_act, axis=0)\n    if y_true.ndim == 2:\n        y_true_idx = np.argmax(y_true, axis=0)\n    else:\n        y_true_idx = y_true\n    return np.mean(y_pred_idx == y_true_idx), y_pred_idx, y_true_idx\n\nz1, h1, z2, y_pred_test = mlp_object_test_3.forward()\nacc_test, preds_idx, true_idx = accuracy_from_preds(y_pred_test, test_sample_labels_3) \n</code></pre> <p>A acur\u00e1cia do modelo na amostragem de teste foi de \\(83.58\\%\\).</p>"},{"location":"exs/ex4_vae/main/","title":"VAE","text":"<p>Informa\u00e7\u00f5es da entrega</p> <p>\ud83d\udcc6 26/10/2025</p> <p>\ud83d\udcd6 O enunciado da atividade est\u00e1 dispon\u00edvel neste link.</p> <p>Para importar as bibliotecas necess\u00e1rias, incluir as linhas a seguir no c\u00f3digo.</p> Importando bibliotecas main.py<pre><code>import torch\nimport torch.nn as nn\nfrom torchvision import datasets\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader\nfrom utils import mlp\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom tqdm import tqdm\n</code></pre> <p>A atividade foi feita utilizando uma seed para reprodutibilidade em outros ambientes. Tamb\u00e9m \u00e9 importante selecionar o dispositivo no qual o programa ser\u00e1 executado.</p> Semente manualSele\u00e7\u00e3o do dispositivo main.py<pre><code>gen = torch.manual_seed(42)\n</code></pre> main.py<pre><code>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'-&gt; Using device: {device}')\n</code></pre>"},{"location":"exs/ex4_vae/main/#preparacao-do-dataset","title":"Prepara\u00e7\u00e3o do dataset","text":"<p>Os dados utilizados foram carregados do dataset MNIST, utilizando o framework do <code>PyTorch</code>.</p> <p>Juntamente ao carregamento dos dados, foi feita a divis\u00e3o em datasets para treinamento e teste, contendo \\(60000\\) e \\(10000\\) imagens cada um, respectivamente.</p> Dataset de treinamentoDataset de testes train.py<pre><code>transform = transforms.Compose([transforms.ToTensor()])\n\ntrain_dataset = datasets.MNIST(\n    root=DATA_PATH,\n    train=True,\n    transform=transform,\n    download=True\n)\n</code></pre> test.py<pre><code>transform = transforms.Compose([transforms.ToTensor()])\n\ntest_dataset = datasets.MNIST(\n    root=DATA_PATH,\n    train=False,\n    transform=transform,\n    download=True\n)\n</code></pre> <p>Sendo <code>DATA_PATH</code> o caminho onde os dados ser\u00e3o salvos em sua m\u00e1quina.</p> <p>O argumento <code>transform</code> foi utilizado para fazer com que os dados fossem representados em forma de tensores, ao inv\u00e9s de imagens no formato <code>PIL</code>.</p> <p>Ap\u00f3s o carregamento dos datasets, precisamos fazer com que seja poss\u00edvel fazer itera\u00e7\u00f5es sobre os itens dentro deles. Isso \u00e9 feito utilizando a classe <code>DataLoader</code> do m\u00f3dulo <code>torch.utils.data</code> do PyTorch.</p> Carregando dataset de treinamentoCarregando dataset de testes train.py<pre><code>train_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True\n)\n</code></pre> test.py<pre><code>test_loader = DataLoader(\n    dataset=test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n</code></pre> <p>Visualizando \\(10\\) amostras do dataset, temos:</p> Figura 1: Visualiza\u00e7\u00e3o dos dados"},{"location":"exs/ex4_vae/main/#implementacao-do-modelo","title":"Implementa\u00e7\u00e3o do modelo","text":"<p>A arquitetura do modelo utilizado pode ser representada pela Figura 2.</p> Figura 2: Visualiza\u00e7\u00e3o dos dados Arquitetura do modelo models.py<pre><code>class VAE(nn.Module):\n    def __init__(self, device, input_dim=784, hidden_dim=400, latent_dim=10):\n        super(VAE, self).__init__()\n        self.device = device\n        self.encoder = nn.Sequential(\n            OrderedDict([\n                ('fc1', nn.Linear(input_dim, hidden_dim)),\n                ('relu1', nn.ReLU()),\n                ('fc2', nn.Linear(hidden_dim, latent_dim))\n            ])\n        )\n\n        self.mu_layer = nn.Linear(latent_dim, 2)\n        self.logvar_layer = nn.Linear(latent_dim, 2)\n\n        self.decoder = nn.Sequential(\n            OrderedDict([\n                ('fc1', nn.Linear(2, latent_dim)),\n                ('relu1', nn.ReLU()),\n                ('fc2', nn.Linear(latent_dim, hidden_dim)),\n                ('relu3', nn.ReLU()),\n                ('fc3', nn.Linear(hidden_dim, input_dim)),\n                ('output', nn.Sigmoid())\n            ])\n        )\n\n    def encode(self, x):\n        x = self.encoder(x)\n        mu, logvar = self.mu_layer(x), self.logvar_layer(x)\n        return mu, logvar\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std).to(self.device)\n        return mu + eps * std\n\n    def decode(self, z):\n        return self.decoder(z)\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        x_pred = self.decode(z)\n        return x_pred, mu, logvar\n</code></pre> <p>Nessa arquitetura, temos as seguintes caracter\u00edsticas:</p> <ul> <li> <p>Encoder: a entrada \u00e9 um tensor de tamanho \\(784\\), ou seja, uma imagem do dataset \"achatada\" (\\(28 \\times 28\\)). As informa\u00e7\u00f5es da imagem s\u00e3o ent\u00e3o transferidas para uma camada oculta. Podemos representar a passagem pelo encoder como: \\(784 \\rightarrow 400 \\rightarrow 10 \\rightarrow 2\\);</p> </li> <li> <p>Reparametriza\u00e7\u00e3o: \u00e9 adicionada uma camada para que o truque seja feito corretamente. Essa camada possui 2 dimens\u00f5es;</p> </li> <li> <p>Decoder: a entrada \u00e9 a sa\u00edda do espa\u00e7o latente, ou seja, um tensor com 2 dimens\u00f5es. Essa entrada faz o caminho contr\u00e1rio do encoder, ou seja, \\(2 \\rightarrow 10 \\rightarrow 400 \\rightarrow 784\\). A sa\u00edda \u00e9 uma imagem reconstru\u00edda com base no espa\u00e7o latente.</p> </li> </ul>"},{"location":"exs/ex4_vae/main/#treinamento","title":"Treinamento","text":"<p>Para treinar o modelo, utilizaremos \\(100\\) \u00e9pocas e o otimizador Adam, Binary Cross-Entropy e Kullback Leibler Divergence para fun\u00e7\u00e3o de perda, em adi\u00e7\u00e3o a um batch size de \\(128\\).</p> Vari\u00e1veis para treinamentoFun\u00e7\u00e3o para treinamento train.py<pre><code>vae = models.VAE(device).to(device)\noptimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n\nEPOCHS = 100\nbatch_size = 128\n</code></pre> train.py<pre><code>def train(model, device, train_loader, optimizer, epochs, checkpoint_path=None):\n    model.train()\n    for epoch in range(epochs):\n        train_loss = 0.0\n\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n\n        for _, (data, _) in enumerate(progress_bar):\n            batch_size = data.size(0)\n            data = data.to(device).view(batch_size, -1)\n\n            optimizer.zero_grad()\n\n            x_pred, mu, logvar = model(data)\n            loss = loss_function(data, x_pred, mu, logvar)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * batch_size\n\n            # atualiza descri\u00e7\u00e3o da barra\n            progress_bar.set_postfix(loss=loss.item())\n\n        avg_loss = train_loss / len(train_loader.dataset)\n\n\n        if checkpoint_path:\n            if (epoch + 1) % 10 == 0:\n                checkpoint_path = f\"{CHECKPOINTS_PATH}/vae_epoch_{epoch + 1}.pt\"\n\n                checkpoint = {\n                    'epoch': epoch + 1,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'loss': avg_loss,\n                }\n\n                torch.save(checkpoint, checkpoint_path)\n\n        print(f\"Epoch {epoch + 1}/{epochs} - Average loss: {avg_loss:.6f}\")\n\n    return train_loss\n</code></pre> <p>A fun\u00e7\u00e3o calcula a perda acumulada ao final de cada \u00e9poca e soma em uma vari\u00e1vel <code>train_loss</code>, que ser\u00e1 retornada ap\u00f3s o treinamento ser conclu\u00eddo. Al\u00e9m disso, foram implementadas duas funcionalidades extras:</p> <ul> <li> <p>Visualiza\u00e7\u00e3o gr\u00e1fica atrav\u00e9s de uma barra de progresso;</p> </li> <li> <p>Salvamento peri\u00f3dico em arquivos <code>.pt</code>, denominados checkpoints, que possuem informa\u00e7\u00f5es sobre o modelo em um determinado momento. Por padr\u00e3o, no c\u00f3digo, o per\u00edodo foi de \\(10\\) \u00e9pocas, ou seja, a cada per\u00edodo \u00e9 gerado um arquivo contendo as informa\u00e7\u00f5es do modelo que podem ser recuperadas caso o treinamento seja interrompido.</p> </li> </ul> <p>Podemos ent\u00e3o, realizar o treinamento.</p> train.py<pre><code>total_loss = train(vae, device, train_loader, optimizer, epochs=100, checkpoint_path=CHECKPOINTS_PATH)\n</code></pre>"},{"location":"exs/ex4_vae/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do modelo","text":"<p>Para avaliarmos o modelo, usamos </p>"},{"location":"exs/ex4_vae/main/#visualizacao-do-espaco-latente","title":"Visualiza\u00e7\u00e3o do espa\u00e7o latente","text":"<p>Abaixo, temos visualiza\u00e7\u00f5es do espa\u00e7o latente, tanto em rela\u00e7\u00e3o \u00e0 distribui\u00e7\u00e3o quanto \u00e0s imagens dentro desse espa\u00e7o.</p> Figura 3: Espa\u00e7o latente (distribui\u00e7\u00e3o) Figura 4: Espa\u00e7o latente (imagens)"},{"location":"projs/proj1_classification/main/","title":"Classifica\u00e7\u00e3o","text":"<p>Informa\u00e7\u00f5es da entrega</p> <p>\ud83d\udcc6 05/10/2025</p> <p>\ud83d\udcd6 O enunciado da atividade est\u00e1 dispon\u00edvel neste link.</p>"},{"location":"projs/proj1_classification/main/#integrantes-do-grupo","title":"Integrantes do Grupo","text":"<ul> <li> <p>Carlos Eduardo P. Yamada</p> </li> <li> <p>Pedro De Lucca S. C. Ferro</p> </li> </ul>"},{"location":"projs/proj1_classification/main/#codigo-fonte","title":"C\u00f3digo-fonte","text":"<ul> <li>Notebook de explora\u00e7\u00e3o e modelagem: <code>src/projs/proj1_classification/main.ipynb</code></li> </ul>"},{"location":"projs/proj1_classification/main/#resumo","title":"Resumo","text":"<p>Este projeto implementa uma rede neural Multi-Layer Perceptron (MLP) para classifica\u00e7\u00e3o de alertas de terremotos em quatro categorias: green, yellow, orange e red. O modelo foi treinado utilizando dados s\u00edsmicos que incluem caracter\u00edsticas como magnitude, profundidade, intensidade sentida pela comunidade (CDI), intensidade de danos (MMI) e signific\u00e2ncia do evento.</p>"},{"location":"projs/proj1_classification/main/#fontes-de-dados","title":"Fontes de Dados","text":"<p>Os datasets utilizados neste projeto est\u00e3o dispon\u00edveis no Kaggle:</p> <ul> <li>Earthquake Dataset: https://www.kaggle.com/datasets/warcoder/earthquake-dataset</li> <li>Earthquake Alert Prediction Dataset: https://www.kaggle.com/datasets/ahmeduzaki/earthquake-alert-prediction-dataset</li> </ul>"},{"location":"projs/proj1_classification/main/#objetivos","title":"Objetivos","text":"<ul> <li>Desenvolver um modelo de classifica\u00e7\u00e3o multiclasse para prever o n\u00edvel de alerta de terremotos;</li> <li>Avaliar o desempenho do modelo utilizando m\u00faltiplas m\u00e9tricas (acur\u00e1cia, precis\u00e3o, recall, F1-score);</li> <li>Analisar os padr\u00f5es de erro e limita\u00e7\u00f5es do modelo.</li> </ul>"},{"location":"projs/proj1_classification/main/#dataset","title":"Dataset","text":""},{"location":"projs/proj1_classification/main/#descricao-dos-dados","title":"Descri\u00e7\u00e3o dos Dados","text":"<p>O dataset utilizado \u00e9 uma vers\u00e3o pr\u00e9-processada e otimizada especificamente para aplica\u00e7\u00f5es de machine learning em avalia\u00e7\u00e3o de riscos s\u00edsmicos e sistemas de predi\u00e7\u00e3o de alertas de terremotos. Cont\u00e9m 1300 amostras e 6 colunas, representando registros de eventos s\u00edsmicos com diferentes intensidades e alertas associados.</p> Coluna Tipo Descri\u00e7\u00e3o <code>magnitude</code> Num\u00e9rico (<code>float</code>) Medida da energia liberada pelo terremoto na escala Richter. <code>depth</code> Num\u00e9rico (<code>float</code>) Profundidade do epicentro em quil\u00f4metros. <code>cdi</code> Num\u00e9rico (<code>float</code>) Community Decimal Intensity \u2013 intensidade sentida pela popula\u00e7\u00e3o (escala de 1 a 10). <code>mmi</code> Num\u00e9rico (<code>float</code>) Modified Mercalli Intensity \u2013 intensidade dos danos observados (escala de 1 a 10). <code>sig</code> Num\u00e9rico (<code>float</code>) Signific\u00e2ncia do evento (pontua\u00e7\u00e3o calculada pelo USGS). <code>alert</code> Categ\u00f3rica (<code>string</code>) Target: n\u00edvel de alerta \u2014 <code>green</code>, <code>yellow</code>, <code>orange</code>, ou <code>red</code>."},{"location":"projs/proj1_classification/main/#balanceamento-dos-dados-via-smote","title":"Balanceamento dos Dados via SMOTE","text":"<p>O dataset utilizado foi balanceado utilizando SMOTE (Synthetic Minority Over-sampling Technique), uma t\u00e9cnica avan\u00e7ada de oversampling que gera amostras sint\u00e9ticas para as classes minorit\u00e1rias. Diferente da simples duplica\u00e7\u00e3o de amostras, o SMOTE cria novos exemplos interpolando entre inst\u00e2ncias existentes da classe minorit\u00e1ria, resultando em:</p> <ul> <li>Melhor generaliza\u00e7\u00e3o: O modelo aprende padr\u00f5es mais diversos em vez de memorizar amostras duplicadas;</li> <li>Redu\u00e7\u00e3o de overfitting: Amostras sint\u00e9ticas adicionam variabilidade controlada ao dataset;</li> <li>Distribui\u00e7\u00e3o equilibrada: Todas as classes de alerta possuem aproximadamente o mesmo n\u00famero de amostras.</li> </ul> Figura 1: Distribui\u00e7\u00e3o das classes no conjunto de dados desbalanceado Figura 2: Distribui\u00e7\u00e3o das classes no conjunto de dados balanceado (utilizado no treinamento)"},{"location":"projs/proj1_classification/main/#analise-exploratoria","title":"An\u00e1lise Explorat\u00f3ria","text":"Figura 3: Distribui\u00e7\u00e3o dos atributos num\u00e9ricos do dataset Figura 4: Matriz de correla\u00e7\u00e3o entre as vari\u00e1veis num\u00e9ricas <p>As principais observa\u00e7\u00f5es da an\u00e1lise explorat\u00f3ria incluem: - Forte correla\u00e7\u00e3o entre <code>magnitude</code> e <code>sig</code> (signific\u00e2ncia); - Correla\u00e7\u00e3o moderada entre <code>cdi</code> e <code>mmi</code>; - <code>depth</code> apresenta menor correla\u00e7\u00e3o com outras vari\u00e1veis.</p>"},{"location":"projs/proj1_classification/main/#metodologia","title":"Metodologia","text":""},{"location":"projs/proj1_classification/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<ol> <li>One-hot Encoding: Convers\u00e3o da vari\u00e1vel categ\u00f3rica <code>alert</code> em 4 colunas bin\u00e1rias;</li> <li>Normaliza\u00e7\u00e3o Z-Score: Padroniza\u00e7\u00e3o de todas as features num\u00e9ricas usando m\u00e9dia e desvio padr\u00e3o;</li> <li>Embaralhamento: Randomiza\u00e7\u00e3o das amostras para evitar overfitting por enviesamento;</li> <li>Divis\u00e3o dos dados: \\(70\\%\\) treino, \\(30\\%\\) teste (com <code>random_state=42</code>).</li> </ol>"},{"location":"projs/proj1_classification/main/#arquitetura-do-modelo","title":"Arquitetura do Modelo","text":"<p>Multi-Layer Perceptron (MLP) - Scikit-learn</p> <ul> <li>Camada de entrada: 5 neur\u00f4nios (features normalizadas);</li> <li>Camada oculta: 16 neur\u00f4nios;</li> <li>Camada de sa\u00edda: 4 neur\u00f4nios (classes de alerta);</li> <li>Fun\u00e7\u00e3o de ativa\u00e7\u00e3o: ReLU (camadas ocultas), sigmoide (sa\u00edda);</li> <li>Otimizador: Adam;</li> <li>Learning rate: 0.01;</li> <li>Batch size: 100;</li> <li>\u00c9pocas: 1000.</li> </ul>"},{"location":"projs/proj1_classification/main/#resultados","title":"Resultados","text":""},{"location":"projs/proj1_classification/main/#evolucao-do-treinamento","title":"Evolu\u00e7\u00e3o do Treinamento","text":"Figura 5: Evolu\u00e7\u00e3o da acur\u00e1cia ao longo das 1000 \u00e9pocas de treinamento Figura 6: Matriz de confus\u00e3o dos resultados de teste Figura 7: Compara\u00e7\u00e3o de Precis\u00e3o, Recall e F1-Score por classe de alerta"},{"location":"projs/proj1_classification/main/#metricas-de-performance","title":"M\u00e9tricas de Performance","text":"M\u00e9trica Conjunto de Treino Conjunto de Teste Acur\u00e1cia \\(~80\\%\\) \\(~78\\%\\) Diferen\u00e7a (Overfitting) - \\(~2\\%\\) <p>O modelo apresentou boa generaliza\u00e7\u00e3o, com diferen\u00e7a m\u00ednima entre treino e teste, indicando aus\u00eancia de overfitting significativo.</p>"},{"location":"projs/proj1_classification/main/#erros-mais-significativos","title":"Erros mais significativos","text":"Figura 8: Visualiza\u00e7\u00e3o dos principais erros"},{"location":"projs/proj1_classification/main/#curva-de-perda-durante-o-treinamento","title":"Curva de perda durante o treinamento","text":"Figura 9: Curva de perda durante o treinamento"},{"location":"projs/proj1_classification/main/#comparacao-entre-as-distribuicoes-de-reais-e-preditas","title":"Compara\u00e7\u00e3o entre as distribui\u00e7\u00f5es de reais e preditas","text":"Figura 10: Compara\u00e7\u00e3o entre as distribui\u00e7\u00f5es de reais e preditas"},{"location":"projs/proj1_classification/main/#analise-de-erros","title":"An\u00e1lise de Erros","text":"<p>Os principais tipos de erro do modelo incluem: - Confus\u00e3o entre classes adjacentes (<code>orange</code> \u2194 <code>green</code>, <code>green</code> \u2194 <code>yellow</code>); - Melhor desempenho nas classes extremas (<code>yellow</code> e <code>red</code>); - Maior dificuldade nas classes intermedi\u00e1rias devido \u00e0 sobreposi\u00e7\u00e3o de caracter\u00edsticas.</p>"},{"location":"projs/proj1_classification/main/#distribuicao-das-predicoes","title":"Distribui\u00e7\u00e3o das Predi\u00e7\u00f5es","text":"<p>A distribui\u00e7\u00e3o das predi\u00e7\u00f5es do modelo manteve-se consistente com a distribui\u00e7\u00e3o real das classes no conjunto de teste, indicando que o modelo n\u00e3o apresenta vi\u00e9s significativo em dire\u00e7\u00e3o a nenhuma classe espec\u00edfica.</p>"},{"location":"projs/proj1_classification/main/#discussao","title":"Discuss\u00e3o","text":""},{"location":"projs/proj1_classification/main/#pontos-fortes","title":"Pontos Fortes","text":"<ol> <li>Boa generaliza\u00e7\u00e3o: Diferen\u00e7a m\u00ednima entre acur\u00e1cia de treino e teste (\\(~2\\%\\));</li> <li>Modelo balanceado: N\u00e3o apresenta vi\u00e9s excessivo para nenhuma classe;</li> <li>Converg\u00eancia est\u00e1vel: Curva de perda monotonicamente decrescente;</li> <li>Performance consistente: M\u00e9tricas equilibradas entre precis\u00e3o e recall.</li> </ol>"},{"location":"projs/proj1_classification/main/#limitacoes","title":"Limita\u00e7\u00f5es","text":"<ol> <li>Confus\u00e3o entre classes adjacentes: O modelo tem dificuldade em distinguir alertas de n\u00edveis pr\u00f3ximos;</li> <li>Acur\u00e1cia moderada: \\(~78\\%\\) pode n\u00e3o ser suficiente para aplica\u00e7\u00f5es cr\u00edticas de seguran\u00e7a;</li> <li>Arquitetura simples: Uma \u00fanica camada oculta pode limitar a capacidade de aprender padr\u00f5es complexos.</li> </ol>"},{"location":"projs/proj1_classification/main/#melhorias-possiveis","title":"Melhorias Poss\u00edveis","text":"<ul> <li>Adicionar mais camadas ocultas para aumentar a capacidade representacional;</li> <li>Implementar t\u00e9cnicas de regulariza\u00e7\u00e3o (Dropout, L2);</li> <li>Explorar outras arquiteturas (CNN, LSTM) se houver dados temporais;</li> <li>Aumentar o dataset para melhorar a generaliza\u00e7\u00e3o;</li> <li>Feature engineering: criar vari\u00e1veis derivadas das existentes;</li> <li>Ajuste fino de hiperpar\u00e2metros via Grid Search ou Random Search.</li> </ul>"},{"location":"projs/proj1_classification/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O modelo MLP desenvolvido demonstrou capacidade satisfat\u00f3ria para classifica\u00e7\u00e3o de alertas de terremotos, atingindo \\(~78\\%\\) de acur\u00e1cia no conjunto de teste. A an\u00e1lise detalhada revelou que o modelo funciona melhor para classes extremas (green e red) e apresenta maior confus\u00e3o entre classes adjacentes. </p> <p>Para aplica\u00e7\u00f5es em sistemas de alerta real, recomenda-se: - Priorizar recall para classes cr\u00edticas (red e orange) para minimizar falsos negativos; - Investigar t\u00e9cnicas de ensemble para melhorar a robustez; - Coletar mais dados para as transi\u00e7\u00f5es entre classes.</p>"}]}