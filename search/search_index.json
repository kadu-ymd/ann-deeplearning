{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Template de Entrega","text":""},{"location":"#template-de-entrega","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> <li>Maria Oliveira</li> <li>Grupo K<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"ex1_data/main/","title":"Exerc\u00edcio da aula de Data","text":""},{"location":"ex1_data/main/#exercicio-1","title":"Exerc\u00edcio 1","text":"<p>Os dados foram gerados por um script em Python, apresentado a seguir:</p> main.pyutils.py <pre><code>import matplotlib.pyplot as plt\n\nN = 400\n\ndef main():\n    class_0 = Data(mu=(2,  3), std=(.8,  2.5), n=N)\n    class_1 = Data(mu=(5,  6), std=(1.2, 1.9), n=N)\n    class_2 = Data(mu=(8,  1), std=(.9,   .9), n=N)\n    class_3 = Data(mu=(15, 4), std=(.5,  2.0), n=N)\n\n    x0, y0 = class_0.sample_initialize()\n    x1, y1 = class_1.sample_initialize()\n    x2, y2 = class_2.sample_initialize()\n    x3, y3 = class_3.sample_initialize()\n\n    plt.plot(x0, y0, \"o\", label=\"Classe 0\")\n    plt.plot(x1, y1, \"o\", label=\"Classe 1\")\n    plt.plot(x2, y2, \"o\", label=\"Classe 2\")\n    plt.plot(x3, y3, \"o\", label=\"Classe 3\")\n\n    plt.legend()\n\n    plt.title(\"Plot das classes\")\n\n    plt.show()\n\n    return 0\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>import numpy as np\n\n\nclass Data:\n    def __init__(self, mu, std, n):\n        self.mu_x, self.mu_y = mu\n        self.std_x, self.std_y = std\n        self.n = n\n\n    def sample_initialize(self) -&gt; tuple[np.ndarray, np.ndarray]:\n        return np.random.normal(self.mu_x, self.std_x, self.n), np.random.normal(self.mu_y, self.std_y, self.n)\n\nclass MultiDimensionData:\n    def __init__(self, mu, cov, n):\n        self.mu = mu\n        self.cov = cov\n        self.n = n\n\n    def sample_initialize(self):\n        return np.random.multivariate_normal(self.mu, self.cov, self.n)\n</code></pre> <p>A imagem a seguir mostra o plot dos pontos gerados em para cada uma das classes, diferenciadas pela cor.</p> <p></p> <p>Podemos observar que, principalmente as classes 0 e 1 possuem um grande overlap, que tamb\u00e9m \u00e9 presente entre as classes 1 e 2, de maneira menos gritante. A classe 3 est\u00e1 completamente separada das outras tr\u00eas, quando observada visualmente.</p> <p>Dessa forma, podemos concluir que as classes poderiam ser separadas com linhas, mas que provavelmente existiriam alguns conflitos quanto \u00e0 classifica\u00e7\u00e3o das classes 0 e 1 e das classes 1 e 2.</p> <p>Abaixo segue uma representa\u00e7\u00e3o visual de como as linhas poderiam separar as classes.</p> <p></p>"},{"location":"ex1_data/main/#exercicio-2","title":"Exerc\u00edcio 2","text":"<p>As amostras foram geradas pelo c\u00f3digo apresentado abaixo:</p> main.pyutils.py <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\n\ndef main():\n    mu_A = np.array([0, 0, 0, 0, 0])\n    cov_A = np.array([[1.0, 0.8, 0.1, 0.0, 0.0],\n                    [0.8, 1.0, 0.3, 0.0, 0.0],\n                    [0.1, 0.3, 1.0, 0.5, 0.0],\n                    [0.0, 0.0, 0.5, 1.0, 0.2],\n                    [0.0, 0.0, 0.0, 0.2, 1.0]])\n\n    mu_B = np.array([1.5, 1.5, 1.5, 1.5, 1.5])\n    cov_B = np.array([[ 1.5, -0.7, 0.2, 0.0, 0.0],\n                    [-0.7,  1.5, 0.4, 0.0, 0.0],\n                    [ 0.2,  0.4, 1.5, 0.6, 0.0],\n                    [ 0.0,  0.0, 0.6, 1.5, 0.3],\n                    [ 0.0,  0.0, 0.0, 0.3, 1.5]])\n\n    class_A = MultiDimensionData(mu=mu_A, cov=cov_A, n=500)\n    class_B = MultiDimensionData(mu=mu_B, cov=cov_B, n=500)\n\n    sample_A = class_A.sample_initialize()\n    sample_B = class_B.sample_initialize()\n\n    dataset = np.concatenate((sample_A, sample_B))\n\n    return 0\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>import numpy as np\n\n\nclass Data:\n    def __init__(self, mu, std, n):\n        self.mu_x, self.mu_y = mu\n        self.std_x, self.std_y = std\n        self.n = n\n\n    def sample_initialize(self) -&gt; tuple[np.ndarray, np.ndarray]:\n        return np.random.normal(self.mu_x, self.std_x, self.n), np.random.normal(self.mu_y, self.std_y, self.n)\n\nclass MultiDimensionData:\n    def __init__(self, mu, cov, n):\n        self.mu = mu\n        self.cov = cov\n        self.n = n\n\n    def sample_initialize(self):\n        return np.random.multivariate_normal(self.mu, self.cov, self.n)\n</code></pre> <p>Em seguida, aplicou-se o conceito de PCA (Principal Component Analysis) para reduzir a dimensionalidade dos dados para duas dimens\u00f5es (2D).</p>"},{"location":"ex1_data/main/#passo-a-passo","title":"Passo-a-passo","text":"<p>Ap\u00f3s gerar as amostras (classes A e B), \u00e9 necess\u00e1rio obter a matriz de covari\u00e2ncia dos dados como um todo.</p> <pre><code>mat = np.cov(dataset, rowvar=False)\n</code></pre> <p>Depois disso, precisamos obter os autovalores e os autovetores dessa matriz, sendo que os autovalores servir\u00e3o para auxiliar na defini\u00e7\u00e3o da import\u00e2ncia das features e os autovetores s\u00e3o essenciais para que possamos obter um novo conjunto de amostras, agora apenas com as features selecionadas.</p> <pre><code># Obten\u00e7\u00e3o dos autovalores e autovetores\neigenvalues, eigenvectors = np.linalg.eig(mat)\n\n# Processo feito para ordenar a lista de autovetores e autovalores\n## Obt\u00e9m os \u00edndices que ordenariam o vetor e inverte a lista\nidx = np.argsort(eigenvalues)[::-1]\n\n## Ordena a lista de autovalores\neigenvalues = eigenvalues[idx]\n\n## Ordena a lista de autovetores (colunas)\neigenvectors = eigenvectors[:, idx]\n\n# Obt\u00e9m os dois principais autovetores (para PC1 e PC2)\npcs = eigenvectors[:, :2] # matrix 5x2\n\n# Centralizar o dataset original \ndataset_mu = dataset.mean(axis=0) # matriz 1000x5\ndataset_cent = dataset - dataset_mu\n\n# Obten\u00e7\u00e3o do novo conjunto de dados\nZ = dataset_cent @ pcs # (1000,5) x (5, 2)\n</code></pre> <p>Nota-se que foram realizadas algumas outras etapas antes de obtermos o novo conjunto de amostras, que foram realizadas para que esse conjunto estivesse centralizado.</p> <p>Por fim, podemos plotar o gr\u00e1fico com as duas features selecionadas e separ\u00e1-las de acordo com as respectivas classes.</p> <p></p> <p>De acordo com a imagem, observa-se que os dados da classe B tendem mais a valores negativos, enquanto os da classes A tendem mais a valores positivos.</p> <p>O problema surge pois existe uma grande quantidade de dados que s\u00e3o semelhantes, tornando o uso de modelos simples para classifica\u00e7\u00e3o linear inadequados para classificar as classes. Seria necess\u00e1rio o uso de ferramentas mais robustas como um MLP, que possibilitam uma propaga\u00e7\u00e3o de erro em camadas para que o modelo seja treinado de forma mais eficiente (backpropagation).</p>"},{"location":"ex1_data/main/#exercicio-3","title":"Exerc\u00edcio 3","text":""},{"location":"ex1_data/main/#objetivo-do-dataset","title":"Objetivo do dataset","text":"<p>O dataset apresenta como objetivo prever se um passageiro foi transportado para uma outra dimens\u00e3o durante uma colis\u00e3o da nave espacial Titanic com uma anomalia espa\u00e7o-temporal. Para isso, s\u00e3o disponibilizados dados que foram recuperados dos registros pessoais dos passageiros do sistema da nave.</p>"},{"location":"ex1_data/main/#descricao-das-features","title":"Descri\u00e7\u00e3o das features","text":"<p>Existem 14 features diferentes do dataset a ser analisado. Podemos separ\u00e1-las em num\u00e9ricas e em categ\u00f3ricas, como mostrado a seguir:</p> <ul> <li> <p>Num\u00e9ricas: <code>Age</code>, <code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>;</p> </li> <li> <p>Categ\u00f3ricas: <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Cabin</code>, <code>Destination</code>, <code>VIP</code>, <code>Name</code>, <code>Transported</code>.</p> </li> </ul>"},{"location":"ex1_data/main/#valores-ausentes","title":"Valores ausentes","text":"<p>Podemos observar na imagem abaixo a quantidade de valores nulos por feature.</p> <p></p>"},{"location":"ex1_data/main/#pre-processamento-dos-dados","title":"Pr\u00e9-processamento dos dados","text":"<p>Para cada tipo de feature, os dados faltantes foram tratados de maneiras diferentes:</p> <ul> <li> <p>categ\u00f3ricas (bin\u00e1rias e nominais): foi extra\u00edda a moda da coluna e os valores ausentes foram preenchidos por ela, visto que \u00e9 uma estrat\u00e9gia simples, mas que contorna o problema de impossibilitar o one-hot encoding, por exemplo.</p> </li> <li> <p>num\u00e9ricas: foi extra\u00edda a mediana e os valores ausentes preenchidos por ela, da mesma forma, \u00e9 uma t\u00e9cnica simples que n\u00e3o exige muito tratamento, al\u00e9m de garantir roubstez a outliers, algo que o uso da m\u00e9dia n\u00e3o possibilitaria.</p> </li> </ul> <p>Dessa forma, apesar de o dataset sofrer um leve desbalanceamento, os dados puderam ser mantidos em vez de remover linhas inteiras que contivessem valores nulos, mantendo a integridade da base de dados.</p> <p>Al\u00e9m disso, a feature <code>Cabin</code> foi subdividida em 3 categorias menores: <code>CabinDeck</code>, <code>CabinNum</code> e <code>CabinSide</code>, como \u00e9 descrito no site do Kaggle.</p>"},{"location":"ex1_data/main/#fazendo-one-hot-encoding-de-features-categoricas","title":"Fazendo one-hot encoding de features categ\u00f3ricas","text":"<p>Para features como <code>HomePlanet</code>, <code>Destination</code>, <code>CabinDeck</code> e <code>CabinSide</code> (derivadas da feature <code>Cabin</code>), foi feito one-hot encoding para transform\u00e1-las em vari\u00e1veis categ\u00f3ricas de ordem bin\u00e1ria, sendo uma das etapas para possibilitar a implementa\u00e7\u00e3o de uma rede neural cuja fun\u00e7\u00e3o de ativa\u00e7\u00e3o \u00e9 a tangente hiperb\u00f3lica (\\(tanh(x)\\)).</p>"},{"location":"ex1_data/main/#padronizacao-dos-dados-z-score","title":"Padroniza\u00e7\u00e3o dos dados (z-score)","text":"<p>Em seguida, os dados foram tratados de forma que as features num\u00e9ricas possu\u00edssem m\u00e9dia \\(0\\) (\\(\\mu = 0\\)) e desvio padr\u00e3o \\(1\\) (\\(\\sigma = 0\\)). Essa \u00e9 outra etapa para que seja poss\u00edvel realizar o treinamento da rede neural utilizando a fun\u00e7\u00e3o tanh(x) como fun\u00e7\u00e3o de ativa\u00e7\u00e3o, visto que o dom\u00ednio da fun\u00e7\u00e3o est\u00e1 definido no intervalo \\([-1, 1]\\).</p>"},{"location":"ex1_data/main/#visualizacao-dos-resultados","title":"Visualiza\u00e7\u00e3o dos resultados","text":"<p>O primeiro histograma mostra a compara\u00e7\u00e3o de como era a distribui\u00e7\u00e3o das idades ANTES do tratamento dos dados e como ficou AP\u00d3S o tratamento.</p> <p></p> <p>Podemos observar que a quantidade de pessoas \u00e0 bordo na faixa de 20 anos se mostra maior quando os dados n\u00e3o foram tratados. Ap\u00f3s o tratamento, a faixa muda para 25 anos.</p> <p>Em seguida, temos a compara\u00e7\u00e3o para duas vari\u00e1veis semelhantes, que abordam os gastos na pra\u00e7a de alimenta\u00e7\u00e3o da nave e com servi\u00e7os de quarto, respectivamente.</p> <p></p> <p></p> <p>Conseguimos, a partir dos gr\u00e1ficos, concluir que no caso dessas duas vari\u00e1veis, n\u00e3o houverem mudan\u00e7as significativas, uma vez que boa parte dos passageiros n\u00e3o gastou com esses dois servi\u00e7os.</p>"},{"location":"projeto/main/","title":"Main","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"roteiro1/main/","title":"Main","text":""},{"location":"roteiro1/main/#objetivo","title":"Objetivo","text":"<p>Aqui vai o objetivo macro do roteiro. Por que estamos fazendo o que estamos fazendo?</p>"},{"location":"roteiro1/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Os pontos \"tarefas\" s\u00e3o os passos que devem ser seguidos para a realiza\u00e7\u00e3o do roteiro. Eles devem ser claros e objetivos. Com evid\u00eancias claras de que foram realizados.</p>"},{"location":"roteiro1/main/#tarefa-1","title":"Tarefa 1","text":"<p>Instalando o MAAS:</p> sudo snap install maas --channel=3.5/Stable <p></p> <p>Dashboard do MAAS</p> <p>Conforme ilustrado acima, a tela inicial do MAAS apresenta um dashboard com informa\u00e7\u00f5es sobre o estado atual dos servidores gerenciados. O dashboard \u00e9 composto por diversos pain\u00e9is, cada um exibindo informa\u00e7\u00f5es sobre um aspecto espec\u00edfico do ambiente gerenciado. Os pain\u00e9is podem ser configurados e personalizados de acordo com as necessidades do usu\u00e1rio.</p>"},{"location":"roteiro1/main/#tarefa-2","title":"Tarefa 2","text":""},{"location":"roteiro1/main/#app","title":"App","text":""},{"location":"roteiro1/main/#tarefa-1_1","title":"Tarefa 1","text":""},{"location":"roteiro1/main/#tarefa-2_1","title":"Tarefa 2","text":"<p>Exemplo de diagrama</p> <pre><code>architecture-beta\n    group api(cloud)[API]\n\n    service db(database)[Database] in api\n    service disk1(disk)[Storage] in api\n    service disk2(disk)[Storage] in api\n    service server(server)[Server] in api\n\n    db:L -- R:server\n    disk1:T -- B:server\n    disk2:T -- B:db</code></pre> <p>Mermaid</p>"},{"location":"roteiro1/main/#questionario-projeto-ou-plano","title":"Question\u00e1rio, Projeto ou Plano","text":"<p>Esse se\u00e7\u00e3o deve ser preenchida apenas se houver demanda do roteiro.</p>"},{"location":"roteiro1/main/#discussoes","title":"Discuss\u00f5es","text":"<p>Quais as dificuldades encontradas? O que foi mais f\u00e1cil? O que foi mais dif\u00edcil?</p>"},{"location":"roteiro1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O que foi poss\u00edvel concluir com a realiza\u00e7\u00e3o do roteiro?</p>"},{"location":"roteiro2/main/","title":"Main","text":""},{"location":"roteiro2/main/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<pre><code>classDiagram\n    class Conta {\n        - String id\n        # double saldo\n        - Cliente cliente\n        + sacar(double valor)\n        + depositar(double valor)\n    }\n    class Cliente {\n        - String id\n        - String nome\n        - List&lt;Conta&gt; contas\n    }\n    class PessoaFisica {\n        - String cpf\n    }\n    class PessoaJuridica {\n        - String cnpj\n    }\n    class ContaCorrente {\n        - double limite\n        + sacar(double valor)\n    }\n    class ContaPoupanca {\n        + sacar(double valor)\n    }\n    Conta *-- Cliente\n    Conta &lt;|-- ContaCorrente\n    Conta &lt;|-- ContaPoupanca\n    Cliente &lt;|-- PessoaFisica\n    Cliente &lt;|-- PessoaJuridica</code></pre>"},{"location":"roteiro2/main/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre>"},{"location":"roteiro3/main/","title":"Main","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> </p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> <p></p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"roteiro4/main/","title":"Main","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> 2025-09-05T22:37:53.569761 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>Traceback (most recent call last):\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\curl_cffi\\requests\\session.py\", line 640, in request\n    c.perform()\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\curl_cffi\\curl.py\", line 365, in perform\n    self._check_error(ret, \"perform\")\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\curl_cffi\\curl.py\", line 187, in _check_error\n    raise error\ncurl_cffi.curl.CurlError: Failed to perform, curl: (77) error setting certificate verify locations:  CAfile: C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\certifi\\cacert.pem CApath: none. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\markdown_exec\\_internal\\formatters\\python.py\", line 71, in _run_python\n    exec_python(code, code_block_id, exec_globals)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\markdown_exec\\_internal\\formatters\\_exec_python.py\", line 8, in exec_python\n    exec(compiled, exec_globals)  # noqa: S102\n  File \"&lt;code block: n2&gt;\", line 15, in &lt;module&gt;\n    data = info.history(period='2y')\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\utils.py\", line 92, in wrapper\n    result = func(*args, **kwargs)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\base.py\", line 101, in history\n    return self._lazy_load_price_history().history(*args, **kwargs)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\base.py\", line 107, in _lazy_load_price_history\n    self._price_history = PriceHistory(self._data, self.ticker, self._get_ticker_tz(timeout=10))\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\base.py\", line 132, in _get_ticker_tz\n    if k in self.info:\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\ticker.py\", line 163, in info\n    return self.get_info()\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\base.py\", line 298, in get_info\n    data = self._quote.info\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\scrapers\\quote.py\", line 511, in info\n    self._fetch_info()\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\scrapers\\quote.py\", line 610, in _fetch_info\n    result = self._fetch(modules=modules)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\scrapers\\quote.py\", line 590, in _fetch\n    result = self._data.get_raw_json(_QUOTE_SUMMARY_URL_ + f\"/{self._symbol}\", params=params_dict)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\data.py\", line 432, in get_raw_json\n    response = self.get(url, params=params, timeout=timeout)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\utils.py\", line 92, in wrapper\n    result = func(*args, **kwargs)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\data.py\", line 370, in get\n    return self._make_request(url, request_method = self._session.get, params=params, timeout=timeout)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\utils.py\", line 92, in wrapper\n    result = func(*args, **kwargs)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\data.py\", line 391, in _make_request\n    crumb, strategy = self._get_cookie_and_crumb()\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\utils.py\", line 92, in wrapper\n    result = func(*args, **kwargs)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\data.py\", line 360, in _get_cookie_and_crumb\n    crumb = self._get_cookie_and_crumb_basic(timeout)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\utils.py\", line 92, in wrapper\n    result = func(*args, **kwargs)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\data.py\", line 239, in _get_cookie_and_crumb_basic\n    if not self._get_cookie_basic(timeout):\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\utils.py\", line 92, in wrapper\n    result = func(*args, **kwargs)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\yfinance\\data.py\", line 196, in _get_cookie_basic\n    self._session.get(\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\curl_cffi\\requests\\session.py\", line 661, in get\n    return self.request(method=\"GET\", url=url, **kwargs)\n  File \"C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\curl_cffi\\requests\\session.py\", line 647, in request\n    raise error(str(e), e.code, rsp) from e\ncurl_cffi.requests.exceptions.SSLError: Failed to perform, curl: (77) error setting certificate verify locations:  CAfile: C:\\Users\\Kadu\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\\u00c1rea de Trabalho\\geral\\insper_engcomp\\25_2\\redes_neurais\\ann-deeplearning\\env\\lib\\site-packages\\certifi\\cacert.pem CApath: none. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.\n</code></pre> <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"},{"location":"thisdocumentation/main/","title":"Main","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}