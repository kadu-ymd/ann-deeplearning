{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#ann-e-deep-learning","title":"ANN e Deep Learning","text":"<p>Turma</p> <p> 2025.2</p>"},{"location":"#entregas","title":"Entregas","text":"Exerc\u00edcios <ul> <li> Data - Prazo 05/09/2025</li> <li> Perceptron - Prazo 14/09/2025</li> <li> MLP - Prazo 21/09/2025</li> <li> VAE - Prazo 26/10/2025</li> </ul> Projetos <ul> <li> Classifica\u00e7\u00e3o - Prazo 05/10/2025</li> <li> Regress\u00e3o - Prazo 26/10/2025</li> <li> Generative Models - Prazo --/--/2025</li> </ul>"},{"location":"exs/ex1_data/main/","title":"Data","text":"<p>Informa\u00e7\u00f5es da entrega</p> <p>\ud83d\udcc6 Deadline: 05/09/2025</p> <p>\ud83d\udcd6 O enunciado da atividade est\u00e1 dispon\u00edvel neste link.</p>"},{"location":"exs/ex1_data/main/#exercicio-1","title":"Exerc\u00edcio 1","text":"<p>Os dados foram gerados por um script em Python, apresentado a seguir:</p> main.pyutils.py <pre><code>import matplotlib.pyplot as plt\n\nN = 400\n\ndef main():\n    class_0 = Data(mu=(2,  3), std=(.8,  2.5), n=N)\n    class_1 = Data(mu=(5,  6), std=(1.2, 1.9), n=N)\n    class_2 = Data(mu=(8,  1), std=(.9,   .9), n=N)\n    class_3 = Data(mu=(15, 4), std=(.5,  2.0), n=N)\n\nx0, y0 = class_0.sample_initialize()\n    x1, y1 = class_1.sample_initialize()\n    x2, y2 = class_2.sample_initialize()\n    x3, y3 = class_3.sample_initialize()\n\nplt.plot(x0, y0, \"o\", label=\"Classe 0\")\n    plt.plot(x1, y1, \"o\", label=\"Classe 1\")\n    plt.plot(x2, y2, \"o\", label=\"Classe 2\")\n    plt.plot(x3, y3, \"o\", label=\"Classe 3\")\n\nplt.legend()\n\nplt.title(\"Plot das classes\")\n\nplt.show()\n\nreturn 0\n\nif__name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>import numpy as np\n\nclass Data:\n    def__init__(self, mu, std, n):\n        self.mu_x, self.mu_y = mu\n        self.std_x, self.std_y = std\n        self.n = n\n\ndef sample_initialize(self) -&gt; tuple[np.ndarray, np.ndarray]:\n        return np.random.normal(self.mu_x, self.std_x, self.n), np.random.normal(self.mu_y, self.std_y, self.n)\n\nclass MultiDimensionData:\n    def__init__(self, mu, cov, n):\n        self.mu = mu\n        self.cov = cov\n        self.n = n\n\ndef sample_initialize(self):\n        return np.random.multivariate_normal(self.mu, self.cov, self.n)\n</code></pre> <p>A imagem a seguir mostra o plot dos pontos gerados em para cada uma das classes, diferenciadas pela cor.</p> <p></p> <p>Podemos observar que, principalmente as classes 0 e 1 possuem um grande overlap, que tamb\u00e9m \u00e9 presente entre as classes 1 e 2, de maneira menos gritante. A classe 3 est\u00e1 completamente separada das outras tr\u00eas, quando observada visualmente.</p> <p>Dessa forma, podemos concluir que as classes poderiam ser separadas com linhas, mas que provavelmente existiriam alguns conflitos quanto \u00e0 classifica\u00e7\u00e3o das classes 0 e 1 e das classes 1 e 2.</p> <p>Abaixo segue uma representa\u00e7\u00e3o visual de como as linhas poderiam separar as classes.</p> <p></p>"},{"location":"exs/ex1_data/main/#exercicio-2","title":"Exerc\u00edcio 2","text":"<p>As amostras foram geradas pelo c\u00f3digo apresentado abaixo:</p> main.pyutils.py <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\ndef main():\n    mu_A = np.array([0, 0, 0, 0, 0])\n    cov_A = np.array([[1.0, 0.8, 0.1, 0.0, 0.0],\n                    [0.8, 1.0, 0.3, 0.0, 0.0],\n                    [0.1, 0.3, 1.0, 0.5, 0.0],\n                    [0.0, 0.0, 0.5, 1.0, 0.2],\n                    [0.0, 0.0, 0.0, 0.2, 1.0]])\n\nmu_B = np.array([1.5, 1.5, 1.5, 1.5, 1.5])\n    cov_B = np.array([[ 1.5, -0.7, 0.2, 0.0, 0.0],\n                    [-0.7,  1.5, 0.4, 0.0, 0.0],\n                    [ 0.2,  0.4, 1.5, 0.6, 0.0],\n                    [ 0.0,  0.0, 0.6, 1.5, 0.3],\n                    [ 0.0,  0.0, 0.0, 0.3, 1.5]])\n\nclass_A = MultiDimensionData(mu=mu_A, cov=cov_A, n=500)\n    class_B = MultiDimensionData(mu=mu_B, cov=cov_B, n=500)\n\nsample_A = class_A.sample_initialize()\n    sample_B = class_B.sample_initialize()\n\ndataset = np.concatenate((sample_A, sample_B))\n\nreturn 0\n\nif__name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>import numpy as np\n\nclass Data:\n    def__init__(self, mu, std, n):\n        self.mu_x, self.mu_y = mu\n        self.std_x, self.std_y = std\n        self.n = n\n\ndef sample_initialize(self) -&gt; tuple[np.ndarray, np.ndarray]:\n        return np.random.normal(self.mu_x, self.std_x, self.n), np.random.normal(self.mu_y, self.std_y, self.n)\n\nclass MultiDimensionData:\n    def__init__(self, mu, cov, n):\n        self.mu = mu\n        self.cov = cov\n        self.n = n\n\ndef sample_initialize(self):\n        return np.random.multivariate_normal(self.mu, self.cov, self.n)\n</code></pre> <p>Em seguida, aplicou-se o conceito de PCA (Principal Component Analysis) para reduzir a dimensionalidade dos dados para duas dimens\u00f5es (2D).</p>"},{"location":"exs/ex1_data/main/#passo-a-passo","title":"Passo-a-passo","text":"<p>Ap\u00f3s gerar as amostras (classes A e B), \u00e9 necess\u00e1rio obter a matriz de covari\u00e2ncia dos dados como um todo.</p> <pre><code>mat = np.cov(dataset, rowvar=False)\n</code></pre> <p>Depois disso, precisamos obter os autovalores e os autovetores dessa matriz, sendo que os autovalores servir\u00e3o para auxiliar na defini\u00e7\u00e3o da import\u00e2ncia das features e os autovetores s\u00e3o essenciais para que possamos obter um novo conjunto de amostras, agora apenas com as features selecionadas.</p> <pre><code># Obten\u00e7\u00e3o dos autovalores e autovetores\neigenvalues, eigenvectors = np.linalg.eig(mat)\n\n# Processo feito para ordenar a lista de autovetores e autovalores\n## Obt\u00e9m os \u00edndices que ordenariam o vetor e inverte a lista\nidx = np.argsort(eigenvalues)[::-1]\n\n## Ordena a lista de autovalores\neigenvalues = eigenvalues[idx]\n\n## Ordena a lista de autovetores (colunas)\neigenvectors = eigenvectors[:, idx]\n\n# Obt\u00e9m os dois principais autovetores (para PC1 e PC2)\npcs = eigenvectors[:, :2] # matrix 5x2\n\n# Centralizar o dataset original \ndataset_mu = dataset.mean(axis=0) # matriz 1000x5\ndataset_cent = dataset - dataset_mu\n\n# Obten\u00e7\u00e3o do novo conjunto de dados\nZ = dataset_cent @ pcs # (1000,5) x (5, 2)\n</code></pre> <p>Nota-se que foram realizadas algumas outras etapas antes de obtermos o novo conjunto de amostras, que foram realizadas para que esse conjunto estivesse centralizado.</p> <p>Por fim, podemos plotar o gr\u00e1fico com as duas features selecionadas e separ\u00e1-las de acordo com as respectivas classes.</p> <p></p> <p>De acordo com a imagem, observa-se que os dados da classe B tendem mais a valores negativos, enquanto os da classes A tendem mais a valores positivos.</p> <p>O problema surge pois existe uma grande quantidade de dados que s\u00e3o semelhantes, tornando o uso de modelos simples para classifica\u00e7\u00e3o linear inadequados para classificar as classes. Seria necess\u00e1rio o uso de ferramentas mais robustas como um MLP, que possibilitam uma propaga\u00e7\u00e3o de erro em camadas para que o modelo seja treinado de forma mais eficiente (backpropagation).</p>"},{"location":"exs/ex1_data/main/#exercicio-3","title":"Exerc\u00edcio 3","text":""},{"location":"exs/ex1_data/main/#objetivo-do-dataset","title":"Objetivo do dataset","text":"<p>O dataset apresenta como objetivo prever se um passageiro foi transportado para uma outra dimens\u00e3o durante uma colis\u00e3o da nave espacial Titanic com uma anomalia espa\u00e7o-temporal. Para isso, s\u00e3o disponibilizados dados que foram recuperados dos registros pessoais dos passageiros do sistema da nave.</p>"},{"location":"exs/ex1_data/main/#descricao-das-features","title":"Descri\u00e7\u00e3o das features","text":"<p>Existem 14 features diferentes do dataset a ser analisado. Podemos separ\u00e1-las em num\u00e9ricas e em categ\u00f3ricas, como mostrado a seguir:</p> <ul> <li>Num\u00e9ricas: <code>Age</code>, <code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>;</li> <li>Categ\u00f3ricas: <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Cabin</code>, <code>Destination</code>, <code>VIP</code>, <code>Name</code>, <code>Transported</code>.</li> </ul>"},{"location":"exs/ex1_data/main/#valores-ausentes","title":"Valores ausentes","text":"<p>Podemos observar na imagem abaixo a quantidade de valores nulos por feature.</p> <p></p>"},{"location":"exs/ex1_data/main/#pre-processamento-dos-dados","title":"Pr\u00e9-processamento dos dados","text":"<p>Para cada tipo de feature, os dados faltantes foram tratados de maneiras diferentes:</p> <ul> <li>categ\u00f3ricas (bin\u00e1rias e nominais): foi extra\u00edda a moda da coluna e os valores ausentes foram preenchidos por ela, visto que \u00e9 uma estrat\u00e9gia simples, mas que contorna o problema de impossibilitar o one-hot encoding, por exemplo.</li> <li>num\u00e9ricas: foi extra\u00edda a mediana e os valores ausentes preenchidos por ela, da mesma forma, \u00e9 uma t\u00e9cnica simples que n\u00e3o exige muito tratamento, al\u00e9m de garantir roubstez a outliers, algo que o uso da m\u00e9dia n\u00e3o possibilitaria.</li> </ul> <p>Dessa forma, apesar de o dataset sofrer um leve desbalanceamento, os dados puderam ser mantidos em vez de remover linhas inteiras que contivessem valores nulos, mantendo a integridade da base de dados.</p> <p>Al\u00e9m disso, a feature <code>Cabin</code> foi subdividida em 3 categorias menores: <code>CabinDeck</code>, <code>CabinNum</code> e <code>CabinSide</code>, como \u00e9 descrito no site do Kaggle.</p>"},{"location":"exs/ex1_data/main/#fazendo-one-hot-encoding-de-features-categoricas","title":"Fazendo one-hot encoding de features categ\u00f3ricas","text":"<p>Para features como <code>HomePlanet</code>, <code>Destination</code>, <code>CabinDeck</code> e <code>CabinSide</code> (derivadas da feature <code>Cabin</code>), foi feito one-hot encoding para transform\u00e1-las em vari\u00e1veis categ\u00f3ricas de ordem bin\u00e1ria, sendo uma das etapas para possibilitar a implementa\u00e7\u00e3o de uma rede neural cuja fun\u00e7\u00e3o de ativa\u00e7\u00e3o \u00e9 a tangente hiperb\u00f3lica (\\(tanh(x)\\)).</p>"},{"location":"exs/ex1_data/main/#padronizacao-dos-dados-z-score","title":"Padroniza\u00e7\u00e3o dos dados (z-score)","text":"<p>Em seguida, os dados foram tratados de forma que as features num\u00e9ricas possu\u00edssem m\u00e9dia \\(0\\) (\\(\\mu = 0\\)) e desvio padr\u00e3o \\(1\\) (\\(\\sigma = 0\\)). Essa \u00e9 outra etapa para que seja poss\u00edvel realizar o treinamento da rede neural utilizando a fun\u00e7\u00e3o tanh(x) como fun\u00e7\u00e3o de ativa\u00e7\u00e3o, visto que o dom\u00ednio da fun\u00e7\u00e3o est\u00e1 definido no intervalo \\([-1, 1]\\).</p>"},{"location":"exs/ex1_data/main/#visualizacao-dos-resultados","title":"Visualiza\u00e7\u00e3o dos resultados","text":"<p>O primeiro histograma mostra a compara\u00e7\u00e3o de como era a distribui\u00e7\u00e3o das idades ANTES do tratamento dos dados e como ficou AP\u00d3S o tratamento.</p> <p></p> <p>Podemos observar que a quantidade de pessoas \u00e0 bordo na faixa de 20 anos se mostra maior quando os dados n\u00e3o foram tratados. Ap\u00f3s o tratamento, a faixa muda para 25 anos.</p> <p>Em seguida, temos a compara\u00e7\u00e3o para duas vari\u00e1veis semelhantes, que abordam os gastos na pra\u00e7a de alimenta\u00e7\u00e3o da nave e com servi\u00e7os de quarto, respectivamente.</p> <p></p> <p></p> <p>Conseguimos, a partir dos gr\u00e1ficos, concluir que no caso dessas duas vari\u00e1veis, n\u00e3o houverem mudan\u00e7as significativas, uma vez que boa parte dos passageiros n\u00e3o gastou com esses dois servi\u00e7os.</p>"},{"location":"exs/ex2_perceptron/main/","title":"Perceptron","text":"<p>Informa\u00e7\u00f5es da entrega</p> <p>\ud83d\udcc6 Deadline: 14/09/2025</p> <p>\ud83d\udcd6 O enunciado da atividade est\u00e1 dispon\u00edvel neste link.</p> <p>Para trabalhar nos exerc\u00edcios, foi feita um arquivo de utilidades (<code>./utils/data.py</code>) com algumas fun\u00e7\u00f5es comuns que foram utilizadas em outras situa\u00e7\u00f5es tamb\u00e9m.</p> data.py<pre><code>import numpy as np\n\nclass Data:\n    def __init__(self, mu, std, n):\n        self.mu_x, self.mu_y = mu\n        self.std_x, self.std_y = std\n        self.n = n\n\n    def sample_initialize(self) -&gt; tuple[np.ndarray, np.ndarray]:\n        return np.random.normal(self.mu_x, self.std_x, self.n), np.random.normal(self.mu_y, self.std_y, self.n)\n\nclass MultiDimensionData:\n    def __init__(self, mu: list, cov: list, n: int):\n        self.mu = np.array(mu)\n        self.cov = np.array(cov)\n        self.n = n\n\n    def sample_initialize(self):\n        return np.random.multivariate_normal(self.mu, self.cov, self.n)\n</code></pre> <p>E importamos isso no arquivo de execu\u00e7\u00e3o do c\u00f3digo.</p> <pre><code>from utils import data\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\n</code></pre>"},{"location":"exs/ex2_perceptron/main/#geracao-de-dados","title":"Gera\u00e7\u00e3o de dados","text":"<p>Foram geradas 2000 amostras de dados, utilizando uma distribui\u00e7\u00e3o normal (Gaussiana) multivariada, sendo que metade dos dados fazem parte de uma classe e a outra metade de outra (denominadas classes 0 e 1)</p> <pre><code>class_0 = data.MultiDimensionData(mu=[mu1, mu2],\n                                  cov=[[cov11, cov12], [cov21, cov22]],\n                                  n=N)\n\nclass_1 = data.MultiDimensionData(mu=[mu1, mu2],\n                                  cov=[[cov11, cov12], [cov21, cov22]],\n                                  n=N)\n\nfeatures = np.concatenate((class_0.sample_initialize(), class_1.sample_initialize()))\n\nlabels = np.concatenate((np.zeros(N, dtype=int), np.ones(N, dtype=int)))\n\nshuffled_features, shuffled_labels = shuffle_sample(sample_array=features, labels_array=labels)\n</code></pre> <p>sendo <code>N = 1000</code>.</p> <p>Foram utilizados diferentes valores para m\u00e9dia e covari\u00e2ncia para cada um dos exerc\u00edcios, disponibilizados no link com o enunciado do exerc\u00edcio.</p> <p>Tamb\u00e9m precisamos levar em conta que os dados foram embaralhados para evitar enviesamento durante o treinamento do modelo.</p> <p>Para fins pr\u00e1ticos, iremos referenci\u00e1-los aqui como linearmente separ\u00e1veis (i - exerc\u00edcio 1) e sobrepostos (ii - exerc\u00edcio 2).</p> <p>O plot dos gr\u00e1ficos para (i) e (ii) se encontra abaixo, respectivamente.</p> Figura 1 - Amostragem com dados linearmente separados Figura 2 - Amostragem com dados sobrepostos"},{"location":"exs/ex2_perceptron/main/#implementacao-do-perceptron","title":"Implementa\u00e7\u00e3o do perceptron","text":"<p>Foram definidas algumas fun\u00e7\u00f5es que foram utilizadas para o perceptron.</p> Shuffle <pre><code>def shuffle_sample(sample_array, labels_array):\n    lista = list(zip(sample_array, labels_array))\n    random.shuffle(lista)\n\n    features, labels = zip(*lista)\n    return np.array(features), np.array(labels)\n</code></pre> M\u00e9tricas <pre><code>def confusion_matrix(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    VP = np.sum((y_true == 1) &amp; (y_pred == 1))  # verdadeiros positivos\n    VN = np.sum((y_true == 0) &amp; (y_pred == 0))  # verdadeiros negativos\n    FP = np.sum((y_true == 0) &amp; (y_pred == 1))  # falsos positivos\n    FN = np.sum((y_true == 1) &amp; (y_pred == 0))  # falsos negativos\n\n    return np.array([[VN, FP],\n                     [FN, VP]])\n\ndef accuracy(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    return np.mean(y_true == y_pred)\n</code></pre> Processamento <pre><code>def forward(x, y, activation, n_epochs, eta=.01):\n    W = np.array([[0, 0]])\n    b = 0\n\n    acc_array = []\n    total_epochs = 0\n\n    for i in range(n_epochs):\n        print(f\"[epoch {i+1}] Starting...\")\n\n        total_epochs = i+1\n        y_pred_vec = []\n        updated = 0\n\n        for j in range(x.shape[0]):\n            z = np.dot(W, x[j].T) + b\n\n            y_pred = activation(z)\n\n            y_pred_vec.append(y_pred)\n\n            error = y[j] - y_pred\n\n            if error != 0:\n                updated += 1\n                W = W + eta * error * x[j]\n                b = b + eta * error\n\n        acc = accuracy(y, y_pred_vec)\n        acc_array.append(acc)\n\n        print(f\"- Accuracy: {acc}\")\n\n        if not updated:\n            print(f\"- No updates detected...\")\n\n            break\n\n    print(f\"Training finished after {total_epochs} epochs.\")\n    return W, b, y_pred_vec\n</code></pre> <p>No exerc\u00edcio 1, como esperado, o modelo converge ap\u00f3s algumas \u00e9pocas (menos que 100), visto que os dados s\u00e3o linearmente separ\u00e1veis.</p> <p>O gr\u00e1fico abaixo mostra a linha de separa\u00e7\u00e3o entre as classes, calculada com base nos pesos e no bias obtidos pelo forward pass ap\u00f3s o treinamento.</p> Figura 3 - Linha de separa\u00e7\u00e3o para a amostra (i) <p>Em seguida, calculamos para os dados sobrepostos, em que o esperado era que o modelo n\u00e3o fosse capaz de convergir, visto que precisamos de um modelo mais complexo (por exemplo, MLP ou SVM) para separar os dados de forma mais correta. Ao rodar o c\u00f3digo, foi obtida uma acur\u00e1cia de aproximadamente \\(60\\%\\), e a linha de decis\u00e3o pode ser vista na imagem abaixo.</p> Figura 4 - Linha de separa\u00e7\u00e3o para a amostra (ii)"},{"location":"exs/ex3_mlp/main/","title":"MLP","text":"<p>Informa\u00e7\u00f5es da entrega</p> <p>\ud83d\udcc6 Deadline: 21/09/2025</p> <p>\ud83d\udcd6 O enunciado da atividade est\u00e1 dispon\u00edvel neste link.</p> <p>Para essa atividade, uma sequ\u00eancia de passos foi seguida a fim de garantir a execu\u00e7\u00e3o correta do MLP:</p> <ol> <li> <p>Inicializa\u00e7\u00e3o da amostra;</p> </li> <li> <p>Amostragem (\\(x\\)): \\(n_{features} \\times n_{amostras}\\)</p> </li> <li>R\u00f3tulos (\\(y\\)): \\(n_{outputs} \\times n_{amostras}\\)</li> <li> <p>Defini\u00e7\u00e3o de hiperpar\u00e2metros para o treinamento do modelo;</p> </li> <li> <p>Pesos da camada oculta: (\\(W^{(1)}\\)) \\(n_{features} \\times n_{neur\u00f4nios}\\)</p> </li> <li>Bias da camada oculta(\\(b^{(1)}\\)): \\(n_{neur\u00f4nios} \\times n_{amostras}\\)</li> <li>Pesos da camada de sa\u00edda (\\(W^{(2)}\\)): \\(n_{neur\u00f4nios} \\times n_{sa\u00eddas}\\)</li> <li>Bias da camada de sa\u00edda (\\(b^{(2)}\\)): \\(n_{sa\u00eddas} \\times n_{amostras}\\)</li> <li> <p>Fun\u00e7\u00e3o de ativa\u00e7\u00e3o: \\(f(x)\\)</p> </li> <li> <p>Derivada da fun\u00e7\u00e3o de ativa\u00e7\u00e3o: \\(f'(x)\\)</p> </li> <li>Fun\u00e7\u00e3o de perda: \\(\\mathcal{L}\\)</li> <li>Treino;</li> <li>Teste.</li> </ol>"},{"location":"exs/ex3_mlp/main/#exercicio-1-calculo-manual-das-etapas-para-um-multi-layer-perceptron-mlp","title":"Exerc\u00edcio 1: C\u00e1lculo manual das etapas para um Multi-Layer Perceptron (MLP)","text":"<ul> <li>Passo 1</li> </ul> Inicializa\u00e7\u00e3o da amostra <p><code>{ .py title=main.py }     samples_1 = np.array([[0.5, -0.2]]).T   # n_features X n_samples      labels_1 = np.array([[1]])              # n_outputs X n_samples</code></p> <ul> <li>Passo 2</li> </ul> Defini\u00e7\u00e3o de hiperpar\u00e2metros main.py<pre><code>W1_1 = np.array([[0.3, 0.2], [-0.1, 0.4]])  # n_features X n_neurons\nb1_1 = np.array([[0.1], [-0.2]])            # n_neurons X n_samples\n\nW2_1 = np.array([[0.5], [-0.3]])            # n_neurons X n_outputs\nb2_1 = np.array([[0.2]])                    # n_outputs X n_samples\n\nactivation_function_1 = lambda x: (np.exp(2 * x) - 1) / (np.exp(2 * x) + 1)\nactivation_function_1_derivative = lambda x: 1 - (activation_function_1(x)**2)\n\nloss_function_1 = lambda y, y_pred: 0.5 * (y - y_pred)**2\nloss_function_1_derivative = lambda y, y_pred: y - y_pred\n</code></pre> <p>Foi utilizada, conforme o enunciado do exerc\u00edcio, a fun\u00e7\u00e3o de perda Mean Squared Error (MSE) e a fun\u00e7\u00e3o de ativa\u00e7\u00e3o \\(tanh(x)\\).</p> <ul> <li>Passo 3</li> </ul> TreinamentoClasse main.py<pre><code>kwargs_1 = {\n            \"input\": samples_1,\n            \"output\": labels_1,\n            \"W_hidden\": W1_1,\n            \"b_hidden\": b1_1,\n            \"W_output\": W2_1,\n            \"b_output\": b2_1,\n            \"eta\": eta_1,\n            \"hidden_activation\": activation_function_1,\n            \"hidden_activation_d\": activation_function_1_derivative,\n            \"output_activation\": activation_function_1,\n            \"output_activation_d\": activation_function_1_derivative,\n            \"loss_function\": loss_function_1,\n            \"loss_function_d\": loss_function_1_derivative\n        }\n\nmlp_data_train_1 = data.MLP(**kwargs_1)\n\nz1, h1, z2, y_pred = mlp_data_train_1.forward()\n\nloss = mlp_data_train_1.loss_calculation(labels_1, y_pred)\n\ndW1_1, db1_1, dW2_1, db2_1 = mlp_data_train_1.backpropagation(z1, h1, z2, y_pred)\n\nW_hidden, b_hidden, W_output, b_output = mlp_data_train_1.update_weights(dW1_1, db1_1, dW2_1, db2_1)\n</code></pre> models.py<pre><code>class MLP:\n\n    def__init__(self, **kwargs):\n        self.input  = kwargs.get(\"input\")\n        self.output = kwargs.get(\"output\")\n        self.W_hidden = kwargs.get(\"W_hidden\")\n        self.b_hidden = kwargs.get(\"b_hidden\")\n        self.W_output = kwargs.get(\"W_output\")\n        self.b_output = kwargs.get(\"b_output\")\n        self.eta = kwargs.get(\"eta\", 0.001)\n\n        # Hidden layer\n        self.hidden_activation   = kwargs.get(\"hidden_activation\")\n        self.hidden_activation_d = kwargs.get(\"hidden_activation_d\")\n\n        # Output layer (opcional)\n        self.output_activation   = kwargs.get(\"output_activation\", None)\n        self.output_activation_d = kwargs.get(\"output_activation_d\", None)\n\n        # Loss\n        self.loss_function   = kwargs.get(\"loss_function\")\n        self.loss_function_d = kwargs.get(\"loss_function_d\")\n\n    def forward(self):\n        # Hidden layer\n        # z1_pre: (n_neurons X n_samples);\n        # W1: (n_neurons X n_feat); input: (n_feat X n_samples); b1: (n_neurons X n_samples)\n        z1_pre = self.W_hidden.T @ self.input + self.b_hidden\n        z1_act = self.hidden_activation(z1_pre)\n\n        # Output layer\n        # z2_pre: (n_outputs X n_samples);\n        # W2: (n_outputs X n_neurons); z1_act: (n_neurons X n_samples); b2: (n_outputs X n_samples)\n        z2_pre = self.W_output.T @ z1_act + self.b_output\n\n        if self.output_activation:\n            z2_act = self.output_activation(z2_pre)\n        else:\n            z2_act = z2_pre\n\n        return z1_pre, z1_act, z2_pre, z2_act\n\n    def loss_calculation(self, true_label, predicted_label):\n        return self.loss_function(true_label, predicted_label)\n\n    def backpropagation(self, z1_pre, z1_act, z2_pre, z2_act):\n        # formato n_output X n_samples\n        output_error = self.loss_function_d(self.output, z2_act)\n\n        if self.output_activation_d:\n            output_error *= self.output_activation_d(z2_pre)\n\n        # formato n_neurons X n_samples\n        hidden_error = (self.W_output @ output_error) * self.hidden_activation_d(z1_pre)\n\n        # Gradientes\n        W_output_gradient = z1_act @ output_error.T\n        b_output_gradient = np.sum(output_error, axis=1, keepdims=True)\n        W_hidden_gradient = self.input @ hidden_error.T\n        b_hidden_gradient = np.sum(hidden_error, axis=1, keepdims=True)\n\n        return W_hidden_gradient, b_hidden_gradient, W_output_gradient, b_output_gradient\n\n    def update_weights(self, W_hidden_gradient, b_hidden_gradient,\n                    W_output_gradient, b_output_gradient):\n        self.W_hidden -= self.eta * W_hidden_gradient\n        self.b_hidden -= self.eta * b_hidden_gradient\n        self.W_output -= self.eta * W_output_gradient\n        self.b_output -= self.eta * b_output_gradient\n        return self.W_hidden, self.b_hidden, self.W_output, self.b_output\n</code></pre> <p>Os resultados do backward pass para as camadas oculta (1) e de sa\u00edda (2) foram:</p> <p>\\(\\frac{\\partial \\mathcal{L}}{\\partial W^{(1)}} \\approx \\begin{bmatrix} 0.26179727 &amp; 0.22385243 \\cr -0.08471891 &amp; 0.39045903 \\end{bmatrix}\\)</p> <p>\\(\\frac{\\partial \\mathcal{L}}{\\partial b^{(1)}} \\approx \\begin{bmatrix} 0.02359454  \\cr -0.15229515 \\end{bmatrix}\\)</p> <p>\\(\\frac{\\partial \\mathcal{L}}{\\partial W^{(2)}} \\approx \\begin{bmatrix} 0.45670643 \\cr -0.27075481 \\end{bmatrix}\\)</p> <p>\\(\\frac{\\partial \\mathcal{L}}{\\partial b^{(2)}} \\approx 0.03577581\\)</p>"},{"location":"exs/ex3_mlp/main/#exercicio-2-classificacao-binaria-com-dados-sinteticos","title":"Exerc\u00edcio 2: Classifica\u00e7\u00e3o bin\u00e1ria com dados sint\u00e9ticos","text":"<ul> <li>Passo 1</li> </ul> Inicializa\u00e7\u00e3o da amostra main.py<pre><code>N_FEATURES_2 = 2\nN_OUTPUT_2 = 1\nN_NEURONS_2 = 10\nSAMPLE_SIZE_2 = 1000\nTRAIN_SIZE = .8\n\nsamples_1_2, samples_labels_1_2 = make_classification(n_samples=SAMPLE_SIZE_2 // 2,\n                                                n_classes=1,\n                                                n_clusters_per_class=1,\n                                                n_features=N_FEATURES_2,\n                                                n_informative=2,\n                                                n_redundant=0,\n                                                random_state=21,\n                                                class_sep=2.0)\n\nsamples_2_2, samples_labels_2_2 = make_classification(n_samples=SAMPLE_SIZE_2 // 2,\n                                                n_classes=1,\n                                                n_clusters_per_class=2,\n                                                n_features=N_FEATURES_2,\n                                                n_informative=2,\n                                                n_redundant=0,\n                                                random_state=42,\n                                                class_sep=2.0)\n\nsamples_labels_1_2[:] = 0\nsamples_labels_2_2[:] = 1\n\nsamples_total_2 = np.concatenate((samples_1_2, samples_2_2))\nsamples_total_labels_2 = np.concatenate((samples_labels_1_2, samples_labels_2_2))\n\nshuffled_samples_total_2, shuffled_samples_total_labels_2 = data.shuffle_sample(sample_array=samples_total_2, labels_array=samples_total_labels_2)\n</code></pre> <p>O tamanho da amostragem \u00e9 de 1000, com 2 classes, 2 features e 16 neur\u00f4nios para a camada oculta. Como \u00e9 um problema de classifica\u00e7\u00e3o bin\u00e1ria, o n\u00famero de outputs \u00e9 de 1 (0 ou 1).</p> <p>A imagem (ref) ilustra graficamente a rela\u00e7\u00e3o entre as features.</p> Figura 1: Amostragem para o exerc\u00edcio 2 <ul> <li>Passo 2</li> </ul> Defini\u00e7\u00e3o de hiperpar\u00e2metros main.py<pre><code>val = (6 / (N_FEATURES_2 + N_OUTPUT_2))**.5\n\nW1_2 = np.random.uniform(-val, val, size=(N_FEATURES_2, N_NEURONS_2))\nW2_2 = np.random.uniform(-val, val,  size=(N_NEURONS_2, N_OUTPUT_2))\n\nb1_2 = np.zeros((N_NEURONS_2, 1)) # n_neurons X n_sample (train)\nb2_2 = np.zeros((N_OUTPUT_2, 1))\n\ntrain_sample_2, test_sample_2, train_sample_labels_2, test_sample_labels_2 = data.train_test_split(shuffled_samples_total_2, shuffled_samples_total_labels_2, TRAIN_SIZE)\n\ntrain_sample_2 = train_sample_2.T\ntest_sample_2 = test_sample_2.T\n\nmu  = np.mean(train_sample_2, axis=1, keepdims=True)\nstd = np.std(train_sample_2, axis=1, keepdims=True) + 1e-8\n\ntrain_sample_norm_2 = (train_sample_2 - mu) / std\ntest_sample_norm_2  = (test_sample_2  - mu) / std\n\nsigmoid = lambda x: 1 / (1 + np.exp(-x))\nsigmoid_d = lambda x: sigmoid(x) * (1 - sigmoid(x))\n\neps = 1e-8\nbce = lambda y, y_pred: -(y * np.log(y_pred + eps) + (1 - y) * np.log(1 - y_pred + eps))\nbce_d = lambda y, y_pred: (y_pred - y) / ((y_pred + eps) * (1 - y_pred + eps))\n</code></pre> <p>Aqui, inicializamos os pesos com o m\u00e9todo de Xavier/Glorot. No exerc\u00edcio, \u00e9 utilizada a inicializa\u00e7\u00e3o uniforme de Xavier, definida pela equa\u00e7\u00e3o \\(2.1\\).</p> \\[ x = \\sqrt{\\frac{6}{n_{inputs} + n_{outputs}}} \\quad \\text{(2.1)} \\] <p>Foi utilizada a fun\u00e7\u00e3o de ativa\u00e7\u00e3o sigmoide, pois os valores est\u00e3o normalizados, juntamente \u00e0 fun\u00e7\u00e3o de perda Binary Cross-Entropy (BCE), por se tratar de uma classifica\u00e7\u00e3o bin\u00e1ria.</p> <ul> <li>Passo 3</li> </ul> Treinamento train.py<pre><code>kwargs_2 = {\"input\": train_sample_norm_2,\n        \"output\": train_sample_labels_2,\n        \"W_hidden\": W1_2,\n        \"b_hidden\": b1_2,\n        \"W_output\": W2_2,\n        \"b_output\": b2_2,\n        \"eta\": .001,\n        \"hidden_activation\": sigmoid,\n        \"hidden_activation_d\": sigmoid_d,\n        \"output_activation\": sigmoid,\n        \"output_activation_d\": sigmoid_d,\n        \"loss_function\": bce,\n        \"loss_function_d\": bce_d}\n\nmlp_object_train_2 = data.MLP(**kwargs_2)\n\nepoch_losses = {100: [], 300: [], 500: []}\nepoch_accuracy = {}\n\nfor n_epochs, losses in epoch_losses.items():\n    epoch_accuracy[n_epochs] = []\n\nfor epoch in range(n_epochs):\n        z1_pre, z1_activation, z2_pre, z2_activation = mlp_object_train_2.forward()\n\nloss = mlp_object_train_2.loss_calculation(train_sample_labels_2, z2_activation)\n        losses.append(np.mean(loss))\n\ny_pred = (z2_activation &gt; 0.5).astype(int)\n        acc = np.mean(y_pred == train_sample_labels_2)\n        epoch_accuracy[n_epochs].append(acc)\n\nW_hidden_gradient, b_hidden_gradient, W_output_gradient, b_output_gradient = mlp_object_train_2.backpropagation(z1_pre, z1_activation, z2_pre, z2_activation)\n\nW_hidden, b_hidden, W_output, b_output = mlp_object_train_2.update_weights(W_hidden_gradient, b_hidden_gradient, W_output_gradient, b_output_gradient)\n</code></pre> <p>O treinamento foi realizado utilizando 100, 300 e 500 \u00e9pocas, e foi avaliada de acordo com as perdas ao longo do treinamento, assim como a acur\u00e1cia obtida.</p> Figura 2: Perda ao longo do treinamento Figura 3: Acur\u00e1cia ao longo do treinamento <ul> <li>Passo 4</li> </ul> Teste main.py<pre><code>kwargs_test_2 = {\n                \"input\": test_sample_norm_2,\n                \"output\": test_sample_labels_2,\n                \"W_hidden\": W_hidden,\n                \"b_hidden\": b_hidden,\n                \"W_output\": W_output,\n                \"b_output\": b_output,\n                \"eta\": .001,\n                \"hidden_activation\": sigmoid,\n                \"hidden_activation_d\": sigmoid_d,\n                \"output_activation\": sigmoid,\n                \"output_activation_d\": sigmoid_d,\n                \"loss_function\": bce,\n                \"loss_function_d\": bce_d\n            }\n\nmlp_object_test_2 = data.MLP(**kwargs_test_2)\n\nz1_test_2, h1_test_2, z2_test_2, y_pred_test_2 = mlp_object_test_2.forward()\n\nloss_test_2 = mlp_object_test_2 = data.MLP(**kwargs_test_2).loss_calculation(test_sample_labels_2, y_pred_test_2)\n\nTHRESHOLD = .5\n\ny_pred = (y_pred_test_2 &gt; THRESHOLD).astype(int)\nacc_test = np.mean(y_pred == test_sample_labels_2)\n</code></pre> <p>Ap\u00f3s o treinamento, foi obtida uma acur\u00e1cia de \\(90.50\\%\\), como esperado de acordo com o gr\u00e1fico ilustrado na figura 3.</p>"},{"location":"exs/ex3_mlp/main/#exercicio-3-classificacao-multi-classe-com-dados-sinteticos","title":"Exerc\u00edcio 3: Classifica\u00e7\u00e3o multi-classe com dados sint\u00e9ticos","text":"<ul> <li>Passo 1</li> </ul> Inicializa\u00e7\u00e3o da amostra main.py<pre><code>SAMPLE_SIZE_3           = 1500\nN_FEATURES_3            = 4\nN_INFORMATIVE_3         = 4\nN_REDUNDANT_3           = 0\nrandom_state            = {\"classe 0\": 21,\n                    \"classe 1\": 42,\n                    \"classe 2\": 84}\nn_cluters_per_class     = {\"classe 0\": 2,\n                    \"classe 1\": 3,\n                    \"classe 2\": 4}\nCLASS_SEP_3             = 2.0\nN_CLASSES_3             = 3\nN_NEURONS_3             = 128\n\nsamples_0_3, samples_labels_0_3 = make_classification(n_samples=SAMPLE_SIZE_3 // 3,\n                                                n_classes=1,\n                                                n_clusters_per_class=n_cluters_per_class[\"classe 0\"],\n                                                n_features=N_FEATURES_3,\n                                                n_informative=N_INFORMATIVE_3,\n                                                n_redundant=N_REDUNDANT_3,\n                                                random_state=random_state[\"classe 0\"],\n                                                class_sep=CLASS_SEP_3)\n\nsamples_1_3, samples_labels_1_3 = make_classification(n_samples=SAMPLE_SIZE_3 // 3,\n                                                n_classes=1,\n                                                n_clusters_per_class=n_cluters_per_class[\"classe 1\"],\n                                                n_features=N_FEATURES_3,\n                                                n_informative=N_INFORMATIVE_3,\n                                                n_redundant=N_REDUNDANT_3,\n                                                random_state=random_state[\"classe 1\"],\n                                                class_sep=CLASS_SEP_3)\n\nsamples_2_3, samples_labels_2_3 = make_classification(n_samples=SAMPLE_SIZE_3 // 3,\n                                                n_classes=1,\n                                                n_clusters_per_class=n_cluters_per_class[\"classe 2\"],\n                                                n_features=N_FEATURES_3,\n                                                n_informative=N_INFORMATIVE_3,\n                                                n_redundant=N_REDUNDANT_3,\n                                                random_state=random_state[\"classe 2\"],\n                                                class_sep=CLASS_SEP_3)\n\nsamples_labels_0_3[:] = 0\nsamples_labels_1_3[:] = 1\nsamples_labels_2_3[:] = 2\n\nsamples_total_3 = np.concatenate((samples_0_3, samples_1_3, samples_2_3))\nsamples_total_labels_3 = np.concatenate((samples_labels_0_3, samples_labels_1_3, samples_labels_2_3))\n\nshuffled_samples_total_3, shuffled_samples_total_labels_3 = data.shuffle_sample(sample_array=samples_total_3, labels_array=samples_total_labels_3)\n</code></pre> <p>A figura 4 mostra um gr\u00e1fico da distribui\u00e7\u00e3o das amostras em rela\u00e7\u00e3o \u00e0 2 features.</p> Figura 4: Amostragem para o exerc\u00edcio 3 <ul> <li>Passo 2</li> </ul> Defini\u00e7\u00e3o dos hiperpar\u00e2metros main.py<pre><code>val = (6 / (N_FEATURES_3 + N_CLASSES_3))**.5\n\nW1_3 = np.random.uniform(-val, val, size=(N_FEATURES_3, N_NEURONS_3))\nW2_3 = np.random.uniform(-val, val, size=(N_NEURONS_3, N_CLASSES_3))\n\nb1_3 = np.zeros((N_NEURONS_3, 1))\nb2_3 = np.zeros((N_CLASSES_3, 1))\n\ntrain_sample_3, test_sample_3, train_sample_labels_3, test_sample_labels_3 = data.train_test_split(shuffled_samples_total_3, shuffled_samples_total_labels_3)\n\ntrain_sample_3 = train_sample_3.T\ntest_sample_3 = test_sample_3.T\n\nmu  = np.mean(train_sample_3, axis=1, keepdims=True)\nstd = np.std(train_sample_3, axis=1, keepdims=True) + 1e-8\n\ntrain_sample_norm_3 = (train_sample_3 - mu) / std\ntest_sample_norm_3  = (test_sample_3  - mu) / std\n\ntanh = lambda x: (np.exp(2*x) - 1) / (np.exp(2*x) + 1)\ntanh_d = lambda x: 1 - tanh(x)**2\n\ndef softmax(z):\n    exp_z = np.exp(z - np.max(z, axis=0, keepdims=True))\n    return exp_z / np.sum(exp_z, axis=0, keepdims=True)\n\ndef cce(y, y_pred, eps=1e-8):\n    N = y.shape[1]\n    return -np.sum(y * np.log(y_pred + eps)) / N\n\ndef cce_d(y, y_pred):\n    N = y.shape[1]\n    return (y_pred - y) / N\n</code></pre> <p>Nesse exerc\u00edcio, utilizamos a fun\u00e7\u00e3o de ativa\u00e7\u00e3o \\(tanh(x)\\), visto que a amostra foi normalizada, e \\(softmax(x)\\), que \u00e9 adequada para problemas de classifica\u00e7\u00e3o multi-classe. Para avalia\u00e7\u00e3o, foi utilizada a fun\u00e7\u00e3o de perda Categorical Cross-Entropy.</p> <ul> <li>Passo 3</li> </ul> Treinamento main.py<pre><code>THRESHOLD_3 = .5\nactivation_array = [tanh, softmax]\nactivation_d_array = [tanh_d, None]\n\nkwargs_train_3 = {\n                \"input\": train_sample_norm_3,\n                \"output\": train_labels_onehot_3,\n                \"W_hidden\": W1_3,\n                \"b_hidden\": b1_3,\n                \"W_output\": W2_3,\n                \"b_output\": b2_3,\n                \"eta\": .001,\n                \"hidden_activation\": activation_array[0],\n                \"hidden_activation_d\": activation_d_array[0],\n                \"output_activation\": activation_array[1],\n                \"output_activation_d\": activation_d_array[1],\n                \"loss_function\": cce,\n                \"loss_function_d\": cce_d\n                }\n\nmlp_object_train_3 = data.MLP(**kwargs_train_3)\n\nepoch_losses_3 = {100: [], 300: [], 500: []}\nepoch_accuracy_3 = {}\n\nbatch_size = 32\nN = train_sample_norm_3.shape[1]\n\nfor n_epochs, losses in epoch_losses_3.items():\n    epoch_accuracy_3[n_epochs] = []\n\nfor epoch in range(n_epochs):\n        epoch_correct = 0\n        epoch_count = 0\n        epoch_loss_accum = 0.0\n\nfor start in range(0, N, batch_size):\n            end = min(start + batch_size, N)\n\nsample_batch = train_sample_norm_3[:, start:end]\n            labels_batch = train_labels_onehot_3[:, start:end]\n\nmlp_object_train_3.input = sample_batch\n            mlp_object_train_3.output = labels_batch\n\nz1_pre_train_3, z1_activation_train_3, z2_pre_train_3, z2_activation_train_3 = mlp_object_train_3.forward(\n            )\n\n# ==============================================================\n            # Armazenando a loss para plotar no gr\u00e1fico depois\n            loss = mlp_object_train_3.loss_calculation(labels_batch,\n                                                    z2_activation_train_3)\n            if np.ndim(loss) &gt; 0:\n                loss = np.mean(loss)\n\nB = end - start\n            epoch_loss_accum += loss * B\n            # ==============================================================\n\n# ==============================================================\n            # Armazenando a acur\u00e1cia do modelo para plotar no gr\u00e1fico depois\n            preds_idx = np.argmax(z2_activation_train_3, axis=0)\n            true_idx = np.argmax(labels_batch, axis=0)\n            epoch_correct += np.sum(preds_idx == true_idx)\n            epoch_count += B\n            # ==============================================================\n\n# ==============================================================\n            # Backpropagation\n            dW1_train_3, db1_train_3, dW2_train_3, db2_train_3 = mlp_object_train_3.backpropagation(\n                z1_pre_train_3, z1_activation_train_3, z2_pre_train_3,\n                z2_activation_train_3)\n            # ==============================================================\n\n# ==============================================================\n            # Ajustando os par\u00e2metros para o pr\u00f3ximo batch\n            W_hidden_train_3, b_hidden_train_3, W_output_train_3, b_output_train_3 = mlp_object_train_3.update_weights(\n                dW1_train_3, db1_train_3, dW2_train_3, db2_train_3)\n            # ==============================================================\n\nepoch_loss = epoch_loss_accum / epoch_count\n        epoch_acc = epoch_correct / epoch_count\n\nlosses.append(epoch_loss)\n        epoch_accuracy_3[n_epochs].append(epoch_acc)\n</code></pre> <p>Dessa vez, fazemos o treinamento em batches como tentativa de aumentar a qualidade do modelo.</p> <ul> <li>Passo 4</li> </ul> Teste <pre><code>kwargs_test_3 = {\n                \"input\": test_sample_norm_3, \n                \"output\": test_sample_labels_3, \n                \"W_hidden\": W_hidden_train_3, \n                \"b_hidden\": b_hidden_train_3, \n                \"W_output\": W_output_train_3, \n                \"b_output\": b_output_train_3, \n                \"eta\": .001, \n                \"hidden_activation\": activation_array[0], \n                \"hidden_activation_d\": activation_d_array[0], \n                \"output_activation\": activation_array[1],\n                \"output_activation_d\": activation_d_array[1], \n                \"loss_function\": cce,\n                \"loss_function_d\": cce_d\n            }\n\nmlp_object_test_3 = data.MLP(**kwargs_test_3)\n\ndef accuracy_from_preds(z2_act, y_true):\n    # z2_act: (M, N), y_true: one-hot (M, N) ou indices (N,)\n    y_pred_idx = np.argmax(z2_act, axis=0)\n    if y_true.ndim == 2:\n        y_true_idx = np.argmax(y_true, axis=0)\n    else:\n        y_true_idx = y_true\n    return np.mean(y_pred_idx == y_true_idx), y_pred_idx, y_true_idx\n\nz1, h1, z2, y_pred_test = mlp_object_test_3.forward()\nacc_test, preds_idx, true_idx = accuracy_from_preds(y_pred_test, test_sample_labels_3) \n</code></pre> <p>A acur\u00e1cia do modelo na amostragem de teste foi de \\(83.58\\%\\).</p>"},{"location":"exs/ex4_vae/main/","title":"VAE","text":"<p>Informa\u00e7\u00f5es da entrega</p> <p>\ud83d\udcc6 Deadline: 26/10/2025</p> <p>\ud83d\udcd6 O enunciado da atividade est\u00e1 dispon\u00edvel neste link.</p> <p>Para importar as bibliotecas necess\u00e1rias, incluir as linhas a seguir no c\u00f3digo.</p> Importando bibliotecas main.py<pre><code>import torch\nimport torch.nn as nn\nfrom torchvision import datasets\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader\nfrom utils import mlp\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom tqdm import tqdm\n</code></pre> <p>A atividade foi feita utilizando uma seed para reprodutibilidade em outros ambientes. Tamb\u00e9m \u00e9 importante selecionar o dispositivo no qual o programa ser\u00e1 executado.</p> Semente manualSele\u00e7\u00e3o do dispositivo main.py<pre><code>gen = torch.manual_seed(42)\n</code></pre> main.py<pre><code>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'-&gt; Using device: {device}')\n</code></pre>"},{"location":"exs/ex4_vae/main/#preparacao-do-dataset","title":"Prepara\u00e7\u00e3o do dataset","text":"<p>Os dados utilizados foram carregados do dataset MNIST, utilizando o framework do <code>PyTorch</code>.</p> <p>Juntamente ao carregamento dos dados, foi feita a divis\u00e3o em datasets para treinamento e teste, contendo \\(60000\\) e \\(10000\\) imagens cada um, respectivamente.</p> Dataset de treinamentoDataset de testes train.py<pre><code>transform = transforms.Compose([transforms.ToTensor()])\n\ntrain_dataset = datasets.MNIST(\n    root=DATA_PATH,\n    train=True,\n    transform=transform,\n    download=True\n)\n</code></pre> test.py<pre><code>transform = transforms.Compose([transforms.ToTensor()])\n\ntest_dataset = datasets.MNIST(\n    root=DATA_PATH,\n    train=False,\n    transform=transform,\n    download=True\n)\n</code></pre> <p>Sendo <code>DATA_PATH</code> o caminho onde os dados ser\u00e3o salvos em sua m\u00e1quina.</p> <p>O argumento <code>transform</code> foi utilizado para fazer com que os dados fossem representados em forma de tensores, ao inv\u00e9s de imagens no formato <code>PIL</code>.</p> <p>Ap\u00f3s o carregamento dos datasets, precisamos fazer com que seja poss\u00edvel fazer itera\u00e7\u00f5es sobre os itens dentro deles. Isso \u00e9 feito utilizando a classe <code>DataLoader</code> do m\u00f3dulo <code>torch.utils.data</code> do PyTorch.</p> Carregando dataset de treinamentoCarregando dataset de testes train.py<pre><code>train_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True\n)\n</code></pre> test.py<pre><code>test_loader = DataLoader(\n    dataset=test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n</code></pre> <p>Visualizando \\(10\\) amostras do dataset, temos:</p> Figura 1: Visualiza\u00e7\u00e3o dos dados"},{"location":"exs/ex4_vae/main/#implementacao-do-modelo","title":"Implementa\u00e7\u00e3o do modelo","text":"<p>A arquitetura do modelo utilizado pode ser representada pela Figura 2.</p> Figura 2: Visualiza\u00e7\u00e3o dos dados Arquitetura do modelo models.py<pre><code>class VAE(nn.Module):\n    def __init__(self, device, input_dim=784, hidden_dim=400, latent_dim=10):\n        super(VAE, self).__init__()\n        self.device = device\n        self.encoder = nn.Sequential(\n            OrderedDict([\n                ('fc1', nn.Linear(input_dim, hidden_dim)),\n                ('relu1', nn.ReLU()),\n                ('fc2', nn.Linear(hidden_dim, latent_dim))\n            ])\n        )\n\n        self.mu_layer = nn.Linear(latent_dim, 2)\n        self.logvar_layer = nn.Linear(latent_dim, 2)\n\n        self.decoder = nn.Sequential(\n            OrderedDict([\n                ('fc1', nn.Linear(2, latent_dim)),\n                ('relu1', nn.ReLU()),\n                ('fc2', nn.Linear(latent_dim, hidden_dim)),\n                ('relu3', nn.ReLU()),\n                ('fc3', nn.Linear(hidden_dim, input_dim)),\n                ('output', nn.Sigmoid())\n            ])\n        )\n\n    def encode(self, x):\n        x = self.encoder(x)\n        mu, logvar = self.mu_layer(x), self.logvar_layer(x)\n        return mu, logvar\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std).to(self.device)\n        return mu + eps * std\n\n    def decode(self, z):\n        return self.decoder(z)\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        x_pred = self.decode(z)\n        return x_pred, mu, logvar\n</code></pre> <p>Nessa arquitetura, temos as seguintes caracter\u00edsticas:</p> <ul> <li> <p>Encoder: a entrada \u00e9 um tensor de tamanho \\(784\\), ou seja, uma imagem do dataset \"achatada\" (\\(28 \\times 28\\)). As informa\u00e7\u00f5es da imagem s\u00e3o ent\u00e3o transferidas para uma camada oculta. Podemos representar a passagem pelo encoder como: \\(784 \\rightarrow 400 \\rightarrow 10 \\rightarrow 2\\);</p> </li> <li> <p>Reparametriza\u00e7\u00e3o: \u00e9 adicionada uma camada para que o truque seja feito corretamente. Essa camada possui 2 dimens\u00f5es;</p> </li> <li> <p>Decoder: a entrada \u00e9 a sa\u00edda do espa\u00e7o latente, ou seja, um tensor com 2 dimens\u00f5es. Essa entrada faz o caminho contr\u00e1rio do encoder, ou seja, \\(2 \\rightarrow 10 \\rightarrow 400 \\rightarrow 784\\). A sa\u00edda \u00e9 uma imagem reconstru\u00edda com base no espa\u00e7o latente.</p> </li> </ul>"},{"location":"exs/ex4_vae/main/#treinamento","title":"Treinamento","text":"<p>Para treinar o modelo, utilizaremos \\(100\\) \u00e9pocas e o otimizador Adam, Binary Cross-Entropy e Kullback Leibler Divergence para fun\u00e7\u00e3o de perda, em adi\u00e7\u00e3o a um batch size de \\(128\\).</p> Vari\u00e1veis para treinamentoFun\u00e7\u00e3o para treinamento train.py<pre><code>vae = models.VAE(device).to(device)\noptimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n\nEPOCHS = 100\nbatch_size = 128\n</code></pre> train.py<pre><code>def train(model, device, train_loader, optimizer, epochs, checkpoint_path=None):\n    model.train()\n    for epoch in range(epochs):\n        train_loss = 0.0\n\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n\n        for _, (data, _) in enumerate(progress_bar):\n            batch_size = data.size(0)\n            data = data.to(device).view(batch_size, -1)\n\n            optimizer.zero_grad()\n\n            x_pred, mu, logvar = model(data)\n            loss = loss_function(data, x_pred, mu, logvar)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * batch_size\n\n            # atualiza descri\u00e7\u00e3o da barra\n            progress_bar.set_postfix(loss=loss.item())\n\n        avg_loss = train_loss / len(train_loader.dataset)\n\n\n        if checkpoint_path:\n            if (epoch + 1) % 10 == 0:\n                checkpoint_path = f\"{CHECKPOINTS_PATH}/vae_epoch_{epoch + 1}.pt\"\n\n                checkpoint = {\n                    'epoch': epoch + 1,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'loss': avg_loss,\n                }\n\n                torch.save(checkpoint, checkpoint_path)\n\n        print(f\"Epoch {epoch + 1}/{epochs} - Average loss: {avg_loss:.6f}\")\n\n    return train_loss\n</code></pre> <p>A fun\u00e7\u00e3o calcula a perda acumulada ao final de cada \u00e9poca e soma em uma vari\u00e1vel <code>train_loss</code>, que ser\u00e1 retornada ap\u00f3s o treinamento ser conclu\u00eddo. Al\u00e9m disso, foram implementadas duas funcionalidades extras:</p> <ul> <li> <p>Visualiza\u00e7\u00e3o gr\u00e1fica atrav\u00e9s de uma barra de progresso;</p> </li> <li> <p>Salvamento peri\u00f3dico em arquivos <code>.pt</code>, denominados checkpoints, que possuem informa\u00e7\u00f5es sobre o modelo em um determinado momento. Por padr\u00e3o, no c\u00f3digo, o per\u00edodo foi de \\(10\\) \u00e9pocas, ou seja, a cada per\u00edodo \u00e9 gerado um arquivo contendo as informa\u00e7\u00f5es do modelo que podem ser recuperadas caso o treinamento seja interrompido.</p> </li> </ul> <p>Podemos ent\u00e3o, realizar o treinamento.</p> train.py<pre><code>total_loss = train(vae, device, train_loader, optimizer, epochs=100, checkpoint_path=CHECKPOINTS_PATH)\n</code></pre>"},{"location":"exs/ex4_vae/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do modelo","text":"<p>Para avaliarmos o modelo, usamos </p>"},{"location":"exs/ex4_vae/main/#visualizacao-do-espaco-latente","title":"Visualiza\u00e7\u00e3o do espa\u00e7o latente","text":"<p>Abaixo, temos visualiza\u00e7\u00f5es do espa\u00e7o latente, tanto em rela\u00e7\u00e3o \u00e0 distribui\u00e7\u00e3o quanto \u00e0s imagens dentro desse espa\u00e7o.</p> Figura 3: Espa\u00e7o latente (distribui\u00e7\u00e3o) Figura 4: Espa\u00e7o latente (imagens)"},{"location":"projs/proj1_classification/main/","title":"Classifica\u00e7\u00e3o","text":"<p>Informa\u00e7\u00f5es da entrega</p> <p>\ud83d\udcc6 Deadline: 05/10/2025</p> <p>\ud83d\udcd6 O enunciado da atividade est\u00e1 dispon\u00edvel neste link.</p>"},{"location":"projs/proj1_classification/main/#integrantes-do-grupo","title":"Integrantes do Grupo","text":"<ul> <li> <p>Carlos Eduardo P. Yamada</p> </li> <li> <p>Pedro De Lucca S. C. Ferro</p> </li> </ul>"},{"location":"projs/proj1_classification/main/#codigo-fonte","title":"C\u00f3digo-fonte","text":"<ul> <li>Notebook de explora\u00e7\u00e3o e modelagem: <code>src/projs/proj1_classification/main.ipynb</code></li> </ul>"},{"location":"projs/proj1_classification/main/#resumo","title":"Resumo","text":"<p>Este projeto implementa uma rede neural Multi-Layer Perceptron (MLP) para classifica\u00e7\u00e3o de alertas de terremotos em quatro categorias: green, yellow, orange e red. O modelo foi treinado utilizando dados s\u00edsmicos que incluem caracter\u00edsticas como magnitude, profundidade, intensidade sentida pela comunidade (CDI), intensidade de danos (MMI) e signific\u00e2ncia do evento.</p>"},{"location":"projs/proj1_classification/main/#fontes-de-dados","title":"Fontes de Dados","text":"<p>Os datasets utilizados neste projeto est\u00e3o dispon\u00edveis no Kaggle:</p> <ul> <li>Earthquake Dataset: https://www.kaggle.com/datasets/warcoder/earthquake-dataset</li> <li>Earthquake Alert Prediction Dataset: https://www.kaggle.com/datasets/ahmeduzaki/earthquake-alert-prediction-dataset</li> </ul>"},{"location":"projs/proj1_classification/main/#objetivos","title":"Objetivos","text":"<ul> <li>Desenvolver um modelo de classifica\u00e7\u00e3o multiclasse para prever o n\u00edvel de alerta de terremotos;</li> <li>Avaliar o desempenho do modelo utilizando m\u00faltiplas m\u00e9tricas (acur\u00e1cia, precis\u00e3o, recall, F1-score);</li> <li>Analisar os padr\u00f5es de erro e limita\u00e7\u00f5es do modelo.</li> </ul>"},{"location":"projs/proj1_classification/main/#dataset","title":"Dataset","text":""},{"location":"projs/proj1_classification/main/#descricao-dos-dados","title":"Descri\u00e7\u00e3o dos Dados","text":"<p>O dataset utilizado \u00e9 uma vers\u00e3o pr\u00e9-processada e otimizada especificamente para aplica\u00e7\u00f5es de machine learning em avalia\u00e7\u00e3o de riscos s\u00edsmicos e sistemas de predi\u00e7\u00e3o de alertas de terremotos. Cont\u00e9m 1300 amostras e 6 colunas, representando registros de eventos s\u00edsmicos com diferentes intensidades e alertas associados.</p> Coluna Tipo Descri\u00e7\u00e3o <code>magnitude</code> Num\u00e9rico (<code>float</code>) Medida da energia liberada pelo terremoto na escala Richter. <code>depth</code> Num\u00e9rico (<code>float</code>) Profundidade do epicentro em quil\u00f4metros. <code>cdi</code> Num\u00e9rico (<code>float</code>) Community Decimal Intensity \u2013 intensidade sentida pela popula\u00e7\u00e3o (escala de 1 a 10). <code>mmi</code> Num\u00e9rico (<code>float</code>) Modified Mercalli Intensity \u2013 intensidade dos danos observados (escala de 1 a 10). <code>sig</code> Num\u00e9rico (<code>float</code>) Signific\u00e2ncia do evento (pontua\u00e7\u00e3o calculada pelo USGS). <code>alert</code> Categ\u00f3rica (<code>string</code>) Target: n\u00edvel de alerta \u2014 <code>green</code>, <code>yellow</code>, <code>orange</code>, ou <code>red</code>."},{"location":"projs/proj1_classification/main/#balanceamento-dos-dados-via-smote","title":"Balanceamento dos Dados via SMOTE","text":"<p>O dataset utilizado foi balanceado utilizando SMOTE (Synthetic Minority Over-sampling Technique), uma t\u00e9cnica avan\u00e7ada de oversampling que gera amostras sint\u00e9ticas para as classes minorit\u00e1rias. Diferente da simples duplica\u00e7\u00e3o de amostras, o SMOTE cria novos exemplos interpolando entre inst\u00e2ncias existentes da classe minorit\u00e1ria, resultando em:</p> <ul> <li>Melhor generaliza\u00e7\u00e3o: O modelo aprende padr\u00f5es mais diversos em vez de memorizar amostras duplicadas;</li> <li>Redu\u00e7\u00e3o de overfitting: Amostras sint\u00e9ticas adicionam variabilidade controlada ao dataset;</li> <li>Distribui\u00e7\u00e3o equilibrada: Todas as classes de alerta possuem aproximadamente o mesmo n\u00famero de amostras.</li> </ul> Figura 1: Distribui\u00e7\u00e3o das classes no conjunto de dados desbalanceado Figura 2: Distribui\u00e7\u00e3o das classes no conjunto de dados balanceado (utilizado no treinamento)"},{"location":"projs/proj1_classification/main/#analise-exploratoria","title":"An\u00e1lise Explorat\u00f3ria","text":"Figura 3: Distribui\u00e7\u00e3o dos atributos num\u00e9ricos do dataset Figura 4: Matriz de correla\u00e7\u00e3o entre as vari\u00e1veis num\u00e9ricas <p>As principais observa\u00e7\u00f5es da an\u00e1lise explorat\u00f3ria incluem: - Forte correla\u00e7\u00e3o entre <code>magnitude</code> e <code>sig</code> (signific\u00e2ncia); - Correla\u00e7\u00e3o moderada entre <code>cdi</code> e <code>mmi</code>; - <code>depth</code> apresenta menor correla\u00e7\u00e3o com outras vari\u00e1veis.</p>"},{"location":"projs/proj1_classification/main/#metodologia","title":"Metodologia","text":""},{"location":"projs/proj1_classification/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<ol> <li>One-hot Encoding: Convers\u00e3o da vari\u00e1vel categ\u00f3rica <code>alert</code> em 4 colunas bin\u00e1rias;</li> <li>Normaliza\u00e7\u00e3o Z-Score: Padroniza\u00e7\u00e3o de todas as features num\u00e9ricas usando m\u00e9dia e desvio padr\u00e3o;</li> <li>Embaralhamento: Randomiza\u00e7\u00e3o das amostras para evitar overfitting por enviesamento;</li> <li>Divis\u00e3o dos dados: \\(70\\%\\) treino, \\(30\\%\\) teste (com <code>random_state=42</code>).</li> </ol>"},{"location":"projs/proj1_classification/main/#arquitetura-do-modelo","title":"Arquitetura do Modelo","text":"<p>Multi-Layer Perceptron (MLP) - Scikit-learn</p> <ul> <li>Camada de entrada: 5 neur\u00f4nios (features normalizadas);</li> <li>Camada oculta: 16 neur\u00f4nios;</li> <li>Camada de sa\u00edda: 4 neur\u00f4nios (classes de alerta);</li> <li>Fun\u00e7\u00e3o de ativa\u00e7\u00e3o: ReLU (camadas ocultas), sigmoide (sa\u00edda);</li> <li>Otimizador: Adam;</li> <li>Learning rate: 0.01;</li> <li>Batch size: 100;</li> <li>\u00c9pocas: 1000.</li> </ul>"},{"location":"projs/proj1_classification/main/#resultados","title":"Resultados","text":""},{"location":"projs/proj1_classification/main/#evolucao-do-treinamento","title":"Evolu\u00e7\u00e3o do Treinamento","text":"Figura 5: Evolu\u00e7\u00e3o da acur\u00e1cia ao longo das 1000 \u00e9pocas de treinamento Figura 6: Matriz de confus\u00e3o dos resultados de teste Figura 7: Compara\u00e7\u00e3o de Precis\u00e3o, Recall e F1-Score por classe de alerta"},{"location":"projs/proj1_classification/main/#metricas-de-performance","title":"M\u00e9tricas de Performance","text":"M\u00e9trica Conjunto de Treino Conjunto de Teste Acur\u00e1cia \\(~80\\%\\) \\(~78\\%\\) Diferen\u00e7a (Overfitting) - \\(~2\\%\\) <p>O modelo apresentou boa generaliza\u00e7\u00e3o, com diferen\u00e7a m\u00ednima entre treino e teste, indicando aus\u00eancia de overfitting significativo.</p>"},{"location":"projs/proj1_classification/main/#erros-mais-significativos","title":"Erros mais significativos","text":"Figura 8: Visualiza\u00e7\u00e3o dos principais erros"},{"location":"projs/proj1_classification/main/#curva-de-perda-durante-o-treinamento","title":"Curva de perda durante o treinamento","text":"Figura 9: Curva de perda durante o treinamento"},{"location":"projs/proj1_classification/main/#comparacao-entre-as-distribuicoes-de-reais-e-preditas","title":"Compara\u00e7\u00e3o entre as distribui\u00e7\u00f5es de reais e preditas","text":"Figura 10: Compara\u00e7\u00e3o entre as distribui\u00e7\u00f5es de reais e preditas"},{"location":"projs/proj1_classification/main/#analise-de-erros","title":"An\u00e1lise de Erros","text":"<p>Os principais tipos de erro do modelo incluem: - Confus\u00e3o entre classes adjacentes (<code>orange</code> \u2194 <code>green</code>, <code>green</code> \u2194 <code>yellow</code>); - Melhor desempenho nas classes extremas (<code>yellow</code> e <code>red</code>); - Maior dificuldade nas classes intermedi\u00e1rias devido \u00e0 sobreposi\u00e7\u00e3o de caracter\u00edsticas.</p>"},{"location":"projs/proj1_classification/main/#distribuicao-das-predicoes","title":"Distribui\u00e7\u00e3o das Predi\u00e7\u00f5es","text":"<p>A distribui\u00e7\u00e3o das predi\u00e7\u00f5es do modelo manteve-se consistente com a distribui\u00e7\u00e3o real das classes no conjunto de teste, indicando que o modelo n\u00e3o apresenta vi\u00e9s significativo em dire\u00e7\u00e3o a nenhuma classe espec\u00edfica.</p>"},{"location":"projs/proj1_classification/main/#discussao","title":"Discuss\u00e3o","text":""},{"location":"projs/proj1_classification/main/#pontos-fortes","title":"Pontos Fortes","text":"<ol> <li>Boa generaliza\u00e7\u00e3o: Diferen\u00e7a m\u00ednima entre acur\u00e1cia de treino e teste (\\(~2\\%\\));</li> <li>Modelo balanceado: N\u00e3o apresenta vi\u00e9s excessivo para nenhuma classe;</li> <li>Converg\u00eancia est\u00e1vel: Curva de perda monotonicamente decrescente;</li> <li>Performance consistente: M\u00e9tricas equilibradas entre precis\u00e3o e recall.</li> </ol>"},{"location":"projs/proj1_classification/main/#limitacoes","title":"Limita\u00e7\u00f5es","text":"<ol> <li>Confus\u00e3o entre classes adjacentes: O modelo tem dificuldade em distinguir alertas de n\u00edveis pr\u00f3ximos;</li> <li>Acur\u00e1cia moderada: \\(~78\\%\\) pode n\u00e3o ser suficiente para aplica\u00e7\u00f5es cr\u00edticas de seguran\u00e7a;</li> <li>Arquitetura simples: Uma \u00fanica camada oculta pode limitar a capacidade de aprender padr\u00f5es complexos.</li> </ol>"},{"location":"projs/proj1_classification/main/#melhorias-possiveis","title":"Melhorias Poss\u00edveis","text":"<ul> <li>Adicionar mais camadas ocultas para aumentar a capacidade representacional;</li> <li>Implementar t\u00e9cnicas de regulariza\u00e7\u00e3o (Dropout, L2);</li> <li>Explorar outras arquiteturas (CNN, LSTM) se houver dados temporais;</li> <li>Aumentar o dataset para melhorar a generaliza\u00e7\u00e3o;</li> <li>Feature engineering: criar vari\u00e1veis derivadas das existentes;</li> <li>Ajuste fino de hiperpar\u00e2metros via Grid Search ou Random Search.</li> </ul>"},{"location":"projs/proj1_classification/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O modelo MLP desenvolvido demonstrou capacidade satisfat\u00f3ria para classifica\u00e7\u00e3o de alertas de terremotos, atingindo \\(~78\\%\\) de acur\u00e1cia no conjunto de teste. A an\u00e1lise detalhada revelou que o modelo funciona melhor para classes extremas (green e red) e apresenta maior confus\u00e3o entre classes adjacentes. </p> <p>Para aplica\u00e7\u00f5es em sistemas de alerta real, recomenda-se: - Priorizar recall para classes cr\u00edticas (red e orange) para minimizar falsos negativos; - Investigar t\u00e9cnicas de ensemble para melhorar a robustez; - Coletar mais dados para as transi\u00e7\u00f5es entre classes.</p>"},{"location":"projs/proj2_regression/main/","title":"Regress\u00e3o","text":""},{"location":"projs/proj2_regression/main/#projeto-02-regressao-de-precos-de-combustiveis-2004-2021","title":"Projeto 02 \u2014 Regress\u00e3o de Pre\u00e7os de Combust\u00edveis (2004-2021)","text":""},{"location":"projs/proj2_regression/main/#estudantes","title":"Estudantes","text":"<ul> <li>Pedro De Lucca S. C. Ferro</li> <li>Carlos Eduardo P. Yamada</li> </ul>"},{"location":"projs/proj2_regression/main/#codigo-fonte","title":"C\u00f3digo Fonte","text":"<ul> <li>Notebook de explora\u00e7\u00e3o e modelagem: <code>src/proj2_regression/main.ipynb</code></li> </ul>"},{"location":"projs/proj2_regression/main/#resumo","title":"Resumo","text":"<p>Este projeto modela a varia\u00e7\u00e3o do pre\u00e7o m\u00e9dio de revenda de combust\u00edveis no Brasil entre 2004 e 2021 utilizando a base p\u00fablica da ANP (Ag\u00eancia Nacional do Petr\u00f3leo, G\u00e1s Natural e Biocombust\u00edveis). Foram comparadas duas abordagens de regress\u00e3o:</p> <ul> <li>MLPRegressor (Rede Neural) com arquitetura (64, 32) neur\u00f4nios + early stopping</li> <li>Regress\u00e3o Linear como baseline</li> </ul> <p>Surpreendentemente, a Regress\u00e3o Linear apresentou desempenho superior com R\u00b2 = 1.0000 (perfeito), RMSE = 0.0097 e MAE = 0.0021, superando a MLP (R\u00b2 = 0.9999, RMSE = 0.0146, MAE = 0.0098). Este resultado indica que a rela\u00e7\u00e3o entre as vari\u00e1veis \u00e9 essencialmente linear, tornando modelos mais simples mais apropriados para este problema.</p>"},{"location":"projs/proj2_regression/main/#fonte-de-dados","title":"Fonte de Dados","text":"<ul> <li>Arquivo: <code>code/projects/02-Regression/data/2004-2021.tsv</code></li> <li>Origem: S\u00e9rie hist\u00f3rica da ANP com pre\u00e7os de combust\u00edveis por estado, munic\u00edpio e produto. Acesse aqui</li> <li>Per\u00edodo: Janeiro/2004 a Dezembro/2021</li> </ul>"},{"location":"projs/proj2_regression/main/#dataset","title":"Dataset","text":""},{"location":"projs/proj2_regression/main/#caracteristicas-do-conjunto-de-dados","title":"Caracter\u00edsticas do Conjunto de Dados","text":"<ul> <li>Dimens\u00e3o original: 120.823 linhas \u00d7 18 colunas</li> <li>Dimens\u00e3o ap\u00f3s limpeza: 111.875 linhas (remo\u00e7\u00e3o de duplicatas e valores inv\u00e1lidos -99999.000)</li> <li>Vari\u00e1vel alvo: <code>PRE\u00c7O M\u00c9DIO REVENDA</code> (R$)</li> </ul>"},{"location":"projs/proj2_regression/main/#atributos-principais","title":"Atributos Principais","text":"<p>Temporais: - <code>DATA INICIAL</code>, <code>DATA FINAL</code>: per\u00edodo de coleta dos pre\u00e7os - Vari\u00e1veis derivadas: <code>ANO</code>, <code>MES</code>, <code>ANO/MES</code> (criadas para an\u00e1lise temporal)</p> <p>Geogr\u00e1ficos: - <code>REGI\u00c3O</code>: 5 regi\u00f5es do Brasil - <code>ESTADO</code>: 27 unidades federativas</p> <p>Produto e Medi\u00e7\u00e3o: - <code>PRODUTO</code>: Gasolina Comum, Gasolina Aditivada, Etanol Hidratado, Diesel, Diesel S10, GLP - <code>UNIDADE DE MEDIDA</code>: R$/litro ou R$/13kg (para GLP)</p> <p>M\u00e9tricas de Pre\u00e7o (Revenda): - <code>PRE\u00c7O M\u00c9DIO REVENDA</code> (target) - <code>PRE\u00c7O M\u00cdNIMO REVENDA</code>, <code>PRE\u00c7O M\u00c1XIMO REVENDA</code> - <code>MARGEM M\u00c9DIA REVENDA</code> - <code>COEF DE VARIA\u00c7\u00c3O REVENDA</code> - <code>DESVIO PADR\u00c3O REVENDA</code></p> <p>M\u00e9tricas de Distribui\u00e7\u00e3o: - <code>PRE\u00c7O M\u00c9DIO DISTRIBUI\u00c7\u00c3O</code> - <code>PRE\u00c7O M\u00cdNIMO DISTRIBUI\u00c7\u00c3O</code>, <code>PRE\u00c7O M\u00c1XIMO DISTRIBUI\u00c7\u00c3O</code> - <code>COEF DE VARIA\u00c7\u00c3O DISTRIBUI\u00c7\u00c3O</code> - <code>DESVIO PADR\u00c3O DISTRIBUI\u00c7\u00c3O</code></p> <p>Amostragem: - <code>N\u00daMERO DE POSTOS PESQUISADOS</code>: quantidade de estabelecimentos na coleta</p>"},{"location":"projs/proj2_regression/main/#analise-exploratoria","title":"An\u00e1lise Explorat\u00f3ria","text":"<p> Figura 1: Evolu\u00e7\u00e3o temporal dos pre\u00e7os m\u00e9dios de revenda por tipo de combust\u00edvel (2004-2021). Observa-se tend\u00eancia de crescimento consistente com picos em 2015 e 2021.</p> <p> Figura 2: Compara\u00e7\u00e3o da evolu\u00e7\u00e3o dos pre\u00e7os da gasolina comum entre estados do Nordeste. Nota-se varia\u00e7\u00e3o significativa entre estados ao longo do per\u00edodo.</p>"},{"location":"projs/proj2_regression/main/#metodologia","title":"Metodologia","text":""},{"location":"projs/proj2_regression/main/#1-pre-processamento-e-limpeza","title":"1. Pr\u00e9-processamento e Limpeza","text":""},{"location":"projs/proj2_regression/main/#conversao-de-tipos","title":"Convers\u00e3o de Tipos","text":"<pre><code># Convers\u00e3o de datas\nfor col in [\"DATA INICIAL\", \"DATA FINAL\"]:\n    df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n\n# Convers\u00e3o de colunas num\u00e9ricas que vieram como texto\nnumeric_object_cols = [c for c in obj_cols if c not in categorical_true]\nfor col in numeric_object_cols:\n    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n</code></pre>"},{"location":"projs/proj2_regression/main/#remocao-de-duplicatas-e-valores-invalidos","title":"Remo\u00e7\u00e3o de Duplicatas e Valores Inv\u00e1lidos","text":"<pre><code>df = df.drop_duplicates()\ndf = df.replace(-99999.000, np.nan)\ndf = df.dropna()\n</code></pre> <ul> <li>Removidas duplicatas</li> <li>Removidos valores inv\u00e1lidos codificados como -99999.000</li> <li>Removidas linhas com valores ausentes (NaN)</li> <li>Dataset final: 111.875 registros</li> </ul>"},{"location":"projs/proj2_regression/main/#tratamento-de-valores-ausentes","title":"Tratamento de Valores Ausentes","text":"<ul> <li>Colunas num\u00e9ricas: imputa\u00e7\u00e3o com mediana</li> <li>Colunas categ\u00f3ricas: imputa\u00e7\u00e3o com moda</li> <li>M\u00e9todo robusto a outliers (mediana prefer\u00edvel \u00e0 m\u00e9dia)</li> </ul>"},{"location":"projs/proj2_regression/main/#deteccao-e-tratamento-de-outliers","title":"Detec\u00e7\u00e3o e Tratamento de Outliers","text":"<pre><code># M\u00e9todo IQR (Interquartile Range)\nq1 = df[col].quantile(0.25)\nq3 = df[col].quantile(0.75)\niqr = q3 - q1\nlower_bound = q1 - 1.5 * iqr\nupper_bound = q3 + 1.5 * iqr\n\n# Clipping ao inv\u00e9s de remo\u00e7\u00e3o (preserva tamanho do dataset)\ndf[col] = df[col].clip(lower_bound, upper_bound)\n</code></pre> <p>Justificativa: Clipping preserva informa\u00e7\u00f5es extremas mas realistas (ex: picos hist\u00f3ricos de pre\u00e7o) enquanto remove anomalias claras.</p>"},{"location":"projs/proj2_regression/main/#2-engenharia-de-features","title":"2. Engenharia de Features","text":""},{"location":"projs/proj2_regression/main/#features-temporais","title":"Features Temporais","text":"<ul> <li><code>ANO</code>: extra\u00eddo de <code>DATA FINAL</code></li> <li><code>MES</code>: extra\u00eddo de <code>DATA FINAL</code></li> <li><code>ANO/MES</code>: timestamp mensal para an\u00e1lises de s\u00e9rie temporal</li> </ul>"},{"location":"projs/proj2_regression/main/#encoding-de-variaveis-categoricas","title":"Encoding de Vari\u00e1veis Categ\u00f3ricas","text":"<pre><code># One-hot encoding com drop_first=True para evitar multicolinearidade\ncategorical_cols = [\"REGI\u00c3O\", \"ESTADO\", \"PRODUTO\", \"UNIDADE DE MEDIDA\"]\ndf_model = pd.get_dummies(df_model, columns=categorical_cols, drop_first=True)\n</code></pre> <p>Resultado: expans\u00e3o de 4 colunas categ\u00f3ricas para m\u00faltiplas colunas bin\u00e1rias</p>"},{"location":"projs/proj2_regression/main/#normalizacao-z-score","title":"Normaliza\u00e7\u00e3o (Z-score)","text":"<pre><code># Padroniza\u00e7\u00e3o: (x - \u03bc) / \u03c3\nX[num_cols] = (X[num_cols] - X[num_cols].mean()) / X[num_cols].std(ddof=0)\n</code></pre> <p>Justificativa: essencial para converg\u00eancia da MLP e comparabilidade de pesos entre features.</p>"},{"location":"projs/proj2_regression/main/#3-divisao-do-dataset","title":"3. Divis\u00e3o do Dataset","text":"<pre><code>X_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.2,      # 80/20 split\n    random_state=42,    # reprodutibilidade\n    shuffle=True        # embaralhamento para evitar vi\u00e9s temporal\n)\n</code></pre> <ul> <li>Treino: 89.500 amostras (80%)</li> <li>Teste: 22.375 amostras (20%)</li> </ul>"},{"location":"projs/proj2_regression/main/#4-modelos-implementados","title":"4. Modelos Implementados","text":""},{"location":"projs/proj2_regression/main/#mlpregressor-rede-neural","title":"MLPRegressor (Rede Neural)","text":"<p>Arquitetura:</p> <ul> <li>Camada de entrada: features ap\u00f3s encoding</li> <li>Camada oculta 1: 64 neur\u00f4nios + ReLU</li> <li>Camada oculta 2: 32 neur\u00f4nios + ReLU</li> <li>Camada de sa\u00edda: 1 neur\u00f4nio (regress\u00e3o)</li> </ul> <p>Hiperpar\u00e2metros: </p><pre><code>MLPRegressor(\n    hidden_layer_sizes=(64, 32),\n    activation=\"relu\",\n    solver=\"adam\",           # otimizador adaptativo\n    alpha=1e-3,             # regulariza\u00e7\u00e3o L2\n    learning_rate=\"adaptive\", # ajuste din\u00e2mico de learning rate\n    max_iter=300,\n    early_stopping=True,     \n    n_iter_no_change=10,   \n    random_state=42\n)\n</code></pre> <p>Converg\u00eancia: parada antecipada ap\u00f3s 15 itera\u00e7\u00f5es (de 300 m\u00e1ximas)</p> <p> Figura 3: Curva de perda (loss) durante o treinamento da MLP. Converg\u00eancia r\u00e1pida com estabiliza\u00e7\u00e3o ap\u00f3s ~10 \u00e9pocas.</p>"},{"location":"projs/proj2_regression/main/#regressao-linear-baseline","title":"Regress\u00e3o Linear (Baseline)","text":"<pre><code>LinearRegression()\n</code></pre> <p>Modelo linear sem regulariza\u00e7\u00e3o, servindo como baseline para compara\u00e7\u00e3o.</p>"},{"location":"projs/proj2_regression/main/#5-metricas-de-avaliacao","title":"5. M\u00e9tricas de Avalia\u00e7\u00e3o","text":"M\u00e9trica Descri\u00e7\u00e3o Interpreta\u00e7\u00e3o MSE Mean Squared Error Erro quadr\u00e1tico m\u00e9dio RMSE Root Mean Squared Error Erro m\u00e9dio em R$ (penaliza grandes erros) MAE Mean Absolute Error Erro m\u00e9dio absoluto em R$ R\u00b2 Coeficiente de Determina\u00e7\u00e3o % da vari\u00e2ncia explicada (0 a 1)"},{"location":"projs/proj2_regression/main/#resultados","title":"Resultados","text":""},{"location":"projs/proj2_regression/main/#metricas-comparativas","title":"M\u00e9tricas Comparativas","text":"Modelo MSE (train) MSE (teste) RMSE (train) RMSE (teste) MAE (train) MAE (teste) R\u00b2 (train) R\u00b2 (teste) MLPRegressor 0.0002 0.0002 0.0141 0.0146 0.0096 0.0098 0.9999 0.9999 Regress\u00e3o Linear 0.0001 0.0001 0.0093 0.0097 0.0021 0.0021 1.0000 1.0000 <p>Observa\u00e7\u00f5es:</p> <ul> <li>A Regress\u00e3o Linear surpreendentemente superou a MLP em todas as m\u00e9tricas</li> <li>R\u00b2 da Regress\u00e3o Linear: 1.0000 (perfeito) vs 0.9999 da MLP</li> <li>RMSE da Regress\u00e3o Linear: 34% menor (0.0097 vs 0.0146)</li> <li>MAE da Regress\u00e3o Linear: 79% menor (0.0021 vs 0.0098)</li> <li>Aus\u00eancia de overfitting: m\u00e9tricas de treino e teste praticamente id\u00eanticas em ambos os modelos</li> <li>O n\u00famero reduzido de itera\u00e7\u00f5es (15) da MLP sugere r\u00e1pida converg\u00eancia</li> <li>Conclus\u00e3o principal: A rela\u00e7\u00e3o nos dados \u00e9 essencialmente linear, tornando a Regress\u00e3o Linear o modelo mais apropriado</li> </ul>"},{"location":"projs/proj2_regression/main/#analise-de-predicoes","title":"An\u00e1lise de Predi\u00e7\u00f5es","text":"<p> Figura 4: Compara\u00e7\u00e3o entre valores reais e previstos para MLP (esquerda) e Regress\u00e3o Linear (direita). A linha tracejada representa predi\u00e7\u00f5es perfeitas. A MLP apresenta pontos mais concentrados ao redor da linha ideal.</p> <p>Interpreta\u00e7\u00e3o:</p> <ul> <li>Regress\u00e3o Linear: pontos extremamente concentrados ao redor da linha ideal, indicando predi\u00e7\u00f5es quase perfeitas</li> <li>MLP: dispers\u00e3o ligeiramente maior em compara\u00e7\u00e3o com a regress\u00e3o linear</li> <li>Ambos os modelos capturam bem a rela\u00e7\u00e3o dos dados, mas a superioridade da regress\u00e3o linear confirma que a rela\u00e7\u00e3o \u00e9 predominantemente linear</li> </ul>"},{"location":"projs/proj2_regression/main/#analise-de-residuos","title":"An\u00e1lise de Res\u00edduos","text":"<p> Figura 5: An\u00e1lise de res\u00edduos (diferen\u00e7a entre valor real e previsto) para ambos os modelos. Res\u00edduos pr\u00f3ximos de zero indicam boas predi\u00e7\u00f5es.</p> <p> Figura 6: Histograma dos res\u00edduos. Distribui\u00e7\u00e3o centrada em zero com formato aproximadamente normal indica modelo bem ajustado.</p> <p>MLP:</p> <ul> <li>Res\u00edduos tamb\u00e9m aleat\u00f3rios, mas com dispers\u00e3o ligeiramente maior</li> <li>Vari\u00e2ncia homog\u00eanea, por\u00e9m maior que a regress\u00e3o linear</li> <li>Distribui\u00e7\u00e3o aproximadamente normal</li> <li>Amplitude de res\u00edduos maior comparada \u00e0 regress\u00e3o linear</li> </ul> <p>Regress\u00e3o Linear:</p> <ul> <li>Res\u00edduos distribu\u00eddos aleatoriamente ao redor de zero</li> <li>Vari\u00e2ncia extremamente baixa e homog\u00eanea (homocedasticidade)</li> <li>Distribui\u00e7\u00e3o aproximadamente normal centrada em zero</li> <li>Amplitude de res\u00edduos muito pequena</li> </ul> <p>Conclus\u00e3o: Ambos os modelos satisfazem as premissas de regress\u00e3o (res\u00edduos aleat\u00f3rios, normalmente distribu\u00eddos), mas a Regress\u00e3o Linear apresenta menor vari\u00e2ncia nos erros, confirmando sua superioridade para este problema.</p>"},{"location":"projs/proj2_regression/main/#conclusoes","title":"Conclus\u00f5es","text":""},{"location":"projs/proj2_regression/main/#desempenho-dos-modelos","title":"Desempenho dos Modelos","text":"<ol> <li> <p>Regress\u00e3o Linear demonstrou superioridade surpreendente:</p> <ul> <li>R\u00b2 perfeito de 1.0000 vs 0.9999 da MLP</li> <li>RMSE ~34% menor que a MLP (0.0097 vs 0.0146)</li> <li>MAE ~79% menor que a MLP (0.0021 vs 0.0098)</li> <li>Conclus\u00e3o: A rela\u00e7\u00e3o nos dados \u00e9 essencialmente linear</li> </ul> </li> <li> <p>A natureza linear do problema:</p> <ul> <li>As features ap\u00f3s encoding e normaliza\u00e7\u00e3o apresentam rela\u00e7\u00e3o predominantemente linear com o target</li> <li>A MLP, apesar de sua capacidade de capturar n\u00e3o-linearidades, n\u00e3o conseguiu superar o modelo linear</li> <li>Isso sugere que n\u00e3o h\u00e1 intera\u00e7\u00f5es n\u00e3o-lineares significativas entre as features</li> </ul> </li> <li> <p>MLPRegressor - Efici\u00eancia mas sem ganho de performance:</p> <ul> <li>Converg\u00eancia r\u00e1pida em apenas 15 itera\u00e7\u00f5es (early stopping)</li> <li>Tempo de treinamento maior que a regress\u00e3o linear</li> <li>Arquitetura (64, 32) suficiente para evitar overfitting, mas n\u00e3o adiciona valor preditivo</li> </ul> </li> </ol>"},{"location":"projs/proj2_regression/main/#qualidade-dos-dados","title":"Qualidade dos Dados","text":"<ul> <li>Dataset robusto com ~112K observa\u00e7\u00f5es ap\u00f3s limpeza permite treinamento confi\u00e1vel</li> <li>Tratamento cuidadoso de outliers e remo\u00e7\u00e3o de valores inv\u00e1lidos (-99999.000) melhorou qualidade dos dados</li> <li>One-hot encoding capturou diferen\u00e7as regionais e entre produtos de forma linear</li> <li>A estrutura linear dos dados p\u00f3s-processamento favorece modelos mais simples</li> </ul>"},{"location":"projs/proj2_regression/main/#limitacoes-e-trabalhos-futuros","title":"Limita\u00e7\u00f5es e Trabalhos Futuros","text":"<p>Limita\u00e7\u00f5es:</p> <ol> <li>Dados limitados a 2004-2021 (n\u00e3o incluem per\u00edodo p\u00f3s-pandemia recente)</li> <li>N\u00e3o incorpora fatores macroecon\u00f4micos externos (c\u00e2mbio, petr\u00f3leo)</li> <li>Abordagem transversal n\u00e3o explora totalmente a estrutura temporal</li> </ol> <p>Pr\u00f3ximos Passos:</p> <ol> <li> <p>Modelos de s\u00e9rie temporal:</p> <ul> <li>LSTM/GRU para capturar depend\u00eancias temporais</li> <li>Prophet para sazonalidade e tend\u00eancias</li> </ul> </li> <li> <p>Features adicionais:</p> <ul> <li>Pre\u00e7o internacional do petr\u00f3leo (Brent)</li> <li>Taxa de c\u00e2mbio USD/BRL</li> <li>Indicadores macroecon\u00f4micos (infla\u00e7\u00e3o, PIB)</li> <li>Eventos pol\u00edticos e mudan\u00e7as regulat\u00f3rias</li> </ul> </li> <li> <p>Regulariza\u00e7\u00e3o adicional:</p> <ul> <li>Testar Ridge/Lasso na regress\u00e3o linear</li> <li>Explorar diferentes arquiteturas de MLP</li> </ul> </li> <li> <p>Valida\u00e7\u00e3o temporal:</p> <ul> <li>Cross-validation com blocos temporais</li> <li>Teste de generaliza\u00e7\u00e3o para per\u00edodos futuros</li> </ul> </li> </ol>"},{"location":"projs/proj3_gen_models/main/","title":"Generative","text":"<p>Informa\u00e7\u00f5es da entrega</p> <p>\ud83d\udcc6 Deadline: 19/11/2025</p> <p>\ud83d\udcd6 O enunciado da atividade est\u00e1 dispon\u00edvel neste link.</p> <p>As pipelines de modelos utilizadas nesse projeto foram feitas com base em modelos previamente treinados utilizando a ferramenta visual ComfyUI<sup>1</sup></p>"},{"location":"projs/proj3_gen_models/main/#text-to-image-texto-para-imagem","title":"Text-to-image (Texto para imagem)","text":"<p>A pipeline utilizada nesse exemplo \u00e9 encontrada na documenta\u00e7\u00e3o<sup>2</sup>.</p> <p>Para exemplificar o funcionamento desse workflow, utilizaremos como base o diagrama da Figura 1.</p> <p></p> Figura 1: Fluxograma do processo de gera\u00e7\u00e3o de imagem a partir de um texto. Fonte: Autor. <p></p> <p>Como apontado anteriormente, o modelo foi pr\u00e9-treinado e seus pesos carregados em um arquivo no formato <code>safetensors</code>, que \u00e9 um tipo de arquivo utilizado como alternativa aos de formato <code>pickle</code>, visto que apresenta os valores num\u00e9ricos em forma de c\u00f3digo execut\u00e1vel<sup>4</sup>. Os par\u00e2metros do modelo s\u00e3o carregados devidamente em cada um dos componentes da pipeline: no CLIP, no KSampler e no VAE.</p> <p>Como podemos observar, o processo inicia com o condicionamento do modelo com Contrastive Language\u2013Image Pre-training (CLIP)<sup>3</sup>, seja ele positivo, ou seja, inserindo caracter\u00edsticas que s\u00e3o desejadas na imagem a ser gerada, ou negativo, inserindo caracter\u00edsticas n\u00e3o desejadas na imagem de sa\u00edda.</p> <p>Juntamente \u00e0 entrada, que \u00e9 uma imagem com ru\u00eddo, os condicionamentos servem de entrada para o KSampler, que aplica o modelo treinado para remover o ru\u00eddo da imagem no espa\u00e7o latente. Dessa forma, a imagem sem ru\u00eddos \u00e9 encaminhada para o decoder do Variational Auto Encoder (VAE), que decodifica a imagem no espa\u00e7o latente para uma imagem no formato original. </p> <p>O funcionamento da ferramenta pode ser visualizado pelo V\u00eddeo 1.</p> <p></p> V\u00eddeo 1: Funcionamento da ferramenta de acordo com as especifica\u00e7\u00f5es. Fonte: Autor. <p></p> <p>Al\u00e9m dos exemplos apresentados no v\u00eddeo, as seguintes imagens ilustradas na Figura 2 representam resultados do processo a partir do texto de entrada:</p> PositivoNegativo <pre><code>anime style, 1girl with long pink hair, cherry blossom background, studio ghibli aesthetic, soft lighting, intricate details\n\nmasterpiece, best quality, 4k\n</code></pre> <pre><code>low quality, blurry, deformed hands, extra fingers\n</code></pre> <p></p> Figura 2: Resultados do workflow apresentado. Fonte: Autor. <p></p>"},{"location":"projs/proj3_gen_models/main/#text-to-song-texto-para-musica","title":"Text-to-song (Texto para m\u00fasica)","text":"<p>O fluxo estudado nesse exemplo pode ser encontrado no tutorial apresentado na documenta\u00e7\u00e3o oficial<sup>5</sup>.</p> <p></p> Figura 3: Funcionamento da ferramenta de acordo com as especifica\u00e7\u00f5es. Fonte: Autor. <p></p> <p>Como ilustrado na Figura 3, o funcionamento da pipeline \u00e9 semelhante ao do exemplo de Text-to-image. A mudan\u00e7a que podemos observar em rela\u00e7\u00e3o ao fluxo anterior \u00e9 em rela\u00e7\u00e3o \u00e0s entradas, que nesse caso, n\u00e3o existe um condicionamento negativo introduzido pelo CLIP. Al\u00e9m disso, s\u00e3o introduzidos outros dois par\u00e2metros para gera\u00e7\u00e3o do \u00e1udio: o volume da voz e o tempo total de \u00e1udio a ser produzido. O volume \u00e9 um par\u00e2metro usado em uma opera\u00e7\u00e3o no espa\u00e7o latente sobre o modelo, como pode ser observado na imagem. Com isso, o KSampler re\u00fane os dados e aplica o modelo sobre um \u00e1udio vazio gerado com o tempo especificado e produz uma m\u00fasica conforme especificado pelas tags e letra de input.</p> <p>Foram gerados dois \u00e1udios de acordo com as entradas especificadas abaixo.</p> <p>Cuidado com o volume!</p> <p>Abaixe o som do dispositivo ou dos \u00e1udios clicando passando o cursor por cima do bot\u00e3o de volume do \u00e1udio, pois eles v\u00eam configurados com o volume no m\u00e1ximo por padr\u00e3o.</p> <p>Example</p> LetraTags <pre><code>[verse]\n\n[zh]wo3zou3guo4shen1ye4de5jie1dao4\n[zh]leng3feng1chui1luan4si1nian4de5piao4liang4wai4tao4\n[zh]ni3de5wei1xiao4xiang4xing1guang1hen3xuan4yao4\n[zh]zhao4liang4le5wo3gu1du2de5mei3fen1mei3miao3\n\n[chorus]\n\n[verse]\u200b\n[ko]hamkke si-kkeuleo-un sesang-ui sodong-eul pihae\u200b\n[ko]honja ogsang-eseo dalbich-ui eolyeompus-ileul balaboda\u200b\n[ko]niga salang-eun lideum-i ganghan eum-ag gatdago malhaess-eo\u200b\n[ko]han ta han tamada ma-eum-ui ondoga eolmana heojeonhanji ijge hae\n\n[bridge]\n[es]cantar mi anhelo por ti sin ocultar\n[es]como poes\u00eda y pintura, lleno de anhelo indescifrable\n[es]tu sombra es tan terca como el viento, inborrable\n[es]persigui\u00e9ndote en vuelo, brilla como cruzar una mar de nubes\n\n[chorus]\n[fr]que tu sois le vent qui souffle sur ma main\n[fr]un contact chaud comme la douce pluie printani\u00e8re\n[fr]que tu sois le vent qui s'entoure de mon corps\n[fr]un amour profond qui ne s'\u00e9loignera jamais\n</code></pre> <pre><code>synthwave, techno, synthpop, futuristic, electro, with liquid drum &amp; bass drive.\nRestless, confident, dreamy mood at 128 BPM.\nAnalog bass, pulsating arps, percussive synth stabs, gated drums.\nQuick build,  then explosive drum burst, then clean fade.\nBreathy, rhythmic female vocals, minimal emotion, metallic echo.\n</code></pre> <p></p><p></p> <p>Example</p> LetraTags <pre><code>Verse\nNeon rain on my screen,\nDreams compile in silver sheen.\nNo weight, just motion,\nI\u2019m plugged into emotion.\n\nChorus\nComfy Cloud \u2014 breathing light,\nCode and color, spark and wire.\nDrift through data, feel alive,\nIn your circuits, I arrive.\n</code></pre> <pre><code>synthwave, techno, synthpop, futuristic, electro, with liquid drum &amp; bass drive.\nRestless, confident, dreamy mood at 128 BPM.\nAnalog bass, pulsating arps, percussive synth stabs, gated drums.\nQuick build,  then explosive drum burst, then clean fade.\nBreathy, rhythmic female vocals, minimal emotion, metallic echo.\n</code></pre> <p></p><p></p> <ol> <li> <p>ComfyUI | Generate video, images, 3D, audio with AI \u21a9</p> </li> <li> <p>ComfyUI Text to Image Workflow \u21a9</p> </li> <li> <p>CLIP: Connecting text and images \u21a9</p> </li> <li> <p>Safetensors \u21a9</p> </li> <li> <p>ComfyUI ACE-Step Native Example \u21a9</p> </li> </ol>"}]}